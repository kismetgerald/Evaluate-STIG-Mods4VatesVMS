<?xml version="1.0" encoding="utf-8"?>
<!--**************************************************************************************
This file contains answers for known opens and findings that cannot be evaluated through technical means.
<STIGComments>      - Top element.  May only occur once.
      "Name"           : Required.  Must match the STIG ShortName in -ListSupportedProducts.  When a match is found, this answer file will automatically be used for the STIG.
<Vuln>              - Multiple <Vuln> sections may be configured in a single answer file provided the "ID" attribute is unique.
      "ID"             : Required.  The STIG VulnID or RuleID.
<AnswerKey>         - Multiple <AnswerKey> sections may be configured within a single <Vuln> section provided the "Name" attribute is unique.
      "Name"           : Required.  The name of the key to be called by "-AnswerKey".  "DEFAULT" may be used in lieu of using "-AnswerKey".
<Answer>            - Multiple <Answer> sections may be configured within an <AnswerKey> section provided the "Index" attribute is unique AND the combination of the other attributes is unique.
      "Index"          : Required.  Identifier for the answer.
      "ExpectedStatus" : Required.  The initial status that Evaluate-STIG determined.  Refer to "Valid Status formats" below.
      "Hostname"       : Optional.  Hostname(s) that the answer is applicable to.  Use comma separation for multiple.
      "Instance"       : Optional.  Instance name(s) (e.g. for SQL) that the answer is applicable to.  Use comma separation for multiple.  Reference FindingDetails for appropriate Instance value.
      "Database"       : Optional.  Database name(s) (e.g. for SQL) that the answer is applicable to.  Use comma separation for multiple.  Reference FindingDetails for appropriate Database value.
      "Site"           : Optional.  Site names (e.g. for IIS) that the answer is applicable to.  Use comma separation for multiple.  Reference FindingDetails for appropriate Site value.
      "ResultHash"     : Optional.  Hash of FindingDetails text after "~~~~~" bar.  Use comma separation for multiple.  Reference FindingDetails for calculated ResultHash.
<ValidationCode>    - Powershell code that returns a boolean value or Hashtable.  If blank, "true" is assumed.
                      *Note: If Validation Code returns a Hashtable, the Object MUST contain both [String]"Results" and [Boolean]"Valid" keys.  "Results" will be written to the Comments field of the STIG check.
                      The following Evaluate-STIG variables are also available to be called within validation code:
      $ESPath          : Path that Evaluate-STIG.ps1 was executed from.
      $ExpectedStatus  : Status that Evaluate-STIG determined.  Will be in CKL format (refer to "Valid Status formats" below).
      $ResultHash      : SHA1 hash of ResultData.  Reference FindingDetails for calculated ResultHash.
      $ResultData      : FindingDetails content after "~~~~~" bar.
      $Username        : User name processed for HKCU check.  Reference to FindingDetails for appropriate Username value.
      $UserSID         : User SID processed for HKCU check.  Reference to FindingDetails for appropriate UserSID value.
      $Instance        : Instance name processed.  Reference FindingDetails for appropriate Instance value.
      $Database        : Database name processed.  Reference FindingDetails for appropriate Database value.
      $Site            : Site name processed.  Reference FindingDetails for appropriate Site value.
<ValidationCode>None</ValidationCode>
<ValidTrueStatus>   - The status the check should be set to if ValidationCode returns "true".  Refer to "Valid Status formats" below.  If blank, Status is unchanged.
<ValidTrueComment>  - The verbiage to add to the Comments section if ValidationCode returns "true".
<ValidFalseStatus>  - The status the check should be set to if ValidationCode DOES NOT return "true".  Refer to "Valid Status formats" below.  If blank, Status is unchanged
<ValidFalseComment> - The verbiage to add to the Comments section if ValidationCode DOES NOT return "true".

* Valid Status formats:
    |     Status     | EvalSTIG |       CKL        |       CKLB       |      XCCDF      |
    |================|==========|==================|==================|=================|
    | Not Reviewed   | "NR"     | "Not_Reviewed"   | "Not_Reviewed"   | "notchecked"    |
    | Not A Finding  | "NF"     | "NotAFinding"    | "not_a_finding"  | "pass"          |
    | Open           | "O"      | "Open"           | "Open"           | "fail"          |
    | Not Applicable | "NA"     | "Not_Applicable" | "Not_Applicable" | "notapplicable" |
    |================|==========|==================|==================|=================|

* Answer Weighting:
  Evaluate-STIG adds the weights for all "applicable" attributes configured in an <Answer>.  If an attribute is configured but not applicable to the STIG (e.g. configuring the "Database" attribute for an IIS Site STIG) then the weight for that attribute is not included in the calculation.
    |    Attribute     | Weight |
    |==================|========|
    | ExpectedStatus   |   0 *  |  * ExpectedStatus is a hard requirement.  If not a match, the answer is ignored.
    | Hostname         |   5    |
    | Instance         |   4    |
    | Database         |   3    |
    | Site             |   2    |
    | ResultHash       |   1    |
    | <AnswerKey Name> |   16   |
    |==================|========|
**************************************************************************************-->
<STIGComments Name="XO_WebSRG">
  <!--Evaluate-STIG answer file for Xen Orchestra (based on the Web Server SRG)-->
  
  <Vuln ID="V-206350">
    <!--RuleTitle: The web server must limit the number of allowed simultaneous session requests.-->
    <AnswerKey Name="XO">
      <!--Session #25 Batch 2 (Jan 31, 2026): Organizational policy check for session limits-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with documented session limit policy-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra session management is configured with organizational session limits to prevent resource exhaustion and denial of service.

The automated check verified session limit infrastructure:
(1) Redis session store with maxclients limit configured
(2) Node.js/Express server connection limits
(3) Operating system file descriptor limits (ulimit)
(4) Session limit monitoring implemented

Finding: Not a Finding

Justification: This organization has defined maximum concurrent session limits based on system capacity and documented them in the security plan per NIST SP 800-53r5 SC-5 (Denial of Service Protection). The session limit configuration prevents resource exhaustion while allowing legitimate users appropriate access.

Session limit configuration:
- Redis maxclients: [organizational value]
- Monitoring: Session count tracked in SIEM
- Documentation: Security plan Section [X.X]

No additional configuration or remediation required for systems with documented session limit policy.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but organizational session limit policy is not documented, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant or undocumented systems requiring session limit policy-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check detected session management infrastructure (Redis) but cannot verify organizational session limit policy is defined and documented.

Required Manual Verification:
(1) Define organizational maximum concurrent session limit
    - Consider system capacity (CPU, memory, network)
    - Balance security (prevent DoS) with usability
    - Document rationale for chosen limit

(2) Configure session limit in XO Server or Redis
    - For Redis: Set maxclients in /etc/redis/redis.conf
    - For XO: Configure in /opt/xo/xo-server/config.toml
    - Example Redis configuration:
      maxclients 1000

(3) Test session limit enforcement
    - Use load testing tool to verify limit enforced
    - Confirm graceful handling when limit reached
    - Verify error messages appropriate for users

(4) Implement monitoring for session count
    - Configure SIEM alerts for high session usage
    - Define threshold for warning (e.g., 80% of limit)
    - Trend analysis to identify capacity issues

(5) Document session limit policy in security plan
    - Maximum concurrent sessions allowed
    - Justification for limit chosen
    - Monitoring and alerting procedures

Restart XO service after configuration changes:
  systemctl restart xo-server

Re-run scan to verify compliance after documentation complete.

Note: Default Redis maxclients is 10000, but organizational policy must define appropriate limit based on risk tolerance and system capacity per NIST SP 800-53r5 SC-5.
        </ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but session limit policy is documented and enforced, manual verification required to confirm policy meets DoD requirements.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206351">
    <!--RuleTitle: The web server must perform server-side session management.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO uses Redis for server-side session storage by default. Session tokens stored on server, not client cookies.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra performs server-side session management using Redis, which stores session tokens on the server rather than in client-side cookies. This organization has verified that Redis is properly configured and running on the XO server. Session data is maintained server-side with only a session identifier sent to the client, meeting the requirement for server-side session management. The architecture prevents session hijacking through client-side cookie manipulation and ensures centralized session control.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>Xen Orchestra's session management configuration could not be verified. This organization must manually confirm that server-side session management is properly implemented using Redis or another server-side session store. Client-side cookie-only session management does not meet STIG requirements.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206352">
    <!--RuleTitle: The web server must use cryptography to protect the integrity of remote access sessions.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Index created by Evaluate-STIG_GUI.ps1-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus></ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra uses TLS 1.2+ with strong cryptographic algorithms to protect the integrity of remote access sessions. The Node.js HTTPS server employs AES encryption and SHA hashing algorithms that meet current cryptographic standards. Session data transmitted between clients and the XO server is protected against unauthorized modification through the use of authenticated encryption modes. This implementation satisfies the requirement for cryptographic protection of session integrity as specified in the Web Server Security Requirements Guide.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206353">
    <!--RuleTitle: The web server must use cryptography to protect the confidentiality of remote access sessions.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Index created by Evaluate-STIG_GUI.ps1-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus></ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra exclusively uses HTTPS for all remote access sessions, ensuring confidentiality through TLS encryption. The Node.js HTTPS server encrypts all session data using TLS 1.2+ protocols, preventing eavesdropping and unauthorized disclosure of sensitive information. HTTP access is disabled by default, eliminating any possibility of plain text session data transmission. This configuration ensures that all communication between XO clients and the server is encrypted, meeting the STIG requirement for cryptographic protection of session confidentiality.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206354">
    <!--RuleTitle: The web server must generate information to be used by external applications or entities to monitor and control remote access.-->
    <AnswerKey Name="XO">
      <!--Session #25 Batch 1: Remote access monitoring - requires SIEM integration verification-->
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--System integrated with organizational SIEM/monitoring platform-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra is integrated with the organizational SIEM/monitoring platform for remote access monitoring and control.

            The automated check verified:
            (1) XO generates remote access logs via Winston logger and systemd journal
            (2) Log data is accessible via standard Linux mechanisms
            (3) Network architecture (separate VLAN + ACLs) supports external monitoring

            This organization has confirmed:
            - SIEM integration: [SPECIFY: Splunk/ArcSight/QRadar/Other]
            - Log forwarding configured via rsyslog/filebeat/other
            - Remote access events are forwarded to monitoring system
            - Monitoring system receives and processes XO access logs

            Finding: Not a Finding

            Justification: XO web server generates comprehensive log information accessible to external monitoring applications. Integration with organizational SIEM platform confirmed per security plan. This configuration meets NIST SP 800-53r5 AU-2 (Event Logging) and AU-6 (Audit Record Review) requirements.

            No additional configuration required for systems where SIEM integration is documented.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but SIEM integration is not documented, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--SIEM integration not verified - manual documentation required-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check confirmed XO generates log data containing remote access information, but integration with external monitoring applications cannot be automatically verified.

              Required Manual Verification:
              (1) Document SIEM/monitoring platform in use (Splunk, ArcSight, QRadar, etc.)
              (2) Verify log forwarding configuration (rsyslog, filebeat, logstash, etc.)
              (3) Confirm monitoring system receives XO remote access events
              (4) Validate alerting configured for suspicious access patterns
              (5) Document integration in organizational security plan

              Evidence to Collect:
              - SIEM dashboard screenshot showing XO logs
              - Log forwarding configuration file (/etc/rsyslog.conf or equivalent)
              - Monitoring system query results for XO remote access events
              - Security plan section documenting external monitoring

              Remediation (if not integrated):
              Configure log forwarding to organizational SIEM:

              For rsyslog:
                Edit /etc/rsyslog.conf
                Add: *.* @@[SIEM_IP]:514
                Restart: systemctl restart rsyslog

              For filebeat:
                Install filebeat package
                Configure /etc/filebeat/filebeat.yml
                Point to SIEM endpoint
                Enable and start service

              After configuration:
              - Test log forwarding with logger command
              - Verify logs appear in SIEM
              - Update security plan with integration details
              - Re-run scan to verify compliance

              This check supports NIST SP 800-53r5 AU-2 and AU-6 requirements for audit logging and centralized monitoring.
        </ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but SIEM integration is verified through other means, document the verification method.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206355">
    <!--RuleTitle: The web server must enforce approved authorizations for logical access to hosted applications and resources in accordance with applicable access control policies.-->
    <AnswerKey Name="XO">
      <!--Session #25 Batch 1: Authorization enforcement via Microsoft AD + XO RBAC-->
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Microsoft AD integration confirmed with RBAC enforcement-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra enforces approved authorizations through integration with Microsoft Active Directory and XO's Role-Based Access Control (RBAC) framework.

            The automated check verified:
            (1) XO delegates ALL authentication to Microsoft Active Directory
            (2) External IdP architecture detected in configuration (LDAP/AD)
            (3) RBAC framework present in XO implementation
            (4) Web server (Node.js/Express) serves as transport layer only

            This organization has confirmed:
            - Microsoft AD integration properly configured and functional
            - AD group-to-role mappings documented in XO configuration
            - Unauthorized users cannot access resources (tested and verified)
            - RBAC policy and role definitions documented in security plan
            - Web server does not perform authorization independently
            - All access decisions enforced by AD authentication + XO RBAC

            Authorization enforcement flow:
            1. User authenticates via Microsoft AD
            2. AD returns user's group memberships
            3. XO maps AD groups to XO roles (documented mappings)
            4. XO ACL checks role permissions for each resource access
            5. API calls require valid token with appropriate role

            Finding: Not a Finding

            Justification: XO web server enforces approved authorizations through external IdP (Microsoft AD) and application-layer RBAC. Web server does not perform authorization independently - all access control decisions delegated to enterprise IdP + XO application logic. This configuration meets NIST SP 800-53r5 AC-2 (Account Management), AC-3 (Access Enforcement), and AC-6 (Least Privilege) requirements.

            No additional configuration required for systems with documented AD integration and RBAC mappings.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but AD integration is not verified, manual testing is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--AD integration or RBAC not verified - manual documentation required-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check detected external authentication configuration, but cannot automatically verify Microsoft AD integration and RBAC enforcement.

Required Manual Verification:
(1) Confirm Microsoft AD integration is properly configured
(2) Verify AD group-to-role mappings in XO configuration
(3) Test that unauthorized users CANNOT access resources
(4) Confirm authorization decisions made by AD + XO RBAC (not web server)
(5) Document RBAC policy and role definitions in security plan
(6) Validate web server delegates all authorization to XO application

Evidence to Collect:
- XO configuration file showing AD integration settings
- AD group-to-role mapping documentation
- Test results showing unauthorized access denied
- Security plan section documenting RBAC implementation
- Screenshots of XO ACL configuration

Testing Procedure:
1. Create test user in AD without authorized groups
2. Attempt login to XO
3. Verify user cannot access VM operations
4. Add user to authorized AD group
5. Verify user can now access resources per role
6. Document test results

Remediation (if not properly configured):
Configure Microsoft AD integration:

XOCE (Community Edition):
  Edit: /opt/xo/xo-server/config.toml

XOA (Appliance):
  Edit: /etc/xo-server/config.toml

Add LDAP/AD configuration:
  [authentication.providers.ldap]
  uri = "ldap://ad.domain.com"
  baseDN = "DC=domain,DC=com"
  filter = "(&amp;(objectClass=user)(sAMAccountName={name}))"

Document AD group mappings and restart XO Server.

This check supports NIST SP 800-53r5 AC-2, AC-3, and AC-6 requirements.
        </ValidTrueComment>
        <ValidFalseStatus>NotAFinding</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but AD integration is verified through testing, document the test results.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206356">
    <!--RuleTitle: Web server must produce log records containing sufficient information to establish what type of events occurred (startup/shutdown events).-->
    <AnswerKey Name="XO">
      <!--Session #18 continuation (Jan 25, 2026): Implemented automated check with multi-method log verification.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO web server produces log records with sufficient event type information.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra web server produces log records containing sufficient information to establish what type of events occurred. The automated check confirmed event type logging through: (1) Systemd journal contains startup/shutdown/restart events for xo-server service with timestamps, (2) Traditional log files (if present) contain event classifications, (3) XO REST API audit logs record event types via /rest/v0/plugins/audit/records endpoint (when API token available), or (4) Log entries include required fields (timestamp, event type, source, outcome). This meets STIG SRG-APP-000095-WSR-000056 requirement for event type identification. Organizational logging policy requires all security-relevant events (authentication, authorization, configuration changes, startup/shutdown) to be logged with standardized event classification codes per NIST SP 800-92 guidelines. Logs are reviewed monthly by security team and retained for minimum 1 year per retention policy.</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>The automated check confirmed event type logging. This comment should not normally appear.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Unable to determine event type logging - manual verification required.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check could not conclusively determine if XO web server logs contain sufficient event type information. Manual verification is required to meet STIG SRG-APP-000095-WSR-000056 compliance.

              Verification procedure:
              (1) Check systemd journal: journalctl -u xo-server --no-pager -n 100
              (2) Look for startup/shutdown/restart events with timestamps
              (3) Check traditional logs: cat /var/log/xo-server/*.log | grep -i 'start\|stop\|restart'
              (4) Verify XO API audit logs (if token available): curl -H "Authorization: Bearer $TOKEN" https://localhost/rest/v0/plugins/audit/records?limit=50
              (5) Confirm log entries include: timestamp, event type, source component, outcome (success/failure)

              Remediation:
              XO should log event types by default via systemd journal. If logging insufficient:
              - Enable XO audit plugin: xo-cli plugin.install id=xo-server-audit
              - Configure logging level in /opt/xo/xo-server/config.toml: [logs] level = "info"
              - Restart xo-server: systemctl restart xo-server
              - Verify enhanced logging: journalctl -u xo-server -f

              Document findings with journalctl output showing event types, systemd unit file verification (systemctl cat xo-server), and XO config.toml logging section. Contact Vates support if event type logging incomplete - XO audit plugin should provide comprehensive event classification.
        </ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206357">
    <!--RuleTitle: The web server must produce log records containing sufficient information to establish the date and time the events occurred.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO logs contain ISO 8601/RFC 3339 timestamps (systemd journal + Winston logger).-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra log records contain comprehensive date and time information. Systemd journal uses ISO 8601 timestamps (YYYY-MM-DDTHH:mm:ss+TZ format). Winston logger uses RFC 3339 timestamps with milliseconds. All logs are synchronized via system time (NTP/chrony). Timestamps establish when events occurred per DoD logging requirements. The organization has verified timestamp formats comply with federal standards.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>Timestamp format verification shows potential issues. Review systemd journal timestamp format (journalctl -u xo-server) and Winston logger configuration. Verify ISO 8601 or RFC 3339 compliance. Ensure NTP/chrony is configured for accurate time synchronization across all systems.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Manual verification required for timestamp compliance.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>Unable to automatically verify timestamp format in logs. Manual review required: Check systemd journal (journalctl -u xo-server --no-pager -n 20), review Winston logger configuration in XO Server source code (/opt/xo/xo-server), verify ISO 8601 or RFC 3339 timestamp format is present in all log entries. Ensure time synchronization service (NTP/chrony) is running and properly configured. Document timestamp format compliance.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index is used when timestamps cannot be automatically verified. If scan returns NotAFinding, validate that timestamp formats actually comply with DoD standards (ISO 8601 or RFC 3339).</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206359">
    <!--RuleTitle: The web server must produce log records containing sufficient information to establish the outcome of events.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO logs contain outcome information via HTTP status codes, log levels, and explicit results.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra logs contain comprehensive event outcome information through multiple mechanisms. HTTP access logs include status codes (2xx success, 4xx client errors, 5xx server errors). Winston logger uses severity levels (error, warn, info, debug) indicating operation outcomes. Application logs include explicit operation results (started, stopped, failed, completed, error). Systemd journal logs service exit codes (0=success, non-zero=failure). The organization has verified that multiple layers establish event outcomes per DoD logging requirements.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>Event outcome information detected but verification shows potential issues. Review HTTP status codes in Express.js access logs, verify Winston log levels are properly configured, check application-specific outcome messages for clarity and completeness. Ensure all critical operations log explicit success/failure results.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Manual verification required for outcome information.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>Unable to automatically verify event outcome information. Manual review required: Check Express.js access logs for HTTP status codes (200, 404, 500, etc.), verify Winston logger configuration includes severity levels, review application logs for explicit operation outcomes (success/failed/error messages), examine systemd journal for service exit codes (journalctl -u xo-server). Ensure all operations log outcomes that clearly indicate success or failure. Document outcome logging compliance.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index is used when outcome information cannot be automatically verified. If scan returns NotAFinding, validate that outcome data (HTTP status codes, log levels, operation results) is actually present and meaningful.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206360">
    <!--RuleTitle: The web server must produce log records containing sufficient information to establish the identity of any user/subject or process associated with an event.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO logs contain comprehensive user/process identity (email, session ID, PID, UID/GID).-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra logs contain comprehensive user, subject, and process identity information. User identity includes email address, display name, session ID (Redis-backed), and authentication method (local/LDAP/SAML/OAuth). Authentication events log username, provider, source IP, and user agent. Process identity includes PID (process ID), UID (user ID), GID (group ID) in systemd journal. API requests are fully attributed to authenticated users with session tracking. The organization has verified that identity information establishes who/what performed each action per DoD audit trail requirements.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>User/process identity information detected but verification shows potential issues. Review application logs for user email/name fields, verify session ID tracking in Redis, check systemd journal for process identity fields (journalctl -u xo-server -o verbose), ensure API requests include user attribution. Verify authentication events log complete user credentials.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Manual verification required for identity information.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>Unable to automatically verify user/process identity information. Manual review required: Check application logs for user email addresses and display names, verify session ID tracking in Redis (redis-cli KEYS "sess:*"), review systemd journal verbose output for _PID, _UID, _GID fields (journalctl -u xo-server -o verbose), examine authentication logs for username and provider information, verify API access logs include user attribution. Ensure all user-initiated actions are logged with identity information. Document identity logging compliance.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index is used when identity information cannot be automatically verified. If scan returns NotAFinding, validate that user/process identity (email, session ID, PID, UID) is actually logged for all events.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

    <Vuln ID="V-206361">
    <!--RuleTitle: The web server must produce log records containing sufficient information to establish where within the web server the events occurred.-->
    <AnswerKey Name="XO">
      <!--Session #25 Batch 2 (Jan 31, 2026): Organizational policy check for event location logging-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with verified log format containing WHERE information-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra logging configuration produces log records containing sufficient information to establish WHERE within the web server events occurred (component, process, module identification).

The automated check verified multi-layer logging architecture:
(1) Winston Logger - Application-level with component names
(2) Express.js Middleware - HTTP request handler identification
(3) Systemd Journal - System-level with PID tracking
(4) Process/component identifiers detected in log files

Finding: Not a Finding

Justification: This organization has verified through manual log review that XO log format includes WHERE information per NIST SP 800-53r5 AU-3 (Content of Audit Records). Log entries include component name (xo-server, API handler, auth module), process ID, and module/function name, enabling auditors to determine where within the web server events occurred.

Example log format verified:
[2026-01-31T12:00:00Z] [xo-server:api] INFO User authentication successful
[2026-01-31T12:01:00Z] [xo-server:vm] WARN VM start operation initiated

Log review documentation: Security plan Section [X.X]

No additional configuration or remediation required for systems with verified log format.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but manual log review has not been performed, verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Systems requiring manual log format verification-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check detected logging infrastructure (Winston, systemd journal) but cannot verify log format contains sufficient WHERE information.

Required Manual Verification Procedure:

(1) Generate test events in XO:
    - User login/logout
    - VM start/stop operation
    - Configuration change
    - Failed authentication attempt
    - API call

(2) Review log files to confirm component/process identification:

    Log locations to check:
    - /var/log/xo-server/xo-server.log (Winston application logs)
    - /var/log/syslog (system-level logs)
    - journalctl -u xo-server (systemd journal)

    View recent XO logs:
      tail -n 50 /var/log/xo-server/xo-server.log
      journalctl -u xo-server -n 50 --no-pager

(3) Verify log entries contain WHERE information:

    Required elements:
    ✓ Component name (xo-server, API handler, auth module, etc.)
    ✓ Process ID (PID)
    ✓ Module/function name (login, VM operations, config, etc.)
    ✓ Service identifier (if multiple services running)

    Expected log format:
    [TIMESTAMP] [COMPONENT] [LEVEL] [MESSAGE]

    Example compliant log entry:
    2026-01-31T12:00:00.000Z [xo-server:api:auth] INFO User admin@domain.com authenticated successfully PID:1234

(4) Document log format verification:
    - Screenshot sample log entries showing WHERE elements
    - List components/modules identified in logs
    - Confirm Winston logger configuration includes component names
    - Document in security plan

(5) If log format insufficient, configure Winston logger:

    Edit /opt/xo/xo-src/xen-orchestra/packages/xo-server/src/xo.mjs
    Ensure Winston transport includes component/module metadata

    Restart XO Server:
      systemctl restart xo-server

Re-run scan after manual verification complete and documented.

Note: Winston logger includes component identification by default. This manual verification confirms WHERE information is sufficient per NIST SP 800-53r5 AU-3.
        </ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but manual review confirms WHERE information is present, update documentation and re-assess.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206362">
    <!--RuleTitle: The web server must produce log records containing sufficient information to establish the source of events.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Index 1: System compliant - logs contain event source information-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>XO Server comprehensively logs event sources through multiple layers:
              - HTTP access logs capture source IP address from network connections
              - Winston logging framework identifies application component and module names
              - Express.js middleware logs API endpoints and authenticated user context
              - Systemd journal records hostname and service unit information

              The combination of these logging layers establishes complete event source traceability per DoD requirements. Each log entry contains sufficient information to identify where an event originated (IP address, user, component, endpoint).
        </ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Index 2: System non-compliant - troubleshooting guidance-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>FINDING: XO Server logs do not contain sufficient event source information.

              Troubleshooting Steps:

              1. Verify Winston Logger Configuration:
                - Check /opt/xo/xo-server/config.toml (XOCE) or /etc/xo-server/config.toml (XOA)
                - Ensure logging section includes component and module identification
                - Verify log level is set to 'info' or more verbose

              2. Check Express.js Middleware:
                - Confirm HTTP access logging middleware is enabled
                - Verify source IP address logging is configured
                - For proxy deployments, ensure 'trust proxy' setting is enabled

              3. Verify Systemd Journal Integration:
                - Run: journalctl -u xo-server -n 50
                - Confirm service logs are being captured by systemd
                - Check for hostname and service unit in journal entries

              4. Test Log Generation:
                - Generate test events (login, API call, VM operation)
                - Review logs to confirm all source information is captured
                - Verify logs contain: IP address, component name, user, endpoint

              5. Contact Vates Support:
                - If logging components are missing or incomplete
                - For guidance on enabling comprehensive source logging
                - Request configuration examples for DoD compliance

              Reference: VATES_COMPLIANCE_BLOCKERS.md for known logging limitations.
        </ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206363">
    <!--RuleTitle: A web server, behind a load balancer or proxy server, must produce log records containing the client IP information as the source and destination and not the load balancer or proxy IP information with each event.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Index 1: System compliant - logs contain real client IP (not proxy IP)-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>XO Server correctly logs real client IP addresses in all deployment scenarios:

              Direct Connection Deployments:
              - Express.js logs socket remote address (actual client IP)
              - No proxy headers involved
              - IP source is direct network connection

              Reverse Proxy Deployments (Nginx/HAProxy):
              - Express.js 'trust proxy' setting extracts real client IP from X-Forwarded-For header
              - Framework parses proxy headers to identify original requestor
              - Logs contain client IP (not proxy IP)

              Multiple Proxy Chain:
              - X-Forwarded-For contains full chain: client, proxy1, proxy2
              - Express.js extracts leftmost (original) IP address
              - Logs show original client IP (first entry in chain)

              The Express.js framework provides built-in proxy-aware client IP logging that complies with DoD requirements for proxy/load balancer environments.
        </ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Index 2: System non-compliant - troubleshooting guidance-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>FINDING: XO Server logs contain proxy/load balancer IP instead of real client IP.

              Troubleshooting Steps:

              1. Verify Express.js Trust Proxy Configuration:
                - Check /opt/xo/xo-server/config.toml (XOCE) or /etc/xo-server/config.toml (XOA)
                - Look for: trustProxy = true (or specific proxy IPs)
                - If missing, add: trustProxy = true under [http] section

              2. Verify Reverse Proxy Configuration:
                - For Nginx: Confirm proxy_set_header X-Forwarded-For in nginx.conf
                - For HAProxy: Confirm option forwardfor in haproxy.cfg
                - Ensure proxy forwards client IP headers to XO Server

              3. Test Client IP Logging:
                - Generate test HTTP request through proxy
                - Check XO logs for client IP (should be your IP, not proxy IP)
                - Compare logged IP with actual client source

              4. Validate Proxy Header Transmission:
                - Use curl with -v flag to view HTTP headers
                - Confirm X-Forwarded-For or X-Real-IP headers are present
                - Verify headers contain original client IP

              5. Check Express.js Version Compatibility:
                - Ensure Express.js version supports 'trust proxy' setting
                - Review XO Server package.json for Express.js version
                - Update if necessary (consult Vates for compatibility)

              6. Contact Vates Support:
                - For assistance configuring trust proxy setting
                - If proxy headers are not being processed correctly
                - Request proxy deployment configuration guidance

              Reference: VATES_COMPLIANCE_BLOCKERS.md for known proxy logging issues.
        </ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206364">
    <!--RuleTitle: The web server must produce log records that contain sufficient information to establish the outcome (success or failure) of events.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Index 1: System compliant - logs contain event outcome information-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>NOTE: V-206364 is an alternate requirement for V-206359. Both checks verify the same logging capability using identical criteria.

              XO Server comprehensively logs event outcomes through multiple layers:

              HTTP Status Codes (Express.js):
              - 2xx Success: 200 OK, 201 Created, 204 No Content
              - 3xx Redirection: 301 Moved, 302 Found, 304 Not Modified
              - 4xx Client Error: 400 Bad Request, 401 Unauthorized, 404 Not Found
              - 5xx Server Error: 500 Internal Error, 503 Service Unavailable

              Winston Logger Severity Levels:
              - error: Operation failed, exceptions thrown, critical issues
              - warn: Warning conditions, degraded performance, potential problems
              - info: Informational messages, successful normal operations
              - debug: Detailed diagnostic information for troubleshooting

              Application-Level Success/Failure Logging:
              - VM lifecycle: start success/failed, stop completed/error, migration completed/failed
              - Backup operations: completed successfully/partial/failed
              - Authentication: authenticated/denied, granted/forbidden
              - Configuration: applied/reverted/validation failed

              The combination of HTTP status codes, Winston log levels, and explicit operation outcomes provides complete event outcome traceability per DoD requirements.
        </ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Index 2: System non-compliant - troubleshooting guidance-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>FINDING: XO Server logs do not contain sufficient event outcome information.

              NOTE: This finding also applies to V-206359 (both verify identical outcome logging requirements).

              Troubleshooting Steps:

              1. Verify HTTP Status Code Logging:
                - Check Express.js access logs for HTTP response status codes
                - Confirm status codes are being logged for each request
                - Verify log format includes status code field

              2. Verify Winston Logger Configuration:
                - Check /opt/xo/xo-server/config.toml (XOCE) or /etc/xo-server/config.toml (XOA)
                - Ensure log level is set to capture error, warn, and info levels
                - Verify Winston log format includes severity level

              3. Verify Application-Level Outcome Logging:
                - Review logs for explicit operation outcomes (success/failed/error)
                - Check VM lifecycle operation logs for outcome status
                - Verify backup/restore logs include completion status

              4. Test Outcome Logging:
                - Generate successful operation (VM start, backup job)
                - Generate failed operation (invalid API call, permission denied)
                - Review logs to confirm outcomes are logged clearly

              5. Check Systemd Journal Integration:
                - Run: journalctl -u xo-server -n 100
                - Verify service state changes and exit codes are logged
                - Confirm journal entries include outcome information

              6. Contact Vates Support:
                - If outcome information is missing from logs
                - For guidance on enhancing outcome logging
                - Request configuration examples for comprehensive outcome tracking

              Reference: VATES_COMPLIANCE_BLOCKERS.md for known logging limitations.
        </ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206365">
    <!--RuleTitle: The web server must produce log records containing sufficient information regarding event details.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO logs contain all DoD minimum information requirements (what, when, where, who, outcome).-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra logs contain all DoD minimum information requirements for comprehensive event details. The five required elements are verified: (1) WHAT - Event types logged via systemd, Winston levels, HTTP methods; (2) WHEN - ISO 8601/RFC 3339 timestamps in all logs; (3) WHERE - Hostname, IP addresses, component/module names; (4) WHO - User email, session ID, process ID, UID/GID; (5) OUTCOME - HTTP status codes, log severity levels, exit codes, explicit results. Multi-layer logging architecture (Winston, Express, systemd, audit plugin) ensures comprehensive coverage. Structured JSON format enables automated analysis and forensic investigation. The organization has verified the system exceeds DoD minimum log information requirements.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>Minimum information requirements detected but verification shows gaps in coverage. Review logs to ensure all five elements present: event type, timestamp, location/source, user/process identity, and outcome. Verify Winston logger configuration, Express.js middleware, and systemd journal settings. Check for any log categories missing required fields.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Manual verification required for comprehensive minimum information.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>Unable to automatically verify all DoD minimum information requirements. Manual comprehensive review required: (1) Verify WHAT happened - event types in logs (startup, shutdown, operations, access); (2) Verify WHEN - timestamp format and presence (ISO 8601/RFC 3339); (3) Verify WHERE - location/source information (hostname, IP, component); (4) Verify WHO - user/process identity (email, session ID, PID); (5) Verify OUTCOME - success/failure indicators (status codes, log levels, results). Review Winston logger configuration, Express.js access logs, systemd journal, and any audit plugins. Ensure structured logging format with all required fields. Document comprehensive logging compliance covering all five minimum elements.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index is used when comprehensive minimum information cannot be automatically verified. If scan returns NotAFinding, validate that all five DoD required elements (what, when, where, who, outcome) are actually present in sufficient detail.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206366">
    <!--RuleTitle: The web server must use a logging mechanism that is configured to alert the ISSO and SA in the event of a processing failure.-->
    <AnswerKey Name="XO">
      <!--Session #25 Batch 2 (Jan 31, 2026): Organizational policy check for log failure alerting-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with SIEM/alerting integration configured-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra logging mechanism is configured to alert the ISSO and SA in the event of log processing failures through integration with organizational monitoring platform.

The automated check verified logging infrastructure:
(1) Systemd journal for system-level logging
(2) systemd OnFailure configured for xo-server service
(3) External monitoring integration confirmed

Finding: Not a Finding

Justification: This organization has integrated XO logging with external SIEM/monitoring platform per NIST SP 800-53r5 AU-5(2) (Real-Time Alerts). Log processing failures trigger alerts to ISSO and SA through:

- SIEM platform: [Splunk/ArcSight/QRadar/etc.]
- Alert mechanism: [Email/SNMP/webhook]
- ISSO contact: [email/phone]
- SA contact: [email/phone]

Alert triggers configured for:
- Disk space exhaustion (&gt;90% full)
- Log service failures (systemd, xo-server crash)
- Log forwarding failures (rsyslog, filebeat)
- Log rotation failures

Alerting tested: [date of last test]
Documentation: Security plan Section [X.X]

No additional configuration or remediation required for systems with verified SIEM integration.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but SIEM integration has not been tested, verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Systems requiring SIEM/alerting integration-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check detected logging infrastructure but cannot verify ISSO/SA alerting is configured for log processing failures.

Required Manual Verification and Configuration:

(1) Confirm SIEM/monitoring platform configured:

    Required components:
    - SIEM platform (Splunk, ArcSight, QRadar, etc.)
    - Log aggregation agent (rsyslog, filebeat, fluentd)
    - Alerting service (email, SNMP, webhook)

    Example rsyslog forwarding configuration:
    Create /etc/rsyslog.d/50-xo-server.conf:
      # Forward XO logs to SIEM
      if $programname == 'xo-server' then @@siem.domain.com:514
      &amp; stop

    Restart rsyslog:
      systemctl restart rsyslog

(2) Configure systemd service failure alerts:

    Edit /etc/systemd/system/xo-server.service:
      [Unit]
      OnFailure=failure-notification@%n.service

    Create notification service:
    /etc/systemd/system/failure-notification@.service:
      [Unit]
      Description=Send notification for %i failure

      [Service]
      Type=oneshot
      ExecStart=/usr/local/bin/send-alert.sh "XO Server failure on %H"

    Reload systemd:
      systemctl daemon-reload

(3) Configure disk space monitoring:

    Create cron job for disk space alerts:
    /etc/cron.hourly/check-disk-space:
      #!/bin/bash
      THRESHOLD=90
      USAGE=$(df -h /var/log | awk 'NR==2 {print $5}' | sed 's/%//')
      if [ $USAGE -gt $THRESHOLD ]; then
        mail -s "XO1 /var/log &gt;90% full" isso@domain.com,sa@domain.com
      fi

    Make executable:
      chmod +x /etc/cron.hourly/check-disk-space

(4) Test alerting mechanism:

    Test log service failure:
      systemctl stop xo-server
      # Verify ISSO/SA receive alert
      systemctl start xo-server

    Test disk space alert:
      # Create large test file to trigger threshold
      # Verify ISSO/SA receive alert
      # Remove test file

(5) Document ISSO and SA contact information:
    - ISSO: [name], [email], [phone]
    - SA: [name], [email], [phone]
    - Backup contacts: [names/contact info]
    - Escalation procedures: [documented process]

(6) Establish testing schedule:
    - Alert test frequency: [monthly/quarterly]
    - Last test date: [date]
    - Next scheduled test: [date]

Document all alerting configuration in security plan.

Re-run scan after SIEM integration verified and tested.

Note: Integration with external monitoring platform required per NIST SP 800-53r5 AU-5(2) to ensure ISSO/SA notification of log processing failures.
        </ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but SIEM alerting is configured, verify configuration and update documentation.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206367">
    <!--RuleTitle: The web server must use the internal system clock to generate time stamps for log records.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)
Session #17 (Jan 24, 2026): Updated with XO REST API integration. Removed Answer Index 2 (manual verification override). API provides real-time timestamp verification with 60-minute tolerance.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO uses system clock for log timestamps. Automated check uses XO REST API audit logs (primary) or systemd journal (fallback).-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra uses the internal system clock to generate timestamps for log records. This organization has verified that XO audit log timestamps (accessed via REST API /rest/v0/plugins/audit/records or systemd journal) are synchronized with the system clock (within 60 minutes tolerance). The automated check retrieves the most recent audit log entry, parses the Unix millisecond timestamp, and compares it to the current system time per STIG requirements. XO uses Node.js runtime which exclusively relies on the operating system's internal system clock (Date.now() and process.hrtime() APIs) for all timestamp generation. There is no external time source configured. This meets the STIG requirement that log timestamps must use the internal system clock.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>The automated check found that log timestamps do not match the system clock (time difference exceeds 60 minutes). This indicates a potential issue with system clock synchronization or XO logging configuration. Verify: (1) NTP is configured and running (timedatectl status), (2) System time is accurate (date), (3) XO server process is running (systemctl status xo-server), (4) Audit logs are being generated (check XO web UI Settings/Logs or REST API). If system time is correct and XO is running but timestamps are still out of sync, this is a finding requiring investigation.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Answer Index 2: For systems with timestamp synchronization issues. Does NOT override status - keeps as Open for investigation.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check found that log timestamps do not match the system clock (time difference exceeds 60 minutes). This indicates a potential issue with system clock synchronization or XO logging configuration. Recommended troubleshooting steps: 

              (1) Check NTP synchronization: timedatectl status, 
              (2) Verify system time is accurate: date, 
              (3) Confirm XO server is running: systemctl status xo-server, 
              (4) Verify audit logs are being generated: Check XO web UI Settings/Logs or REST API /rest/v0/plugins/audit/records. 

              If system time is correct and XO is running but timestamps are still out of sync, this finding requires further investigation by the system administrator to determine the root cause (possible NTP misconfiguration, system clock drift, or XO logging malfunction).
        </ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206368">
    <!--RuleTitle: Web server must restrict the ability of users to launch DoS attacks - log file read/modify protection.-->
    <AnswerKey Name="XO">
      <!--Session #18 continuation (Jan 25, 2026): Implemented automated check with multi-method log verification.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO log files properly protected from unauthorized read/modify access.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra log files are properly protected from unauthorized read/modify access to prevent Denial of Service attacks through log manipulation. The automated check confirmed log protection through: (1) Systemd journal permissions prevent non-root modification (systemd-journal group read-only for authorized users), (2) Traditional log file permissions are 640 or more restrictive (owner read/write, group read, no world access), (3) File group ownership is root, adm, or systemd-journal (privileged groups only), or (4) No world-readable/writable log files detected via find command. This meets STIG SRG-APP-000243-WSR-000146 requirement for log file access control. Organizational security baseline requires all application log files to have permissions ≤640 with root:adm or root:systemd-journal ownership. Quarterly access control audits verify compliance with least privilege principle. Any deviation from baseline permissions triggers automated security alert.</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>The automated check confirmed log file protection. This comment should not normally appear.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Unable to determine log file protection - manual verification required.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check could not conclusively determine if XO log files are properly protected from unauthorized access. Manual verification is required to meet STIG SRG-APP-000243-WSR-000146 compliance.

              Verification procedure:
              (1) Check log file permissions: stat /var/log/xo-server/*.log (should be 640 or 600)
              (2) Check directory permissions: stat /var/log/xo-server (should be drwxr-x--- or more restrictive)
              (3) Verify no world-readable logs: find /var/log/xo-server -type f -perm /o+r
              (4) Verify group ownership: stat -c '%U:%G' /var/log/xo-server/*.log (should be root:adm or xo-server:systemd-journal)
              (5) Test unauthorized access: su - testuser -c "cat /var/log/xo-server/*.log" (should fail)

              Remediation:
              Set proper permissions on log files:
              - chmod 640 /var/log/xo-server/*.log
              - chown root:adm /var/log/xo-server/*.log
              - chmod 750 /var/log/xo-server/
              - Configure logrotate to maintain permissions: edit /etc/logrotate.d/xo-server, add "create 0640 root adm"

              Document findings with stat output, permission verification screenshots, and unauthorized access test results. If systemd journal only (no traditional logs), verify journalctl access control with non-root user test.
        </ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206369">
    <!--RuleTitle: Web server log files must only be accessible by privileged users - log file delete protection.-->
    <AnswerKey Name="XO">
      <!--Session #18 continuation (Jan 25, 2026): Implemented automated check with multi-method log verification.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO log files protected from unauthorized deletion.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra log files are protected from unauthorized deletion through proper file system permissions and ownership controls. The automated check confirmed deletion protection through: (1) Log directory permissions prevent unauthorized file deletion (drwxr-x--- or more restrictive for /var/log/xo-server), (2) Immutable attributes applied to critical log files (lsattr shows +i flag preventing deletion even by root until cleared), (3) File ownership is root:root or xo-server:adm (administrative accounts only), or (4) Sticky bit set on log directory (prevents users from deleting files they don't own). This meets STIG SRG-APP-000118-WSR-000068 requirement for log deletion protection. Organizational log management policy requires privileged account access for log deletion with change request approval. Log retention enforcement through automated backup prevents accidental/malicious deletion. Immutable attributes applied during log rotation for compliance evidence preservation.</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>The automated check confirmed log deletion protection. This comment should not normally appear.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Unable to determine log deletion protection - manual verification required.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check could not conclusively determine if XO log files are protected from unauthorized deletion. Manual verification is required to meet STIG SRG-APP-000118-WSR-000068 compliance.

              Verification procedure:
              (1) Check directory permissions: ls -lad /var/log/xo-server (look for sticky bit: drwxr-x--T)
              (2) Check immutable attributes: lsattr /var/log/xo-server/*.log (look for +i flag)
              (3) Verify ownership: stat -c '%U:%G' /var/log/xo-server (should be root:root or xo-server:adm)
              (4) Test deletion protection: su - testuser -c "rm /var/log/xo-server/test.log" (should fail)
              (5) Check SELinux/AppArmor context: ls -Z /var/log/xo-server/ or aa-status

              Remediation:
              Enable deletion protection:
              - Set sticky bit on directory: chmod +t /var/log/xo-server/
              - Apply immutable attribute to critical logs: chattr +i /var/log/xo-server/xo-server.log
              - Ensure proper ownership: chown -R root:adm /var/log/xo-server/
              - Configure logrotate to preserve immutable: use prerotate script to chattr -i, postrotate to chattr +i

              Document findings with ls -la, lsattr output, ownership verification, and deletion test results. Note: Immutable flag prevents even root deletion until cleared with chattr -i, use with caution.
        </ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206370">
    <!--RuleTitle: Log information from web server must be protected from unauthorized modification or deletion - log file ownership.-->
    <AnswerKey Name="XO">
      <!--Session #18 continuation (Jan 25, 2026): Implemented automated check with multi-method log verification.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO log file ownership properly configured.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra log file ownership is properly configured to prevent unauthorized modification or deletion. The automated check confirmed proper ownership through: (1) Log file ownership via stat shows owner is root or xo-server service account, (2) Group ownership is root, adm, or systemd-journal (administrative groups), (3) Systemd journal directory ownership is systemd-journal:systemd-journal or root:root, (4) No log files owned by unprivileged users or non-administrative groups detected. This meets STIG SRG-APP-000119-WSR-000069 requirement for log ownership controls. Organizational system hardening standards require all security-relevant log files to be owned by root or application service account with group ownership limited to administrative groups (wheel, adm, systemd-journal). Ownership verification performed during monthly security audits. Any ownership deviations remediated immediately per incident response procedures.</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>The automated check confirmed proper log file ownership. This comment should not normally appear.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Unable to determine log file ownership - manual verification required.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check could not conclusively determine if XO log file ownership is properly configured. Manual verification is required to meet STIG SRG-APP-000119-WSR-000069 compliance.

              Verification procedure:
              (1) Check file ownership: stat -c '%U:%G %n' /var/log/xo-server/*
              (2) Expected: root:adm, root:systemd-journal, or xo-server:adm
              (3) Check for incorrect ownership: find /var/log/xo-server -not -user root -not -user xo-server
              (4) Verify group membership: getent group adm systemd-journal
              (5) Check systemd journal: ls -la /var/log/journal/ (should be systemd-journal:systemd-journal)

              Remediation:
              Correct log file ownership:
              - chown -R root:adm /var/log/xo-server/
              - Alternative for systemd-only: chown -R root:systemd-journal /var/log/xo-server/
              - Fix systemd journal: chown -R systemd-journal:systemd-journal /var/log/journal/
              - Configure logrotate to maintain ownership: edit /etc/logrotate.d/xo-server, add "su root adm"

              Document findings with stat output, find results showing ownership issues, and corrective actions taken. Verify ownership persistence after log rotation with "logrotate -f /etc/logrotate.d/xo-server" test.
        </ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206371">
    <!--RuleTitle: Log data and records from web server must be backed up onto different system or media - backup verification.-->
    <AnswerKey Name="XO">
      <!--Session #18 continuation (Jan 25, 2026): Implemented automated check with multi-method log verification.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO log data backed up to different system or media.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra log data is backed up to different system or media to ensure availability and prevent loss due to system failure. The automated check confirmed log backup through one or more methods: (1) rsyslog remote logging configured to forward logs to centralized syslog server (grep '@' /etc/rsyslog.d/), (2) Systemd journal forwarding enabled via journalctl --header Forward= setting, (3) Logrotate external copy configured with postrotate scripts for scp/rsync to backup server, (4) Backup services detected (systemd timers for bacula/duplicity/restic/borg, cron jobs for backup scripts). This meets STIG SRG-APP-000125-WSR-000095 requirement for log backup to different system/media. Organizational backup policy requires real-time log forwarding to SIEM (Splunk/ELK) plus daily incremental backups to network-attached storage with weekly full backups to offline media. Backup verification testing quarterly confirms log restoration capability. Off-site backup retention minimum 1 year for compliance evidence.</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>The automated check confirmed log backup configuration. This comment should not normally appear.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Unable to determine log backup - manual verification required.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check could not conclusively determine if XO logs are backed up to different system or media. Manual verification is required to meet STIG SRG-APP-000125-WSR-000095 compliance.

              Verification procedure:
              (1) Check rsyslog remote logging: grep -r '@' /etc/rsyslog.conf /etc/rsyslog.d/
              (2) Check journald forwarding: journalctl --header | grep Forward
              (3) Check logrotate external copy: grep -r 'postrotate.*scp\|rsync' /etc/logrotate.d/
              (4) Check backup services: systemctl list-timers | grep backup; crontab -l | grep backup
              (5) Verify backup destination: Check SIEM forwarding (Splunk/ELK), NAS backup, tape backup

              Remediation:
              Configure log backup (choose one or more):
              - Remote syslog: Add "*.* @@syslog-server.example.com:514" to /etc/rsyslog.d/50-xo-remote.conf
              - Journald forwarding: Edit /etc/systemd/journald.conf, set ForwardToSyslog=yes
              - Logrotate copy: Add postrotate script: "/usr/bin/rsync /var/log/xo-server/*.gz backup-server:/logs/"
              - Automated backup: Install bacula/duplicity/restic, configure daily backup schedule

              Document findings with rsyslog config, journald config, backup service status, and test backup/restore of recent logs. Verify backup retention meets organizational policy (typically 1 year minimum). Contact backup team to integrate XO logs into enterprise backup strategy.
        </ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206372">
    <!--RuleTitle: All web server files must be verified for their integrity (e.g., checksums and hashes) before becoming part of the production web server.-->
    <AnswerKey Name="XO">
      <!--Session #25 Batch 1: File integrity verification before production deployment-->
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Deployment process includes file integrity verification-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>This organization has implemented file integrity verification procedures for all web server files before production deployment.

              The automated check verified:
              (1) Package manager (dpkg) provides baseline integrity verification for system packages
              (2) Git repository provides commit hash verification for source builds
              (3) NPM package-lock.json provides SHA-512 integrity hashes

              This organization has documented:
              - File integrity verification process in change management procedures
              - Checksum/hash validation for all deployment artifacts
              - Source verification (vendor signatures, Git tags, package signatures)
              - File Integrity Monitoring (FIM) tool deployment [SPECIFY: AIDE/Tripwire/Other]

              Deployment process includes:
              1. Verify checksums for downloaded packages/artifacts
              2. Validate Git commit signatures for source builds
              3. Review npm audit output for known vulnerabilities
              4. Confirm FIM tool (AIDE/Tripwire) configured for production monitoring
              5. Document deployment in change management system

              Finding: Not a Finding

              Justification: Organizational deployment process includes mandatory file integrity verification before production deployment. Checksums/hashes validated per documented procedures. FIM tool configured for ongoing monitoring. This configuration meets NIST SP 800-53r5 CM-3 (Configuration Change Control) and SI-7 (Software, Firmware, and Information Integrity) requirements.

              No additional configuration required for systems with documented deployment procedures.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but deployment process is not documented, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Deployment process not verified - manual documentation required-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check detected package management and source control mechanisms, but cannot automatically verify organizational deployment process includes file integrity verification.

Required Manual Verification:
(1) Document deployment process in security plan
(2) Verify checksums/hashes validated before production deployment
(3) Confirm FIM tool (AIDE/Tripwire) configured if required
(4) Validate Git commit signatures if building from source
(5) Review change management procedures for file integrity checks

Evidence to Collect:
- Deployment process documentation
- Change management procedure including integrity verification steps
- FIM tool configuration (if applicable)
- Example deployment record showing checksum validation
- Security plan section documenting file integrity procedures

Remediation Guidance:
Implement file integrity verification in deployment process:

For Debian/Ubuntu systems:
  1. Install FIM tool:
    apt-get install aide
  2. Initialize database:
    aideinit
  3. Configure /etc/aide/aide.conf
  4. Schedule regular checks via cron

For Git-based deployments:
  1. Enable commit signing:
    git config --global commit.gpgSign true
  2. Verify signatures before deployment:
    git verify-commit &lt;commit-hash&gt;
  3. Document trusted GPG keys

For NPM packages:
  1. Verify package-lock.json present
  2. Run: npm ci (uses lock file, verifies hashes)
  3. Review: npm audit for vulnerabilities

Document all procedures in change management policy.

This check supports NIST SP 800-53r5 CM-3 and SI-7 requirements.
        </ValidTrueComment>
        <ValidFalseStatus>NotAFinding</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but deployment process is verified through documentation review, reference the documentation.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206373">
    <!--RuleTitle: Expansion modules must be fully reviewed, tested, and signed before they can exist on a production web server.-->
    <AnswerKey Name="XO">
      <!--Session #25 Batch 1: Module testing and signing before production-->
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Module review/testing process documented and enforced-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>This organization has implemented module review, testing, and approval procedures for all expansion modules before production deployment.

              The automated check verified:
              (1) XO plugin architecture detected
              (2) NPM package ecosystem provides integrity verification (package-lock.json)
              (3) No unauthorized development/testing indicators on production server

              This organization has documented:
              - Module review process (code review, security scanning)
              - Testing in non-production environment (dev/test/staging)
              - Module approval process before production deployment
              - Change management procedures for module deployments

              Module deployment process includes:
              1. Code review of all module changes
              2. Security scan for known vulnerabilities (npm audit, SAST tools)
              3. Testing in dev/test environment
              4. Approval from change management board
              5. Integrity verification (package-lock.json, checksums)
              6. Documentation in change management system

              Finding: Not a Finding

              Justification: Organizational procedures require all expansion modules to be fully reviewed, tested, and approved before production deployment. No development or testing occurs on production server. NPM package ecosystem provides integrity verification. Module approval process documented in change management procedures. This configuration meets NIST SP 800-53r5 CM-3 (Configuration Change Control), CM-4 (Impact Analyses), and SA-11 (Developer Testing and Evaluation) requirements.

              No additional configuration required for systems with documented module deployment procedures.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but module procedures are not documented, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Module procedures not verified - manual documentation required-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check detected XO plugin architecture and NPM package management, but cannot automatically verify organizational module review and testing procedures.

              Required Manual Verification:
              (1) Document module review and testing process
              (2) Confirm no development/testing on production server
              (3) Verify all plugins fully tested in dev/test environment
              (4) Validate module approval process exists
              (5) Review change management records for module deployments
              (6) Confirm no unapproved or unsigned modules in production

              Evidence to Collect:
              - Module review and testing procedure documentation
              - Change management records showing module approvals
              - Dev/test environment configuration documentation
              - Security scan results (npm audit, SAST output)
              - Production server configuration showing only approved modules

              Remediation Guidance:
              Implement module review and testing process:

              1. Establish non-production environments:
                - Development environment for plugin development
                - Test environment for integration testing
                - Staging environment for pre-production validation

              2. Define approval workflow:
                - Code review by senior developer
                - Security scan (npm audit, Snyk, etc.)
                - Testing in dev/test environments
                - Change management board approval
                - Documented sign-off before production

              3. Enforce integrity verification:
                - Maintain package-lock.json (npm ci for deployments)
                - Verify checksums for custom modules
                - Sign commits (git commit --gpg-sign)

              4. Document in change management:
                - Module name and version
                - Testing results
                - Approval signatures
                - Deployment date/time

              5. Prohibit development on production:
                - Remove development tools from production server
                - Restrict file system write access
                - Monitor for unauthorized changes (AIDE/Tripwire)

              This check supports NIST SP 800-53r5 CM-3, CM-4, and SA-11 requirements.
        </ValidTrueComment>
        <ValidFalseStatus>NotAFinding</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but module procedures are verified through documentation review, reference the procedures.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

    <Vuln ID="V-206374">
    <!--RuleTitle: The web server must not perform user management for hosted applications.-->
    <AnswerKey Name="XO">
      <!--Session #25 Batch 1: User management delegated to Microsoft AD-->
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--User management delegated to enterprise IdP (Microsoft AD)-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>The web server does not perform user management for hosted applications. All user management functions are delegated to Microsoft Active Directory (enterprise IdP).

              The automated check verified:
              (1) Web server (Node.js/Express) serves as HTTP transport layer only
              (2) XO application delegates ALL authentication to Microsoft AD
              (3) External authentication configured (LDAP/AD detected)
              (4) Local database contains only emergency break-glass account (documented exception)

              This organization has confirmed:
              - ALL user management performed via Microsoft Active Directory
              - User provisioning/deprovisioning via AD
              - Password management via AD policies
              - Account lockout via AD policies
              - Multi-factor authentication via AD/ADFS (if applicable)
              - Break-glass account documented as authorized exception

              User management delegation verified:
              - Web server provides HTTP transport only (no user management capabilities)
              - XO application enforces authentication via AD integration
              - No local user creation/modification capabilities enabled
              - Break-glass account justified and documented in security plan
              - Separation of web server and user management functions maintained

              Finding: Not a Finding

              Justification: Web server does not perform user management for hosted applications. All authentication and user management delegated to enterprise Identity Provider (Microsoft Active Directory). Web server serves as HTTP transport layer only. Local database may contain emergency break-glass account (documented authorized exception per security plan). This configuration meets NIST SP 800-53r5 AC-2 (Account Management), IA-2 (Identification and Authentication), and IA-4 (Identifier Management) requirements.

              No additional configuration required for systems with documented AD delegation and break-glass account justification.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but user management delegation is not verified, manual testing is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--User management delegation not verified - manual verification required-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check detected external authentication configuration, but cannot automatically verify web server does not perform user management functions.

Required Manual Verification:
(1) Confirm web server (Node.js/Express) does NOT manage users
(2) Verify ALL user management delegated to Microsoft AD
(3) Confirm break-glass account is documented and justified
(4) Validate no local user creation/modification capabilities
(5) Review authentication configuration for external delegation
(6) Document separation of web server and user management functions

Evidence to Collect:
- XO configuration showing AD integration
- Security plan section documenting break-glass account justification
- Testing results showing no local user management capabilities
- AD administrator confirmation of user lifecycle management
- Documentation of web server role (HTTP transport only)

Testing Procedure:
1. Attempt to create local user via XO interface
   - Verify only AD users can be added
2. Attempt to modify user password
   - Verify redirected to AD password change
3. Disable user in AD
   - Verify XO access immediately revoked
4. Test break-glass account
   - Verify works only when AD unavailable
   - Verify documented in security plan

Remediation (if web server performs user management):
Disable local user management:

XOCE (Community Edition):
  Edit: /opt/xo/xo-server/config.toml

XOA (Appliance):
  Edit: /etc/xo-server/config.toml

Configure ONLY external authentication:
  Remove any [authentication.providers.basic] sections
  Ensure only LDAP/SAML providers configured
  Document break-glass account as authorized exception

Restart XO Server and verify:
- Local user creation disabled
- Only AD users can authenticate
- Break-glass account justified in security plan

This check supports NIST SP 800-53r5 AC-2, IA-2, and IA-4 requirements.</ValidTrueComment>
        <ValidFalseStatus>NotAFinding</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but user management delegation is verified through testing, document the test results.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206376">
    <!--RuleTitle: The web server must not be a proxy server.-->
    <AnswerKey Name="XO">
      <!--Session #25 Batch 2 (Jan 31, 2026): Technical check - proxy server detection-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems not acting as proxy server-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra web server is not configured as a proxy server, meeting DoD requirements to prevent unauthorized proxying of traffic.

The automated check verified:
(1) No forward proxy software installed (Squid, etc.)
(2) Nginx (if present) only reverse proxies to localhost (XO Server)
(3) No proxy ports listening (3128, 8080, 8888)
(4) No Node.js proxy modules detected
(5) XO Server is standalone application server

Finding: Not a Finding

Justification: This configuration meets NIST SP 800-53r5 SC-7 (Boundary Protection) requirements. The web server does not act as a proxy server for external traffic. If nginx is present, it functions solely as a reverse proxy to the local XO Server application on the same host, which is an acceptable architecture pattern.

Web server architecture:
- Primary: Node.js/Express (XO Server application)
- Optional: nginx (reverse proxy to localhost only)
- Proxy functionality: None (verified)

No additional configuration or remediation required.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but proxy functionality is suspected, manual investigation required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant systems with proxy functionality detected-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check detected proxy server functionality that must be removed to comply with DoD requirements.

Finding Details:
The automated check detected one or more of the following:
- Forward proxy software installed (Squid, etc.)
- Nginx configured with proxy_pass to external destinations
- Proxy ports listening (3128, 8080, 8888)
- Node.js proxy modules configured for external proxying

Required Remediation:

(1) Identify proxy software/configuration:
    Review automated check Finding Details for specific items detected

(2) Remove forward proxy software:

    If Squid detected:
      apt-get remove --purge squid squid-common
      apt-get autoremove

    If nginx proxies to external hosts:
      Review nginx configuration:
        nginx -T | grep proxy_pass

      Remove or modify proxy_pass directives pointing to external hosts
      (Keep localhost/127.0.0.1 proxies - acceptable for reverse proxy)

      Restart nginx:
        systemctl restart nginx

(3) Disable proxy ports:

    Check what's listening on proxy ports:
      ss -tlnp | grep -E ':(3128|8080|8888) '

    Stop services listening on proxy ports:
      systemctl stop [service-name]
      systemctl disable [service-name]

(4) Remove Node.js proxy modules (if used for external proxying):

    Check for proxy modules:
      npm list http-proxy express-http-proxy http-proxy-middleware \
        --prefix /opt/xo/xo-src/xen-orchestra/packages/xo-server

    Remove if not needed:
      npm uninstall [module-name] \
        --prefix /opt/xo/xo-src/xen-orchestra/packages/xo-server

(5) Verify proxy functionality removed:

    Check no proxy software:
      which squid nginx
      # Should return nothing or "not found"

    Check no proxy ports:
      ss -tlnp | grep -E ':(3128|8080|8888) '
      # Should return nothing

    Check nginx only proxies to localhost (if present):
      nginx -T | grep proxy_pass
      # Should only show localhost/127.0.0.1 destinations

(6) Document architecture in security plan:
    - Web server role: Application server only
    - Reverse proxy (if applicable): nginx to localhost only
    - No forward proxy functionality

Re-run scan to verify proxy functionality removed.

Note: Reverse proxy to localhost (XO Server on same host) is acceptable. Only forward proxy or proxy to external destinations is prohibited per NIST SP 800-53r5 SC-7.
        </ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but proxy functionality is required for legitimate purpose, document organizational waiver and compensating controls.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206377">
    <!--RuleTitle: The web server must provide install options to exclude the installation of documentation, sample code, example applications, and tutorials.-->
    <AnswerKey Name="XO">
      <!--Session #25 Batch 2 (Jan 31, 2026): Technical check - sample code detection-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with no sample code or web-accessible documentation-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra installation does not include sample code, example applications, tutorials, or web-accessible documentation that could be exploited.

The automated check verified:
(1) No sample/example code directories in production paths
(2) No web-accessible documentation directories
(3) Documentation files (README, LICENSE, CHANGELOG) present but not web-accessible
(4) Test directories (if present) not web-accessible or executable
(5) Minimal installation - no unnecessary components

Finding: Not a Finding

Justification: This configuration meets NIST SP 800-53r5 CM-7 (Least Functionality) requirements. While XO built from source includes development documentation files (README, LICENSE, CHANGELOG), these are:
- Not web-accessible (not in web root directory)
- Not executable (no sample scripts/applications)
- Required for license compliance and system documentation

The critical requirement is met: No sample code or tutorials that could be exploited are web-accessible or executable.

Installation type: Built from source (documentation expected)
Sample code: None detected
Web-accessible docs: None detected

No additional configuration or remediation required.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but sample code is suspected, manual review required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant systems with sample code or web-accessible documentation-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>
The automated check detected sample code, example applications, or web-accessible documentation that must be removed.

Finding Details:
The automated check detected one or more of the following:
- Sample/example code directories
- Web-accessible documentation
- Tutorial applications
- Demo/test applications in production

Required Remediation:

(1) Identify detected items:
    Review automated check Finding Details for specific directories/files

(2) Remove sample/example code directories:

    Common locations to check:
      /opt/xo/examples
      /opt/xo/samples
      /opt/xo/demo
      /opt/xo/tutorials

    Remove if found:
      rm -rf /opt/xo/[directory-name]

(3) Remove web-accessible documentation:

    Check web root directories:
      /var/www/html/docs
      /opt/xo/packages/xo-web/dist/docs
      /usr/share/doc/xo-server

    Remove web-accessible docs:
      rm -rf [web-accessible-doc-path]

    Note: Keep non-web-accessible docs (README, LICENSE in source tree)

(4) Remove tutorial/demo applications:

    Search for demo/tutorial code:
      find /opt/xo -type d -iname '*demo*' -o -iname '*tutorial*' -o -iname '*example*'

    Review each directory to confirm it's sample code
    Remove confirmed sample code:
      rm -rf [sample-code-path]

(5) Verify no sample code web-accessible:

    Check nginx/web server configuration:
      nginx -T | grep -E 'root|alias'

    Ensure no web server paths point to:
      - /examples
      - /samples
      - /demos
      - /tutorials
      - /docs (unless required for production)

(6) Verify removal:

    Re-scan for sample code:
      find /opt/xo -type d \( -iname '*example*' -o -iname '*sample*' -o -iname '*demo*' \) 2&gt;/dev/null

    Check web-accessible paths:
      curl http://localhost/examples
      curl http://localhost/docs
      # Should return 404 Not Found

(7) Document installation in security plan:
    - Installation method: From source
    - Documentation: README/LICENSE retained (not web-accessible)
    - Sample code: Removed
    - Web-accessible docs: Removed

Re-run scan to verify sample code removed.

Note: Documentation files (README, LICENSE, CHANGELOG) in source tree are acceptable if not web-accessible. Only remove sample code, tutorials, and web-accessible documentation per NIST SP 800-53r5 CM-7.
        </ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but detected items are required for production, document justification and ensure not web-accessible.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206378">
    <!--RuleTitle: Ensure only required daemons have network access privileges.-->
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Only required daemons have network access privileges.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>Unexpected network-capable daemons found; manual review required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>Network-capable daemons require administrative action to restrict network privileges.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206375">
    <!--RuleTitle: The web server must only contain services and functions necessary for operation.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Automated default: No unnecessary services detected by the check.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>No unnecessary or unsafe services were detected by the automated service inspection. Review service inventory and confirm organizational baseline if required.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>Automated inspection indicates potentially unnecessary or unsafe services. Manually verify service list, disable or remove unneeded network-facing daemons (telnet/ftp/rsh/etc.), and document remediation.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Manual/alternate: Suspicious services detected and require investigation.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>Potentially unnecessary or unsafe services were detected by the automated check. Perform manual verification: list enabled services (systemctl list-unit-files --state=enabled), enumerate running processes, and confirm whether each service is required for XO operation. Remove or disable services not required.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index is used when the automated check did not find suspicious services. If this appears, validate the service inventory and confirm ExpectedStatus mapping.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206379">
    <!--RuleTitle: The web server must provide install options to exclude installation of utility programs, services, plug-ins, and modules not necessary for operation.-->
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Not a Finding - All automated checks pass-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Web server installation meets minimal configuration requirements. Automated validation confirms: 

(1) Minimal package installation (5 or fewer non-essential packages), 

(2) All running services validated against organizational whitelist, 

(3) No prohibited desktop/development software detected. 

Organization maintains installation documentation per [INSERT POLICY REFERENCE] including: package inventory with operational justification, installation procedures that exclude non-essential software, removal procedures in change management system, quarterly software baseline reviews. 

XO installation (XOCE from-sources or XOA appliance) contains only software necessary for operation. This configuration demonstrates compliance with STIG installation minimization requirements. 

ISSO/ISSM review completed [INSERT DATE].</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>Automated checks show compliance, but organizational documentation incomplete. Organization must document: installation procedures, package justification, removal processes, and baseline reviews per policy requirements.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Open finding - Prohibited software or unauthorized services detected, OR unable to validate-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>Installation minimization violation detected. Prohibited desktop/development software or unauthorized services found on web server. Immediate remediation required: 

(1) Inventory all detected prohibited packages and unauthorized services, 

(2) Remove packages not required for XO operation: 'apt-get purge [package]', 

(3) Disable unauthorized services: 'systemctl disable [service]', 

(4) Document removal in change management system, 

(5) Re-scan to validate remediation. 

POA&amp;M item [INSERT POA&amp;M NUMBER] tracks remediation. 
ISSO/ISSM notified. 

Target completion: [INSERT DATE - URGENT].</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>Unable to fully validate installation minimization. Manual review required: 

(1) Complete package inventory with justification, 

(2) Service whitelist validation, 

(3) Installation procedure documentation, 

(4) Uninstall facility verification. Document findings in system security plan.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206380">
    <!--RuleTitle: The web server must have Multipurpose Internet Mail Extensions (MIME) that invoke OS shell programs disabled.-->
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Not a Finding - No shell-invoking MIME types configured-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Web server configured without MIME types that invoke OS shell programs. Nginx MIME configuration reviewed and contains only standard web content types (HTML, CSS, JavaScript, images, fonts). Dangerous MIME types (application/x-sh, application/x-shellscript, application/x-executable) are not configured in /etc/nginx/mime.types or virtual host configurations. XO Server application uses Node.js/Express framework with controlled MIME handling that does not permit shell invocation. Organization verifies: (1) Nginx mime.types file restricted to web content only, (2) No CGI/shell script handlers configured, (3) Regular review of MIME configuration in change management process. This configuration meets STIG requirements for preventing OS shell access via MIME types.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>Shell-invoking MIME types detected in web server configuration. This creates security risk by potentially allowing users to execute OS shell commands. Organization must: (1) Remove all dangerous MIME types from nginx configuration (application/x-sh, application/x-shellscript, application/x-perl, application/x-python, text/x-script, application/x-executable), (2) Restart nginx service to apply changes, (3) Validate removal via configuration review and re-scan, (4) Document changes in change management system. POA&amp;M item required. Target completion: [INSERT DATE].</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Open finding - Shell-invoking MIME types present-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>Dangerous shell-invoking MIME types detected in nginx configuration files. Immediate remediation required: Edit /etc/nginx/mime.types and remove entries for application/x-sh, application/x-shellscript, application/x-perl, application/x-python, application/x-executable, text/x-script. Execute 'nginx -t' to validate configuration, then 'systemctl reload nginx'. Document changes in change management ticket. Re-scan to verify removal. ISSO/ISSM notified. POA&amp;M [INSERT POA&amp;M NUMBER]. Target completion: [INSERT DATE - URGENT].</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>Manual review required to verify all MIME type configurations and ensure no shell invocation capability exists.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206381">
    <!--RuleTitle: The web server must allow the mappings to unused and vulnerable scripts to be removed.-->
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Not a Finding - No unnecessary script mappings-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Web server contains no script mappings beyond those required for Xen Orchestra operation. Nginx configuration reviewed and shows no CGI, PHP-FPM, Perl, or Python script handlers. XO Server is Node.js-based application using Express.js routing framework which does not use external script mappings. All application routing defined in JavaScript code, not CGI scripts. Organization verifies: (1) No fastcgi_pass, scgi_pass, or uwsgi_pass directives in nginx config, (2) No PHP, Perl, or Python CGI modules installed, (3) No cgi-bin directories present, (4) Script removal procedures documented in change management process. This architecture meets STIG requirements - XO does not use vulnerable script mapping technologies.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>Unnecessary or vulnerable script mappings detected on web server. Found CGI handlers, PHP-FPM, or legacy script directories not required for XO operation. Organization must: (1) Document all detected script handlers and mappings, (2) Remove unnecessary packages (php-fpm, libcgi-pm-perl, python-cgi), (3) Delete cgi-bin directories, (4) Remove script handler directives from nginx configuration, (5) Restart web services, (6) Validate removal via re-scan. POA&amp;M item required. Target completion: [INSERT DATE].</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Open finding - Unnecessary script handlers detected-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>Script handlers or CGI infrastructure detected that are not required for Xen Orchestra operation. Immediate remediation: (1) Remove script handler packages: apt-get purge php*-fpm libcgi-pm-perl python*-cgi, (2) Remove cgi-bin directories, (3) Remove script mapping directives from nginx config files, (4) Execute nginx -t to validate, then systemctl reload nginx, (5) Document in change management system. Re-scan to verify. ISSO/ISSM notified. POA&amp;M [INSERT POA&amp;M NUMBER]. Target completion: [INSERT DATE - HIGH PRIORITY].</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>Manual review required to validate all script mappings are necessary and properly secured.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206382">
    <!--RuleTitle: The web server must have resource mappings set to disable the serving of certain file types.-->
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Not a Finding - Sensitive file types blocked-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Web server configured to block serving of sensitive file types. Nginx location blocks configured with 'deny all' rules for configuration files (.conf, .config, .toml, .env), log files (.log), backup files (.bak, .backup, .old, .swp, .tmp), scripts (.sh, .bash, .py, .pl), and certificates/keys (.key, .pem, .crt, .p12). Sensitive files stored outside web-accessible directories (/var/log, /etc, /opt/xo/xo-server/config.toml not in web root). Organization maintains resource mapping documentation showing: (1) Only legitimate XO file types served (JS, HTML, CSS, JSON, images, fonts), (2) Nginx configuration tested to prevent access to config/log/backup files, (3) Regular security testing includes attempts to access sensitive file types, (4) Configuration changes reviewed in change management process. This configuration meets STIG requirements for file type serving restrictions.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>Configuration or sensitive files are accessible via web server. Resource mappings do not properly restrict serving of dangerous file types. Organization must: (1) Add nginx location blocks to deny access to sensitive file extensions, (2) Move config, log, and backup files outside web root, (3) Implement 'deny all' rules for prohibited file patterns, (4) Test access restrictions using web browser and curl, (5) Document approved file type whitelist. POA&amp;M item required. Target completion: [INSERT DATE - HIGH PRIORITY due to information disclosure risk].</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Open finding - Sensitive files accessible-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>Sensitive configuration or backup files detected in web-accessible directories. Immediate remediation required: (1) Move all .conf, .toml, .env, .log, .bak files outside web root, (2) Add nginx location blocks: 'location ~* \.(conf|config|toml|env|log|bak|backup|old|swp|tmp|sh|bash|key|pem)$ { deny all; }', (3) Execute nginx -t to validate, then systemctl reload nginx, (4) Test restrictions: curl -I https://[server]/.env should return 403/404, (5) Document in change management. Re-scan to verify. ISSO/ISSM notified of information disclosure risk. POA&amp;M [INSERT POA&amp;M NUMBER]. Target completion: [INSERT DATE - URGENT].</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>Manual review required to verify resource mappings and file type serving restrictions.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206383">
    <!--RuleTitle: The web server must have Web Distributed Authoring (WebDAV) disabled.-->
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Not a Finding - WebDAV disabled-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Web Distributed Authoring (WebDAV) is disabled on the web server. Nginx not compiled with http_dav_module, verified via 'nginx -V' output. No WebDAV configuration directives (dav_methods, dav_access, create_full_put_put_path) present in nginx configuration. WebDAV HTTP methods (PUT, DELETE, MKCOL, COPY, MOVE, PROPFIND, PROPPATCH, LOCK, UNLOCK) are not explicitly allowed. Xen Orchestra application does not use or require WebDAV functionality - all file operations use XO REST API and XenAPI. Organization verifies: (1) No WebDAV client/server packages installed (davfs2, cadaver), (2) HTTP method restrictions limit to GET, POST, HEAD only, (3) Security testing confirms WebDAV methods return 405 Method Not Allowed, (4) Configuration changes reviewed in change management. This configuration meets STIG requirements - WebDAV disabled at all layers.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>WebDAV is enabled or WebDAV HTTP methods are permitted. This creates security risk of unauthorized file modifications. Organization must: (1) If nginx compiled with http_dav_module, rebuild without it or disable via configuration, (2) Remove all dav_methods directives from nginx config, (3) Implement HTTP method restrictions: 'limit_except GET POST HEAD { deny all; }', (4) Remove WebDAV packages: apt-get purge davfs2 cadaver, (5) Restart nginx service, (6) Test that PUT, DELETE, PROPFIND methods return 405 error. POA&amp;M item required. Target completion: [INSERT DATE - HIGH PRIORITY].</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Open finding - WebDAV enabled or methods allowed-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>WebDAV functionality detected on web server. Immediate remediation required: (1) Edit nginx config files and remove all 'dav_methods', 'dav_access', 'create_full_put_path' directives, (2) Add to server block: 'limit_except GET POST HEAD { deny all; }', (3) Verify nginx compiled without WebDAV: nginx -V | grep dav_module (should return nothing), (4) If WebDAV module present, plan nginx rebuild or implement compensating controls, (5) Execute nginx -t to validate, then systemctl reload nginx, (6) Test with curl -X PROPFIND (should return 405), (7) Document in change management. Re-scan to verify. ISSO/ISSM notified. POA&amp;M [INSERT POA&amp;M NUMBER]. Target completion: [INSERT DATE - URGENT].</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>Manual review required to verify WebDAV is completely disabled at all layers (module, config, HTTP methods).</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206384">
    <!--RuleTitle: The web server must protect system resources and privileged operations from hosted applications.-->
    <AnswerKey Name="XO">
      <!--Session #26 (Jan 31, 2026): Organizational policy check for application isolation-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with documented application isolation controls-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra web server implements comprehensive application isolation controls to protect system resources and privileged operations from hosted applications.

The automated check verified the following isolation layers:
(1) VM/Container isolation: XO deployed in isolated environment
(2) Linux namespace separation: Process, network, and filesystem isolation detected
(3) Resource limits: Systemd/cgroup controls prevent resource exhaustion
(4) Privilege separation: XO runs as unprivileged service account (not root)
(5) Mandatory Access Control: AppArmor/SELinux enforces access restrictions

Finding: Not a Finding

Justification: This organization has implemented defense-in-depth application isolation per NIST SP 800-53r5 SC-2 (Application Partitioning) and SC-39 (Process Isolation). The system architecture documentation describes isolation boundaries, and security scans confirm controls are effective.

Organizational documentation includes:
- Security architecture diagrams showing isolation layers
- System security plan describing resource protection controls
- Vulnerability assessment results confirming isolation effectiveness

No additional configuration or remediation required for systems with documented and implemented application isolation controls.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but organizational isolation policy is not documented, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant or undocumented systems requiring application isolation verification-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check detected application isolation infrastructure but cannot verify organizational policy compliance.

Required Manual Verification:
(1) CONTAINER/VM ISOLATION:
    - Verify XO runs in isolated VM or container environment
    - Confirm no shared hosting with untrusted applications
    - Review hypervisor isolation controls (if VM deployment)

(2) NAMESPACE ISOLATION:
    - Verify process, network, and filesystem namespace separation
    - Confirm XO cannot access host system resources directly

(3) RESOURCE LIMITS:
    - Verify CPU/memory/file descriptor limits prevent resource exhaustion
    - Confirm cgroup controls protect host system
    - Review systemd service unit files

(4) PRIVILEGE SEPARATION:
    - Verify XO runs as unprivileged user (not root)
    - Confirm no unnecessary sudo/setuid capabilities
    - Review capability grants (getcap /usr/bin/node)

(5) MANDATORY ACCESS CONTROL:
    - Verify AppArmor/SELinux enforces access restrictions
    - Review MAC policy for XO server process

(6) ORGANIZATIONAL DOCUMENTATION:
    - Security architecture diagrams showing isolation boundaries
    - System security plan describing resource protection controls
    - Configuration management database (CMDB) entries

REMEDIATION:
- Document application isolation architecture in security plan
- Implement missing isolation controls (container, namespace, MAC)
- Configure resource limits in systemd service files
- Enable and configure AppArmor profiles for XO/Node.js
- Conduct vulnerability assessment to verify isolation effectiveness

This finding requires ISSO/ISSM review and documentation of organizational application isolation policy.
        </ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206385">
    <!--RuleTitle: Users and scripts running on behalf of users must be contained to the document root or home directory tree of the web server.-->
    <AnswerKey Name="XO">
      <!--Session #26 (Jan 31, 2026): Organizational policy check for user containment-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with documented user containment controls-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra implements user and script containment controls to restrict file system access to the web server document root and authorized directories.

The automated check verified the following containment mechanisms:
(1) Document root isolation: XO files restricted to /opt/xo, /etc/xo-server, /var/lib/xo-server
(2) File permissions: No world-writable files detected in XO directories
(3) Chroot jail: Process containment verified (if applicable)
(4) Symlink protection: Kernel parameters prevent symlink/hardlink attacks (fs.protected_symlinks=1)
(5) User account restrictions: XO service account has no login shell, restricted home directory

Finding: Not a Finding

Justification: This organization has implemented user containment controls per NIST SP 800-53r5 SC-2 (Application Partitioning) and AC-6 (Least Privilege). The system configuration restricts users and scripts to authorized directories, preventing directory traversal and unauthorized file access. Security architecture documentation describes containment boundaries.

Organizational documentation includes:
- Filesystem permission audit results
- User account and privilege documentation
- Security plan describing containment controls
- Code review results for path traversal vulnerabilities

No additional configuration or remediation required for systems with documented and implemented user containment controls.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but organizational containment policy is not documented, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant or undocumented systems requiring user containment verification-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check detected user containment infrastructure but cannot verify organizational policy compliance.

Required Manual Verification:
(1) DOCUMENT ROOT CONTAINMENT:
    - Verify XO application files are isolated to /opt/xo, /etc/xo-server, /var/lib/xo-server
    - Confirm no application code or data outside document root
    - Review file ownership (should be root:root or xo-server:xo-server)

(2) USER CONTAINMENT:
    - Verify XO service account has no login shell (/sbin/nologin or /bin/false)
    - Confirm home directory is within XO installation path
    - Review user's file access permissions (no access to /etc/shadow, /root, etc.)

(3) CHROOT JAIL:
    - Verify XO process runs in chroot jail (if organization requires)
    - Confirm jail includes only necessary files (libraries, configs)
    - Review jail configuration for escape vulnerabilities

(4) SYMLINK/HARDLINK PROTECTION:
    - Verify kernel parameters prevent symlink/hardlink attacks
    - Confirm no suspicious symlinks in XO directories (find -type l)
    - Review /etc/sysctl.conf for fs.protected_symlinks=1

(5) PATH TRAVERSAL PROTECTIONS:
    - Verify XO code validates user-supplied file paths
    - Confirm no directory traversal vulnerabilities (../, ../../, etc.)
    - Review application code for path.join() and path.normalize() usage

(6) ORGANIZATIONAL DOCUMENTATION:
    - User containment policy and procedures
    - Security architecture diagrams showing user/application boundaries
    - Code review results for path traversal vulnerabilities

REMEDIATION:
- Configure XO service account with /sbin/nologin shell
- Set proper file permissions (chmod 755 directories, chmod 644 files)
- Enable kernel symlink protection (sysctl -w fs.protected_symlinks=1)
- Implement chroot jail if required by organizational policy
- Conduct code review for path traversal vulnerabilities
- Document containment controls in security plan

This finding requires ISSO/ISSM review and documentation of organizational user containment policy.
        </ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206386">
    <!--RuleTitle: The web server must be configured to use a specified IP address and port.-->
    <AnswerKey Name="XO">
      <!--Session #17 (Jan 24, 2026): Implemented automated check with static/dynamic IP detection. DHCP-aware guidance. Checks config.toml, Nginx config, and active network listeners.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO is configured to listen on a specific IP address (not all interfaces).-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra web server is configured to listen on a specified IP address and port, not on all available interfaces (0.0.0.0 or ::). The automated check verified one or more of the following: (1) config.toml contains explicit http.listen directive with specific IP address, (2) Nginx reverse proxy is configured with specific listen address, or (3) Active network listeners show XO bound to specific IP, not 0.0.0.0/::/*. This configuration prevents unintended access via management or secondary network interfaces. STIG SRG-APP-000142-WSR-000089 requirement is satisfied. Technical basis: Binding to specific IP addresses restricts which network interfaces can accept connections, implementing defense-in-depth network segmentation.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>The automated check found that XO may not be listening on a specific IP address. Review the Finding Details field for diagnostic information, then verify: (1) Check /opt/xo/xo-server/.config/xo-server/config.toml for http.listen directive, (2) Run 'ss -tlnp | grep xo-server' to see active listeners, (3) Ensure XO is NOT listening on 0.0.0.0 or :: (all interfaces). If listening on all interfaces, configure a specific IP in config.toml: [http] \n listen = 'SPECIFIC_IP:PORT'. If this system uses DHCP, see Finding Details for dynamic IP configuration options. If XO is behind a reverse proxy (Nginx), verify the proxy binds to specific IP and XO listens only on localhost (127.0.0.1).</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO is listening on all interfaces (0.0.0.0 or ::) - finding detected.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check found that XO web server is listening on all available IP addresses (0.0.0.0, ::, or *:PORT). This violates STIG SRG-APP-000142-WSR-000089 which requires the web server to be configured to use a specified IP address and port. Listening on all interfaces allows access via any network interface (production, management, backup networks, etc.), which may enable unauthorized access paths. 

Remediation steps: 

(1) Determine if this system uses DHCP (ip -4 addr show | grep dynamic). 

(2a) For STATIC IP systems: Edit /opt/xo/xo-server/.config/xo-server/config.toml and add '[http] \n listen = "SPECIFIC_IP:PORT"' (e.g., 10.0.10.50:80). 

(2b) For DHCP systems: Either bind to localhost if behind reverse proxy '[http] \n listen = "127.0.0.1:80"', OR use interface-based binding that updates with DHCP renewal. 

(3) Restart xo-server: systemctl restart xo-server. 
(4) Verify with 'ss -tlnp | grep xo-server' - should NOT show 0.0.0.0 or ::. 

This finding requires configuration changes to meet STIG compliance.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206387">
    <!--RuleTitle: The web server must encrypt passwords during transmission.-->
    <AnswerKey Name="XO">
      <!--Session #26 (Jan 31, 2026): Technical check for password encryption during transmission-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with HTTPS/TLS encryption configured-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra web server encrypts all passwords during transmission using TLS/HTTPS encryption.

The automated check verified the following:
(1) HTTPS/TLS configured and active (TLS 1.2+ protocols)
(2) HTTP to HTTPS redirect enabled (no plaintext credential exposure)
(3) HSTS header present (Strict-Transport-Security enforces HTTPS for future connections)
(4) No plain HTTP authentication endpoints (all credentials transmitted over encrypted channels)

Finding: Not a Finding

Justification: This system implements password encryption during transmission per NIST SP 800-53r5 SC-8 (Transmission Confidentiality and Integrity) and IA-5 (Authenticator Management). All authentication credentials are protected by FIPS 140-2 approved TLS encryption algorithms. Configuration prevents password transmission over unencrypted HTTP connections.

Technical evidence:
- TLS 1.2+ active on HTTPS port
- HTTP listeners redirect to HTTPS (301/302 status)
- HSTS header enforces HTTPS for future connections
- OpenSSL s_client verification successful

No additional configuration or remediation required for systems with HTTPS/TLS properly configured.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but HTTPS is not properly configured, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant systems with HTTPS/TLS issues-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check detected password encryption issues that violate STIG requirements.

Issues Detected:
(1) HTTPS/TLS not configured or not active
(2) HTTP listener present without HTTPS redirect (password exposure risk)
(3) No HSTS header (allows downgrade attacks)
(4) Plaintext authentication endpoints accessible

Required Remediation:
(1) Configure HTTPS/TLS in XO config.toml:
    [http]
    cert = '/path/to/certificate.crt'
    key = '/path/to/private.key'
    redirectToHttps = true

(2) Ensure HTTP listeners redirect to HTTPS:
    - Edit config.toml: redirectToHttps = true
    - Verify with: curl -I http://localhost (should return 301/302 to https://)

(3) Enable HSTS header (Strict-Transport-Security: max-age=31536000):
    - Configure in Nginx reverse proxy or XO config
    - Prevents SSL stripping and downgrade attacks

(4) Verify TLS 1.2+ protocols only:
    - Disable TLS 1.0/1.1 (deprecated and vulnerable)
    - Test with: openssl s_client -connect localhost:443 -tls1_2

(5) Test authentication endpoints:
    - Verify all login pages accessible only via HTTPS
    - Confirm no plaintext password transmission

DoD Requirement: All passwords MUST be encrypted during transmission using FIPS 140-2 approved algorithms per NIST SP 800-53r5 SC-8 and IA-5.

This finding requires immediate remediation to prevent password exposure.
        </ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206388">
    <!--RuleTitle: The web server must perform RFC 5280-compliant certification path validation.-->
    <AnswerKey Name="XO">
      <!--Session #26 (Jan 31, 2026): Mixed technical/policy check for RFC 5280 and DoD PKI compliance-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with RFC 5280 and DoD PKI certificates-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra web server performs RFC 5280-compliant certification path validation and uses DoD PKI certificates.

The automated check verified the following RFC 5280 technical compliance:
(1) Valid SSL/TLS certificate present and not expired
(2) Certificate chain validation successful (full path to trusted root CA)
(3) Certificate extensions present (keyUsage, extendedKeyUsage, subjectAltName)
(4) CRL Distribution Points and OCSP responder URIs configured for revocation checking

DoD PKI compliance verified by ISSO/ISSM review:
- Certificate issued by DoD PKI Certificate Authority
- Certificate issuer in DoD Trusted Root CA list
- Certificate policy OIDs match DoD requirements
- ECA (External Certificate Authority) or DoD Root CA signature verified
- Full certificate chain includes DoD intermediate and root CAs
- Certificate revocation checking enabled and functional

Finding: Not a Finding

Justification: This system implements RFC 5280 certification path validation per NIST SP 800-53r5 SC-17 (Public Key Infrastructure Certificates) and IA-5(2) (PKI-Based Authentication). The certificate was obtained from DoD PKI and meets all DoD requirements for certificate-based authentication and encryption. Annual certificate review documented per organizational procedures.

Organizational documentation includes:
- Certificate request and approval from DoD PKI
- DoD PKI sponsor authorization
- Certificate installation and renewal procedures
- Annual certificate inventory and review records

No additional configuration or remediation required for systems with DoD PKI certificates and documented RFC 5280 compliance.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but DoD PKI compliance is not verified, manual review is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant systems requiring DoD PKI certificate compliance verification-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check detected certificate issues or cannot verify DoD PKI compliance.

RFC 5280 Technical Compliance (Automated Checks):
- Certificate validation and expiry check performed
- Certificate chain validation attempted
- Certificate extensions analyzed
- Revocation checking (CRL/OCSP) availability verified

Required Manual Verification for DoD PKI Compliance:
(1) DoD PKI CERTIFICATE REQUIREMENT:
    - Verify certificate is issued by DoD PKI Certificate Authority
    - Confirm certificate issuer is in DoD Trusted Root CA list
    - Review certificate policy OIDs for DoD compliance
    - Verify ECA (External Certificate Authority) or DoD Root CA signature

(2) CERTIFICATE REVOCATION CHECKING:
    - Verify CRL (Certificate Revocation List) is accessible and current
    - Confirm OCSP (Online Certificate Status Protocol) is enabled
    - Test revocation checking with expired/revoked test certificate
    - Review Node.js TLS configuration for revocation enforcement

(3) CERTIFICATE PATH VALIDATION:
    - Verify full chain validation to DoD root CA
    - Confirm intermediate CA certificates are present
    - Review certificate chain order (leaf → intermediate → root)
    - Verify no untrusted or expired CAs in chain

(4) RFC 5280 COMPLIANCE:
    - Verify required X.509v3 extensions present (keyUsage, extendedKeyUsage)
    - Confirm subjectAltName includes FQDN
    - Review certificate constraints (basicConstraints, nameConstraints)
    - Verify signature algorithm is FIPS 140-2 approved (SHA-256+)

(5) ORGANIZATIONAL DOCUMENTATION:
    - Certificate request and approval records
    - DoD PKI sponsor documentation
    - Certificate installation and renewal procedures
    - Annual certificate inventory and review records

REMEDIATION:
- Obtain certificate from DoD PKI (https://public.cyber.mil/pki-pke/)
- Install full certificate chain (leaf + intermediate + DoD root CA)
- Configure Node.js TLS with CA bundle: tls.ca = [ca-bundle.pem]
- Enable OCSP/CRL checking in TLS configuration
- Document DoD PKI sponsor and approval process
- Schedule annual certificate review

NON-COMPLIANCE RISK:
Use of non-DoD PKI certificates in DoD environments violates DISA requirements and prevents integration with DoD certificate-based authentication systems (CAC/PIV).

This finding requires ISSO/ISSM review for DoD PKI compliance verification and remediation.
        </ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206389">
    <!--RuleTitle: Only authenticated system administrators or the designated PKI Sponsor for the web server must have access to the web servers private key.-->
    <AnswerKey Name="XO">
      <!--Session #26 (Jan 31, 2026) - REVISED: Fixed search paths and status logic per user feedback-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with correct private key permissions (600/root:root)-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra web server's private key is properly protected with restricted file permissions and ownership.

The automated check verified the following:
(1) Private key file(s) found with correct permissions (600 or 400)
(2) File ownership is root or authorized service account (xo-server)
(3) No world-readable or group-readable access detected
(4) Private key stored in secure system location (/etc/ssl/ for XOA, /opt/xo/ for XOCE)
(5) No world-readable private keys found in system directories

Finding: Not a Finding

Justification: This system implements private key access restrictions per NIST SP 800-53r5 SC-17 (Public Key Infrastructure Certificates) and IA-5(2) (PKI-Based Authentication). File permissions prevent unauthorized access to cryptographic private keys. Only root and authorized system administrators (via sudo) can access the private key file. PKI Sponsor authorization is documented in organizational procedures.

Technical evidence:
- Private key permissions: 600 (owner read/write only) or 400 (owner read only)
- File ownership: root:root or xo-server:xo-server
- No group or world access
- Secure storage location verified (XOA: /etc/ssl/, XOCE: /opt/xo/)

Organizational documentation includes:
- PKI Sponsor authorization for key access
- Private key installation and renewal procedures
- System administrator authorization matrix

No additional configuration or remediation required for systems with properly protected private keys.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but private key permissions are incorrect, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant systems with private key access control issues-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check detected private key access control issues that violate STIG requirements.

Issues Detected:
(1) Private key file permissions too permissive (not 600 or 400)
(2) File ownership not restricted to authorized accounts
(3) Keys not stored in secure system location
(4) World-readable or group-readable access detected

Required Remediation:
(1) Set private key permissions to 600 (owner read/write only):
    chmod 600 /path/to/private.key

(2) Set private key ownership to root:
    chown root:root /path/to/private.key

(3) Move keys to secure location:
    - XOA: /etc/ssl/private or /etc/ssl/
    - XOCE: /opt/xo/ (with proper permissions)
    - Ensure parent directory also has restricted permissions (700 or 755)

(4) Verify no group or world access:
    ls -l /path/to/private.key
    (Should show: -rw------- 1 root root)

(5) Check for world-readable private keys:
    find /etc/ssl /opt/xo /etc/xo-server -type f -name '*.key' -perm -004

(6) Consider key encryption:
    - Encrypt private key with passphrase (additional protection)
    - Document passphrase management procedures

(7) Document PKI Sponsor authorization:
    - Identify authorized PKI Sponsor
    - Document approval for system administrators to access private key
    - Maintain access control matrix

DoD Requirement: Private keys must be protected from unauthorized access per NIST SP 800-53r5 IA-5(2). Compromise of private key enables man-in-the-middle attacks and impersonation.

WARNING: If world-readable private keys were detected, this is a CRITICAL VULNERABILITY requiring immediate remediation. Unauthorized access to private keys compromises all TLS/SSL encryption for the web server.

This finding requires immediate remediation to protect cryptographic private keys.
        </ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
      <Answer Index="3" ExpectedStatus="NA" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Systems with no private key detected (HTTP only, HSM/key vault, or reverse proxy)-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NA</ValidTrueStatus>
        <ValidTrueComment>The automated check determined this requirement is Not Applicable because no private key files were detected on the XO server.

Per STIG Check_Content: "If the web server does not have a private key, this is N/A."

Comprehensive search completed:
- XO configuration files (/opt/xo/xo-server/config.toml, /etc/xo-server/config.toml)
- XOA standard location (/etc/ssl/, /etc/ssl/private)
- XOCE standard location (/opt/xo/)
- Additional locations (/etc/xo-server/, /etc/pki/tls/private)

Possible compliant scenarios:
(1) XO configured without TLS/SSL (HTTP only) - acceptable for isolated management networks
(2) TLS termination handled by reverse proxy (nginx) - private key on proxy server, not XO
(3) Keys stored in external HSM or key vault - compliant DoD PKI key management

If XO uses HTTPS (V-206387 = NotAFinding), verify with system administrator:
- Reverse proxy configuration (nginx handles TLS termination)
- External key management system (HSM, key vault, cloud KMS)
- Document architecture in security plan

Finding: Not Applicable - No private key present on web server

No remediation required for systems where private keys are managed externally or TLS is terminated at reverse proxy.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206390">
    <!--RuleTitle: The web server must use cryptographic modules that meet the requirements of applicable federal laws, Executive Orders, directives, policies, regulations, standards, and guidance when encrypting stored data.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Index created by Evaluate-STIG_GUI.ps1
ValidationCode removed - technical validation now in scan module Get-V206390
Answer file provides only organizational justification comments-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>System does not meet FIPS 140-2 cryptographic module requirements mandated by organizational security policy. DoD systems handling classified or sensitive information must utilize FIPS-validated cryptographic modules per NIST SP 800-53 SC-13 and CNSSI 1253. Technical assessment indicates remediation required for kernel FIPS mode, OpenSSL configuration, and Node.js cryptographic operations. Interim operational risk has been formally accepted by AO pending scheduled system maintenance window for FIPS enablement. Compensating controls include network segmentation and enhanced monitoring. Target remediation date documented in POA&amp;M.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This system has been configured to use FIPS 140-2 validated cryptographic modules for all encryption operations per organizational security policy and operational requirements. Kernel-level FIPS mode enablement, OpenSSL FIPS module configuration, Node.js FIPS enforcement, and nginx cipher suite restrictions have been implemented and verified. All cryptographic modules are validated against NIST CMVP standards per DoD policy requirements. System configuration documented and maintained in accordance with organizational change management procedures.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206391">
    <!--RuleTitle: The web server must use cryptographic modules that meet the requirements of applicable federal laws, Executive Orders, directives, policies, regulations, standards, and guidance for such authentication.-->
    <AnswerKey Name="XO">
      <!--Session #27 (Jan 31, 2026): FIPS cryptographic modules for authentication-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with FIPS-validated authentication modules-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra authentication uses FIPS 140-2 validated cryptographic modules.

The automated check verified FIPS compliance for authentication:
(1) OpenSSL FIPS mode enabled (system-wide cryptographic operations)
(2) Node.js running with -force-fips flag
(3) LDAP/SAML integration with DoD authentication servers (FIPS-compliant)
(4) TLS client certificate authentication using FIPS-approved algorithms
(5) Password hashing uses approved algorithms or external authentication only

Finding: Not a Finding

Justification: This system implements FIPS 140-2 validated cryptographic modules for all authentication operations per NIST SP 800-53r5 IA-7 (Cryptographic Module Authentication). The organization has configured XO to use external LDAP/SAML authentication with DoD Active Directory (FIPS-compliant), enabled OpenSSL FIPS mode, and configured Node.js with FIPS enforcement. Local password authentication has been disabled in favor of centralized FIPS-validated authentication.

Technical evidence:
- OpenSSL FIPS module active
- Node.js -force-fips flag verified
- LDAP/SAML authentication to DoD PKI-compliant servers
- TLS client certificate authentication using FIPS ciphers

Organizational documentation:
- DoD Active Directory integration documentation
- FIPS compliance validation records
- Authentication architecture diagrams
- Security plan describing cryptographic module requirements

No additional configuration required for systems with FIPS-validated authentication modules.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but FIPS compliance is not verified, manual review is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant systems requiring FIPS authentication configuration-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check detected that FIPS 140-2 validated cryptographic modules are not configured for authentication operations.

Required Manual Verification:
(1) EXTERNAL AUTHENTICATION (LDAP/SAML):
    - Integrate XO with DoD Active Directory or FIPS-compliant LDAP server
    - Verify LDAP/SAML server uses FIPS 140-2 validated modules
    - Confirm TLS connection to auth server uses FIPS-approved ciphers
    - Document DoD authentication integration (CAC/PIV cards)

(2) TLS CLIENT CERTIFICATE AUTHENTICATION:
    - Enable TLS client certificate requirement in XO config
    - Configure OpenSSL FIPS mode for certificate validation
    - Use DoD PKI certificates for client authentication
    - Verify certificate path validation uses FIPS algorithms

(3) PASSWORD HASHING:
    - Note: bcrypt (XO default) is NOT FIPS 140-2 validated
    - Recommendation: Disable local authentication, use LDAP/SAML only
    - Alternative: Request ISSO waiver for bcrypt (industry standard, cryptographically secure)
    - Document justification in security plan

(4) NODE.JS FIPS MODE:
    - Enable Node.js FIPS mode: node -force-fips /opt/xo/xo-server/dist/cli.mjs
    - Update systemd service file (/etc/systemd/system/xo-server.service)
    - Add -force-fips to ExecStart command
    - Reload systemd and restart xo-server: systemctl daemon-reload &amp;&amp; systemctl restart xo-server

(5) OPENSSL FIPS MODE:
    - Enable system-wide OpenSSL FIPS mode
    - Install FIPS module: apt-get install openssl-fips (if available)
    - Configure /etc/ssl/fips_mode_enable
    - Verify: openssl version and openssl list -fips-module

REMEDIATION STEPS:
1. Integrate XO with DoD Active Directory (LDAP):
   - Configure LDAP authentication in /etc/xo-server/config.toml
   - Test authentication with DoD credentials
   - Disable local username/password authentication

2. Enable OpenSSL and Node.js FIPS modes:
   - System-wide: Enable OpenSSL FIPS module
   - Application: Add -force-fips to xo-server startup

3. Document FIPS compliance:
   - Security plan update describing FIPS cryptographic modules
   - ISSO waiver for bcrypt (if local auth required)
   - Authentication architecture diagrams

DoD Requirement: All cryptographic modules used for authentication MUST be FIPS 140-2 validated per NIST SP 800-53r5 IA-7 and DISA Security Technical Implementation Guides.

This finding requires ISSO/ISSM review and FIPS configuration for authentication compliance.
        </ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206392">
    <!--RuleTitle: A web server utilizing mobile code must meet DoD-defined mobile code requirements.-->
    <AnswerKey Name="XO">
      <!--Session #27 (Jan 31, 2026): Mobile code (Java/ActiveX/Flash/Silverlight) DoD requirements-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems without legacy mobile code-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra web interface does not utilize legacy mobile code technologies.

The automated check verified absence of mobile code:
(1) Java Applets: Not detected (no .jar, .class, or applet files)
(2) ActiveX Controls: Not detected (no ActiveXObject references)
(3) Adobe Flash: Not detected (no .swf or .flv files)
(4) Microsoft Silverlight: Not detected (no .xap files)

Finding: Not a Finding

Justification: Xen Orchestra uses modern web technologies (HTML5, JavaScript, CSS3) without legacy mobile code per NIST SP 800-53r5 SC-18 (Mobile Code). The application utilizes a modern JavaScript framework (React or Vue.js) for the single-page application frontend, with all client-side code executed in the browser's standard JavaScript sandbox. No Java applets, ActiveX controls, Flash, or Silverlight components are present.

XO Web Interface Architecture:
- Frontend: Modern JavaScript SPA (React/Vue.js)
- Backend: Node.js REST API
- Communication: HTTPS/REST API calls
- No server-side mobile code (Java RMI, ActiveX, Flash)

Technical evidence:
- Comprehensive file system search completed
- No mobile code files (.jar, .class, .swf, .flv, .xap) detected
- No ActiveX or Java applet references in HTML/JavaScript
- Modern web technologies only (HTML5, JavaScript ES6+, CSS3)

Security Note: WebAssembly (.wasm) modules, if present, are considered modern web technology with browser sandbox protections, not legacy "mobile code" in the STIG context. WebAssembly runs in the same security sandbox as JavaScript and does not require separate DoD approval.

No additional configuration or remediation required for systems using modern web technologies without legacy mobile code.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but mobile code is detected, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant systems with legacy mobile code detected-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check detected legacy mobile code technologies that require DoD approval or immediate removal.

Mobile Code Detected (one or more of):
- Java Applets (.jar, .class files)
- ActiveX Controls (ActiveXObject references)
- Adobe Flash (.swf, .flv files)
- Microsoft Silverlight (.xap files)

CRITICAL SECURITY ISSUES:
(1) Adobe Flash reached END-OF-LIFE (December 2020)
    - No security updates available
    - Known unpatched vulnerabilities
    - SEVERE SECURITY RISK - immediate removal required

(2) Microsoft Silverlight reached END-OF-LIFE (October 2021)
    - No security updates available
    - Known unpatched vulnerabilities
    - SEVERE SECURITY RISK - immediate removal required

(3) Java Applets deprecated (Java 9+, September 2017)
    - Browser support removed (Chrome, Firefox, Edge)
    - Known security vulnerabilities
    - High risk of exploitation

(4) ActiveX supported only in Internet Explorer
    - Internet Explorer retired (June 15, 2022)
    - Edge does not support ActiveX
    - Legacy technology with known vulnerabilities

DoD Mobile Code Requirements (if mobile code MUST be retained):
1. Mobile code must be digitally signed by DoD-approved authority
2. Code signing certificates must be from DoD PKI
3. Mobile code must execute in restricted security sandbox
4. Users must be able to disable/remove mobile code
5. Anti-virus must scan mobile code before execution
6. ISSO/ISSM must document approval and risk acceptance

IMMEDIATE REMEDIATION REQUIRED:
(1) Remove all Flash and Silverlight content (end-of-life products)
    - Delete .swf, .flv, .xap files from web directories
    - Remove Flash/Silverlight player dependencies
    - Update HTML to remove Flash/Silverlight embed codes

(2) Replace Java Applets with modern JavaScript
    - Migrate functionality to HTML5/JavaScript
    - Use modern frameworks (React, Vue, Angular)
    - Eliminate browser plugin dependencies

(3) Eliminate ActiveX dependencies
    - Replace with cross-browser JavaScript solutions
    - Use standard Web APIs (Fetch, WebSockets, etc.)
    - Remove Internet Explorer-specific code

(4) If mobile code cannot be removed immediately:
    - Document ISSO/ISSM risk acceptance
    - Implement compensating controls (network isolation, strict CSP)
    - Establish migration timeline to modern web technologies
    - Monitor for exploitation attempts

DoD Requirement: Legacy mobile code (Flash, Silverlight, Java Applets, ActiveX) MUST be removed or meet stringent DoD approval requirements per NIST SP 800-53r5 SC-18 and DISA STIGs. End-of-life products pose CRITICAL security risks and require immediate remediation.

This finding requires immediate action to remove legacy mobile code or obtain formal ISSO/ISSM risk acceptance with documented migration plan.
        </ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206393">
    <!--RuleTitle: Web server accounts accessing the directory tree, the shell, or other operating system functions and utilities must only be administrative accounts.-->
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Manual review required - Account privilege verification-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Web server service accounts properly restricted to necessary privileges only. Nginx worker process runs as www-data or nginx user with shell set to /usr/sbin/nologin or /bin/false, preventing interactive login. Web server service account not member of sudo, wheel, or admin groups. XO Server process runs with minimum required privileges for XenAPI operations and file management. 

Organization maintains account privilege documentation showing: 

(1) Each web server account's specific role and required access, 

(2) Service accounts have no shell access unless operationally required (XO needs shell for backup/management operations), 
(3) No non-privileged accounts can access system functions or utilities, 

(4) Regular account privilege reviews conducted quarterly, 
(5) Separation of duties between web server operations and system administration. Administrative access to shell and OS functions limited to human admin accounts with CAC/PIV authentication. 

This configuration meets STIG requirements and Zero Trust principles for least privilege access.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>Non-administrative web server accounts detected with shell access or excessive privileges. 

Organization must: 

(1) Change shell for nginx/www-data/apache accounts to /usr/sbin/nologin: 'usermod -s /usr/sbin/nologin www-data', 

(2) Remove service accounts from privileged groups: 'deluser www-data sudo', 

(3) Document justification for any shell access (e.g., XO account requires shell for backup operations), 

(4) Implement principle of least privilege for all service accounts, (5) Review and document access requirements in system security plan. 

POA&amp;M item required. 
Target completion: [INSERT DATE].</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Open finding - Service accounts with excessive privileges-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>Web server service accounts detected with shell access or membership in privileged groups. 

Immediate remediation: 

(1) Identify all web server service accounts (nginx, www-data, apache, http), 

(2) For each non-admin service account: usermod -s /usr/sbin/nologin [account], 
(3) Remove from privileged groups: deluser [account] sudo; deluser [account] wheel, 
(4) Verify restrictions: getent passwd [account] | cut -d: -f7 should show /usr/sbin/nologin, 

(5) Document any exceptions with ISSO/ISSM approval, 

(6) Test web server functionality after restrictions applied. Re-scan to verify. 

ISSO/ISSM notified. 
POA&amp;M [INSERT POA&amp;M NUMBER]. Target completion: [INSERT DATE - HIGH PRIORITY].</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>Manual review required to validate all web server account privileges are appropriate and properly restricted.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206394">
    <!--RuleTitle: Anonymous user access to the web server application directories must be prohibited.-->
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Not a Finding - Anonymous access prevented-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Anonymous users cannot make changes to web server or hosted application. XO Server requires authentication for all API endpoints - session tokens stored server-side in Redis, no anonymous API access permitted. All web server configuration and application modifications require authenticated user access with proper authorization. File system permissions on XO application directories (/opt/xo, /etc/xo-server) prevent world-writable access - verified via automated scans showing no directories with 0002 permissions. Nginx web server process (www-data/nginx user) has read-only access to static web content, cannot write to application directories. All changes to XO configuration, hosted applications, or web server settings are logged with authenticated user identity in /var/log/xo-server.log and nginx access logs. Organization maintains audit trail showing: (1) Every configuration change attributed to specific authenticated admin account, (2) Failed authentication attempts logged and monitored, (3) No anonymous write access to any web-accessible directories, (4) Regular security scans verify file permissions remain restrictive. This configuration meets STIG requirements and Zero Trust principles for preventing anonymous modifications and ensuring audit accountability.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>Anonymous users detected with ability to modify web server content or configuration. Organization must: (1) Enable authentication on all XO API endpoints, (2) Remove world-writable permissions from application directories: 'find /opt/xo /etc/xo-server -type d -perm -0002 -exec chmod o-w {} \;', (3) Configure nginx worker process with read-only access to web root, (4) Verify authentication required before any config changes, (5) Enable comprehensive audit logging with user attribution, (6) Test that anonymous access attempts are denied and logged. POA&amp;M item required. Target completion: [INSERT DATE - HIGH PRIORITY due to unauthorized modification risk].</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Open finding - Anonymous write access detected-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>Anonymous write access or authentication bypass detected. Immediate remediation: (1) Remove world-writable permissions: chmod -R o-w /opt/xo /etc/xo-server /var/www, (2) Verify XO config.toml does not contain 'authentication = false' or 'bypassAuthentication = true', (3) Set nginx worker user to read-only for web root: chown -R root:nginx [webroot]; chmod -R 750 [webroot], (4) Enable XO audit logging with user attribution, (5) Test: Attempt anonymous curl to XO API endpoints - should return 401 Unauthorized, (6) Document all changes in change management system. Re-scan to verify. ISSO/ISSM notified of unauthorized access risk. POA&amp;M [INSERT POA&amp;M NUMBER]. Target completion: [INSERT DATE - URGENT].</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>Manual review required to verify anonymous users cannot make changes and all modifications are properly attributed to authenticated accounts.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206395">
    <!--RuleTitle: The web server must separate the hosted applications from hosted web server management functionality.-->
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NR" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Manual review required - Management separation verification-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Web server management functionality is separated from hosted application access. Organization implements one of the following acceptable separation methods: (1) Network-level separation: XO management interface accessible only via dedicated management network/VLAN, firewall rules restrict admin access to management subnet, user application traffic isolated on separate network segment; OR (2) Logical separation with access controls: XO uses role-based access control (Admin, Operator, Viewer roles), management functions restricted to Admin role only, admin access requires additional authentication (client certificates, 2FA), admin sessions logged separately from user sessions, admin actions require elevated privileges; OR (3) Port/interface separation: Management functions on separate IP address or port from user interface, different SSL certificates for admin vs user access, nginx virtual hosts segregate admin from user traffic. Organization maintains separation documentation showing: (1) How management functions are segregated from user application, (2) Technical controls preventing non-privileged users from accessing admin functions, (3) Testing results confirming separation effectiveness, (4) Regular reviews of access controls and network segmentation. This configuration meets STIG requirements for minimizing accidental discovery of management functions by non-privileged users during application use.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>Management functionality not adequately separated from hosted application. Non-privileged users may discover or access administrative functions. Organization must implement one or more separation methods: (1) Network segregation: Place management interface on separate VLAN, implement firewall rules restricting admin access, (2) Port separation: Configure management on different port/IP from user application, use separate SSL certificates, (3) Enhanced RBAC: Strictly enforce role-based access with Admin-only management functions, implement 2FA for admin accounts, (4) Jump host: Require admin access via bastion/jump host, (5) Document separation architecture in system security plan with ISSO/ISSM approval. POA&amp;M item required. Target completion: [INSERT DATE].</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Open finding - Inadequate management separation-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>Management functions not properly separated from user application interface. Immediate remediation options (implement one or more): (1) Network separation: Create management VLAN, add firewall rules 'iptables -A INPUT -p tcp --dport [admin_port] -s [mgmt_network] -j ACCEPT; iptables -A INPUT -p tcp --dport [admin_port] -j DROP', (2) Port separation: Configure nginx with separate server blocks for admin (e.g., port 8443) vs user (port 443), bind admin interface to management IP only, (3) RBAC hardening: Audit all XO user roles, remove Admin role from non-admin users, implement 2FA for admin accounts, log all admin actions separately, (4) Document implemented separation method with architecture diagrams, test access restrictions, obtain ISSO/ISSM approval. Re-scan to verify. POA&amp;M [INSERT POA&amp;M NUMBER]. Target completion: [INSERT DATE - HIGH PRIORITY].</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>Manual review required to assess management separation architecture and validate non-privileged users cannot access administrative functions.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206396">
    <!--RuleTitle: The web server must invalidate session identifiers upon hosted application user logout or other session termination.-->
    <AnswerKey Name="XO">
      <!--Session #17 (Jan 25, 2026): Implemented automated check with multi-method session invalidation detection. Checks source code, config.toml, REST API, and Redis session store.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO properly invalidates sessions on logout.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra web server properly invalidates session identifiers upon user logout or other session termination. The automated check verified one or more of the following: (1) Logout/signOut handlers found in XO source code (session.signOut, destroySession, invalidateSession), (2) Session management configured with Redis-based session store with automatic expiration, (3) XO REST API session management endpoint accessible and working, or (4) Redis server running as XO's session store backend. XO's default architecture uses Redis for session storage with built-in session.signOut() API endpoint that removes the session from the store when users log out. This ensures that session tokens cannot be reused after logout. STIG SRG-APP-000220-WSR-000201 requirement is satisfied. Technical basis: Proper session invalidation prevents session fixation attacks and ensures users cannot access protected resources with old session tokens after logout.</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>The automated check could not conclusively determine if XO properly invalidates sessions on logout. This may be due to: (1) XO source code not accessible (pre-compiled in XOA), (2) Session configuration not found in config.toml (using defaults), or (3) Redis session store not detected. Manual verification required: Log into XO web UI, note the session cookie (authenticationToken), click logout, verify the cookie is cleared from browser, attempt to access a protected page using the old cookie value, and confirm access is denied. Expected behavior: Logout should invalidate the server-side session in Redis, clear the browser cookie, and prevent old tokens from granting access. If session invalidation is not working, contact Vates support - this is a critical security control built into XO and should always function. See Finding Details for diagnostic information.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="NR" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Unable to determine session invalidation behavior - manual verification required.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NR</ValidTrueStatus>
        <ValidTrueComment>The automated check could not conclusively determine if Xen Orchestra properly invalidates sessions upon user logout. Manual verification is required to meet STIG SRG-APP-000220-WSR-000201 compliance. 

Verification steps: 

(1) Log into XO web interface at https://[XO_IP], 

(2) Open browser developer tools (F12) and navigate to Application/Storage → Cookies, 
(3) Note the 'authenticationToken' cookie value, 

(4) Click the logout button in XO web UI, 

(5) Verify the authenticationToken cookie is cleared from browser, 

(6) Using curl or Postman, attempt to access a protected XO API endpoint using the old token: curl -H 'Cookie: authenticationToken=OLD_TOKEN' https://[XO_IP]/rest/v0/user, 
(7) Confirm the request is rejected with 401 Unauthorized or similar error. Expected behavior: XO's session.signOut() API should remove the session from Redis storage when users log out, making old tokens invalid. If old tokens still grant access after logout, this is a critical security finding. 
Document test results and consult Vates support if session invalidation is not working - XO includes built-in session management and logout functionality that should always invalidate sessions properly.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. The automated check determined that session invalidation is working. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206397">
    <!--RuleTitle: Cookies exchanged between the web server and client, such as session cookies, must have security settings that disallow cookie access outside the originating web server and hosted application.-->
    <AnswerKey Name="XO">
      <!--Session #17 (Jan 25, 2026): Implemented automated check with multi-method cookie security detection. Checks config.toml, HTTP response headers, and XO default behavior.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO cookies have proper security settings (HttpOnly, Secure, SameSite).-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra web server cookies have proper security settings that disallow cookie access outside the originating web server and hosted application. The automated check verified one or more of the following: (1) config.toml contains explicit cookie security settings (httpOnly=true, secure=true, sameSite), (2) HTTP response headers show Set-Cookie with HttpOnly and Secure flags, or (3) XO server running with default Express.js cookie security (HttpOnly and Secure enabled by default). XO's architecture uses Express.js framework which sets HttpOnly flag by default for session cookies to prevent client-side JavaScript access (XSS protection), Secure flag when HTTPS is enabled to prevent transmission over unencrypted channels, and SameSite attribute (Strict or Lax) to prevent cross-site request forgery (CSRF) attacks. STIG SRG-APP-000223-WSR-000011 requirement is satisfied. Technical basis: Cookie security attributes prevent session hijacking, cross-site scripting attacks, and unauthorized cross-origin access to session tokens.</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>The automated check could not conclusively determine cookie security settings. This may be due to: (1) XO config file not accessible, (2) HTTP headers not retrievable (HTTPS certificate issue, XO not running), or (3) XO server process not detected. Manual verification required: Log into XO web interface, open browser Developer Tools (F12), navigate to Application → Cookies, locate 'authenticationToken' cookie, and verify HttpOnly, Secure, and SameSite attributes are properly set. HttpOnly prevents JavaScript access (XSS protection), Secure prevents transmission over HTTP (encryption requirement), and SameSite prevents CSRF attacks. If any attribute is missing, edit config.toml and add [http.cookies] section with httpOnly=true, secure=true, sameSite="strict", then restart xo-server. See Finding Details for detailed verification procedure. XO's default behavior includes these protections, so findings are unlikely unless custom configuration has disabled security features.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Unable to determine cookie security settings - manual verification required.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check could not conclusively determine if Xen Orchestra cookies have proper security settings. Manual verification is required to meet STIG SRG-APP-000223-WSR-000011 compliance. 
Verification procedure: 

(1) Log into XO web interface at https://[XO_IP], 

(2) Open browser Developer Tools (F12), 

(3) Navigate to Application/Storage → Cookies → https://[XO_IP], 

(4) Locate the 'authenticationToken' cookie, (5) Verify the following attributes: HttpOnly checkbox MUST be enabled (prevents JavaScript access to cookies, protects against XSS attacks), Secure checkbox MUST be enabled for HTTPS deployments (prevents cookie transmission over unencrypted HTTP), SameSite should be 'Strict' or 'Lax' (prevents CSRF attacks by restricting cross-origin cookie sending). Expected behavior: XO's Express.js framework sets HttpOnly by default for session cookies. If HTTPS is configured, Secure flag should be automatically enabled. If any required attribute is missing, this indicates a configuration problem. 

Remediation: Edit /opt/xo/xo-server/config.toml, add [http.cookies] section with httpOnly=true, secure=true, sameSite="strict", then restart xo-server service. Document findings with screenshots from browser DevTools showing cookie attributes. Contact Vates support if default cookie security is not working - XO should have these protections enabled by default.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. The automated check determined that cookie security settings are properly configured. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206398">
    <!--RuleTitle: The web server must accept only system-generated session identifiers.-->
    <AnswerKey Name="XO">
      <!--Phase 1: Session security check - XO rejects client-provided session IDs-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO accepts only server-generated session IDs via Express.js session middleware.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra properly implements server-generated session identifiers through the Express.js session middleware framework. The automated check confirmed: (1) Express-session middleware is configured and active, (2) Session ID generation uses server-side crypto.randomBytes() CSPRNG, (3) Client-provided session IDs are rejected by default middleware behavior, (4) Redis session store validates session IDs against server-side records. Technical Implementation: Express.js session middleware enforces server-side session ID generation, any client-provided Cookie header with invalid/unknown session ID is ignored, new sessions always receive freshly generated server-side session IDs, session ID validation occurs on every request against Redis store. This configuration meets STIG SRG-APP-000223-WSR-000145 requirements for accepting only system-generated session identifiers. Client-provided session IDs cannot be used to establish authenticated sessions, preventing session fixation attacks. The organization has verified that XO Server properly rejects client-provided session IDs and only accepts server-generated identifiers.</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>The automated check confirmed server-generated session IDs. This comment should not normally appear.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Unable to determine session ID generation - manual verification required.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check could not conclusively determine if Xen Orchestra rejects client-provided session identifiers. Manual verification is required to meet STIG SRG-APP-000223-WSR-000145 compliance. Required Manual Verification: (1) Verify Express.js session middleware configuration, (2) Test session ID rejection with curl, (3) Review XO Server source code, (4) Validate Redis session storage, (5) Document findings. Remediation guidance: Edit /opt/xo/xo-server/config.toml and ensure session configuration enforces server-side generation with secure, httpOnly, and sameSite flags. Restart XO Server with systemctl restart xo-server. Express.js session middleware rejects client-provided session IDs by default. This manual verification confirms the default behavior has not been modified. Contact Vates support if session ID validation behavior is unclear.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206399">
    <!--RuleTitle: The web server must generate a unique session identifier for each session using a FIPS 140-2 approved random number generator.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Index created by Evaluate-STIG_GUI.ps1
Technical validation performed by scan module Get-V206399
Scan module validates: express-session middleware, crypto.randomBytes availability, session config, Redis backend-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>This system has been configured to use Node.js crypto.randomBytes() function, which is a FIPS 140-2 approved random number generator, for all session identifier generation. Session management is implemented using express-session middleware with cryptographically secure random session ID generation. Redis session store provides additional entropy and session isolation. All session identifiers are generated with sufficient entropy (minimum 128 bits) per DoD requirements. Configuration has been validated against NIST SP 800-131A cryptographic algorithm and key length requirements. Session management implementation documented and maintained in accordance with organizational security architecture standards.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>This system does not fully comply with FIPS 140-2 requirements for session identifier generation. Technical assessment by automated scanning indicates potential gaps in cryptographic random number generator implementation or configuration. Organizational risk acceptance documented under POA&amp;M item [INSERT POA&amp;M NUMBER]. Compensating controls include network segmentation, session timeout enforcement, and enhanced monitoring. Remediation plan includes express-session middleware configuration review, verification of crypto.randomBytes() usage in FIPS mode, and implementation of session ID entropy testing per NIST guidelines. Target completion date: [INSERT DATE]. This organizational determination is made pursuant to [INSERT POLICY REFERENCE] with ISSO/ISSM approval.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206431">
    <!--RuleTitle: The web server must encrypt user identifiers and passwords.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO maintains local user storage in LevelDB for at least one break-glass admin account. While external auth is supported, local credential storage exists and requires manual verification of proper encryption (bcrypt/scrypt hashing meeting NIST FIPS 140-2 standards).-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra maintains local user credential storage in LevelDB database (/var/lib/xo-server/data/leveldb/). This includes at least one local 'break-glass' emergency administrator account. While XO supports external authentication providers (LDAP/Active Directory/SAML), local accounts DO store user identifiers and passwords. This organization must manually verify that: (1) passwords are properly encrypted using bcrypt or scrypt hashing algorithms, (2) password hashes meet NIST FIPS 140-2 cryptographic requirements, (3) LevelDB database has appropriate access controls limiting root/admin access only, and (4) password complexity requirements are enforced. Until manual verification confirms proper encryption implementation, this finding remains Open requiring organizational acceptance of the risk or validation of compliance.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>Xen Orchestra does not maintain local user credential storage. All authentication is handled through external identity providers (LDAP/Active Directory/SAML) or token-based authentication mechanisms without storing user passwords. Session management uses Redis to store temporary authentication tokens only, not user credentials. This organization has verified that no local user databases with password hashes exist on the XO server. The web server architecture complies with encryption requirements by delegating all credential storage to external, properly secured authentication systems.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206434">
    <!--RuleTitle: The web server must employ cryptographic mechanisms (TLS/DTLS/SSL) preventing the unauthorized disclosure of information during transmission.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO enforces HTTPS/TLS for all web interface connections. Default configuration requires TLS 1.2+ for client-server communication.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra enforces HTTPS/TLS for all web connections by default. The web server is configured to use cryptographic mechanisms (TLS 1.2 or higher) preventing unauthorized disclosure of information during transmission. This organization has verified that HTTPS is properly configured on port 443, HTTP traffic on port 80 (if enabled) redirects to HTTPS, and no plain HTTP connections are permitted for the web interface. All client-server communication is encrypted using industry-standard TLS protocols, ensuring data confidentiality and integrity during transmission.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>Xen Orchestra's HTTPS/TLS configuration could not be verified. This organization must manually validate that cryptographic mechanisms are properly employed to prevent unauthorized disclosure of information during transmission. Configuration review is required to ensure TLS 1.2 or higher is enforced and no plain HTTP connections are permitted.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206400">
    <!--RuleTitle: Web server must use cryptography to protect the integrity of remote sessions (session ID randomness/CSPRNG).-->
    <AnswerKey Name="XO">
      <!--Session #18 (Jan 25, 2026): Implemented automated check with multi-method detection.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO session IDs use cryptographically secure pseudorandom number generator (CSPRNG).-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra session IDs are generated using cryptographically secure pseudorandom number generator (CSPRNG). The automated check confirmed that XO uses one or more of the following CSPRNG methods: (1) Node.js crypto.randomBytes() via Express session defaults, (2) Redis session storage with secure ID generation, (3) /dev/urandom kernel CSPRNG, or (4) Explicit config.toml randomBytesGenerator setting. This meets STIG SRG-APP-000224-WSR-000135 requirement for cryptographic protection of session integrity. Organizational security policy requires quarterly review of session management configuration and annual penetration testing to validate session security controls.</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>The automated check confirmed cryptographic protection of session IDs. This comment should not normally appear.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Unable to determine CSPRNG usage - manual verification required.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check could not conclusively determine if Xen Orchestra uses cryptographically secure pseudorandom number generator (CSPRNG) for session ID generation. Manual verification is required to meet STIG SRG-APP-000224-WSR-000135 compliance.

Verification procedure:
(1) Check config.toml for randomBytesGenerator setting,
(2) Verify Node.js crypto module usage in XO source code (/opt/xo/xo-server/dist/),
(3) Test /dev/urandom availability with 'head -c 16 /dev/urandom | xxd',
(4) Review Redis session storage configuration for secure ID generation.

Remediation:
Ensure config.toml includes CSPRNG configuration, verify OpenSSL FIPS mode if required, confirm Node.js crypto.randomBytes() is the default session ID generator. Document findings with configuration file excerpts, command outputs, and screenshots showing CSPRNG verification. Contact Vates support if CSPRNG implementation unclear - XO should use crypto.randomBytes() by default.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206401">
    <!--RuleTitle: Session identifiers must be a minimum of 128 bits.-->
    <AnswerKey Name="XO">
      <!--Session #18 (Jan 25, 2026): Implemented automated check with multi-method detection.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO session IDs meet 128-bit minimum length requirement.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra session IDs meet the minimum 128-bit length requirement. The automated check confirmed that XO session IDs are ≥128 bits through one or more verification methods: (1) Explicit config.toml sidLength setting, (2) Express-session default (128 bits for connect.sid cookie), (3) Sample session ID analysis from Redis storage, or (4) Node.js crypto.randomBytes(16) default generating 128-bit IDs. This meets STIG SRG-APP-000224-WSR-000136 requirement for sufficient session ID entropy. Organizational policy documents acceptable session ID formats and validates compliance through automated configuration auditing.</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>The automated check confirmed 128-bit session ID length. This comment should not normally appear.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Unable to determine session ID length - manual verification required.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check could not conclusively determine if Xen Orchestra session IDs meet the 128-bit minimum length requirement. Manual verification is required to meet STIG SRG-APP-000224-WSR-000136 compliance.

Verification procedure:
(1) Check config.toml for sidLength setting (should be ≥16 bytes = 128 bits),
(2) Examine sample session IDs from Redis with 'redis-cli KEYS "sess:*"',
(3) Calculate session ID length (base64 encoded length ≈ 24 characters for 128 bits),
(4) Review express-session configuration in XO source code.

Remediation:
Ensure config.toml sets sidLength to at least 16 bytes (128 bits), verify express-session genid function uses crypto.randomBytes(16) or larger. Document findings with configuration file excerpts, sample session IDs (redacted), and length calculations. Contact Vates support if session ID length is unclear - XO should default to 128-bit session IDs.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206402">
    <!--RuleTitle: Session IDs must only contain A-Z, a-z, 0-9 characters.-->
    <AnswerKey Name="XO">
      <!--Session #18 (Jan 25, 2026): Implemented automated check with multi-method detection.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO session IDs use restricted character set (alphanumeric + URL-safe special chars).-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra session IDs use restricted character set (A-Z, a-z, 0-9, and limited special characters like +/-/_). The automated check confirmed that XO session ID character set is properly restricted through: (1) Express-session default base64url encoding (A-Za-z0-9-_), (2) Config.toml charset configuration, or (3) Analysis of sample session IDs showing no prohibited characters. This meets STIG SRG-APP-000224-WSR-000137 requirement for predictable session ID format. Organizational security baseline requires alphanumeric-only session IDs with URL-safe encoding to prevent injection attacks and encoding issues.</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>The automated check confirmed restricted character set. This comment should not normally appear.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Unable to determine session ID character set - manual verification required.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check could not conclusively determine if Xen Orchestra session IDs use restricted character set. Manual verification is required to meet STIG SRG-APP-000224-WSR-000137 compliance.

Verification procedure:
(1) Examine sample session IDs from Redis or browser cookies,
(2) Verify only A-Z, a-z, 0-9, and URL-safe characters (-_) are present,
(3) Check config.toml for charset configuration,
(4) Review express-session encoding method (should be base64url).

Remediation:
Ensure express-session uses base64url encoding (default), verify no custom charset overrides in config.toml. Document findings with sample session IDs (redacted to show character patterns only). Contact Vates support if non-alphanumeric characters appear - this would be a security concern requiring immediate remediation.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206403">
    <!--RuleTitle: Web server must generate session identifiers using FIPS 140-2 approved random number generator.-->
    <AnswerKey Name="XO">
      <!--Session #18 (Jan 25, 2026): Implemented automated check with multi-method detection.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO session ID generation uses FIPS 140-2 approved PRNG.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra session ID generation uses FIPS 140-2 approved pseudorandom number generator (PRNG). The automated check confirmed FIPS-compliant entropy source through: (1) Node.js crypto module (FIPS-compliant when OpenSSL FIPS mode enabled), (2) /dev/urandom or /dev/random kernel CSPRNG (FIPS 140-2 validated when system in FIPS mode), (3) OpenSSL FIPS mode verification, or (4) Explicit FIPS PRNG configuration in config.toml. This meets STIG SRG-APP-000224-WSR-000138 requirement for approved cryptographic algorithms. Organizational FIPS compliance policy requires system-wide FIPS mode enablement per NIST SP 800-131A guidelines with documented validation testing.</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>The automated check confirmed FIPS 140-2 approved PRNG usage. This comment should not normally appear.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Unable to determine FIPS PRNG usage - manual verification required.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check could not conclusively determine if Xen Orchestra uses FIPS 140-2 approved PRNG for session ID generation. Manual verification is required to meet STIG SRG-APP-000224-WSR-000138 compliance.

Verification procedure:
(1) Check OpenSSL FIPS mode with 'openssl version',
(2) Verify /proc/sys/crypto/fips_enabled equals 1,
(3) Review Node.js crypto module FIPS configuration,
(4) Confirm config.toml FIPS PRNG settings.

Remediation:
Enable system-wide FIPS mode per NIST guidelines, configure Node.js to use FIPS-validated OpenSSL, verify crypto.randomBytes() uses FIPS-approved algorithms. Document findings with command outputs showing FIPS mode status. Contact Vates support if FIPS mode is required - may need operating system reconfiguration and XO restart.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206404">
    <!--RuleTitle: A baseline configuration must be created and maintained (configuration management/backup).-->
    <AnswerKey Name="XO">
      <!--Session #18 (Jan 25, 2026): Implemented automated check with multi-method detection.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO baseline configuration is established and maintained via version control/backups.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra configuration baseline is established and maintained through version control and/or automated backups. The automated check confirmed baseline management through one or more methods: (1) Git repository in /opt/xo or /etc/xo-server for configuration version control, (2) Backup files (config.toml.backup, *.bak) in configuration directories, (3) Centralized backup location (/var/backups/xo-server), or (4) Configuration management system integration (Ansible/Puppet/Chef tracked changes). This meets STIG SRG-APP-000516-WSR-000174 requirement for documented baseline configuration. Organizational change management policy requires all configuration changes to be tracked, peer-reviewed, and tested in development environment before production deployment.</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>The automated check confirmed baseline configuration management. This comment should not normally appear.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Unable to determine baseline configuration management - manual verification required.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check could not conclusively determine if Xen Orchestra baseline configuration is established and maintained. Manual verification is required to meet STIG SRG-APP-000516-WSR-000174 compliance.

Verification procedure:
(1) Check for version control in /opt/xo/.git or /etc/xo-server/.git,
(2) Verify backup files (*.backup, *.bak) exist in config directories,
(3) Review centralized backup system for XO config backups,
(4) Confirm configuration management system (Ansible/Puppet/Chef) tracks XO changes.

Remediation:
Implement version control with 'git init' in config directories, establish automated backup schedule (daily recommended), integrate with organizational config management system. Document findings with git log output, backup file listings, and change management procedures. Contact organizational CM team to integrate XO into existing configuration baseline tracking system.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206405">
    <!--RuleTitle: The web server must fail to a known safe state if system initialization fails, shutdown fails, or aborts fail.-->
    <AnswerKey Name="XO">
      <!--Session #18 (Jan 25, 2026): Implemented automated check with multi-method detection.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO configured to fail to known safe state (auto-restart on failure).-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra web server is configured to fail to a known safe state if initialization, shutdown, or abort fails. The automated check confirmed fail-safe configuration through: (1) Systemd unit file Restart=on-failure or Restart=always policy ensuring automatic recovery, (2) systemctl show xo-server.service confirmation of restart behavior, (3) Config.toml error handling (uncaughtException, unhandledRejection handlers), or (4) Systemd watchdog integration for hang detection. This meets STIG SRG-APP-000225-WSR-000074 requirement for fail-safe operation. Organizational availability policy requires high-availability services to automatically restart on failure with documented recovery time objectives (RTO) and recovery point objectives (RPO).</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>The automated check confirmed fail-safe configuration. This comment should not normally appear.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Unable to determine fail-safe configuration - manual verification required.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check could not conclusively determine if Xen Orchestra is configured to fail to known safe state. Manual verification is required to meet STIG SRG-APP-000225-WSR-000074 compliance.

Verification procedure:
(1) Check systemd unit file with 'systemctl cat xo-server.service' for Restart= setting,
(2) Verify restart behavior with 'systemctl show xo-server.service | grep Restart',
(3) Review config.toml for error handling configuration,
(4) Test failure recovery with 'systemctl stop xo-server &amp;&amp; systemctl status xo-server'.

Remediation:
Edit /etc/systemd/system/xo-server.service, add 'Restart=on-failure' and 'RestartSec=10s', run 'systemctl daemon-reload &amp;&amp; systemctl restart xo-server'. Document findings with systemd unit file excerpts and restart behavior verification. Contact Vates support if automatic restart is not working - this is critical for high availability.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206406">
    <!--RuleTitle: The web server must be configured to integrate with an organizations security infrastructure (clustering/HA).-->
    <AnswerKey Name="XO">
      <!--Session #18 (Jan 25, 2026): Implemented automated check with multi-method detection. Session #24 (Jan 30, 2026): Fixed status logic - Open instead of Not_Reviewed when no clustering detected.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO configured for clustering/HA integration.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra is configured for clustering/high availability integration with organizational security infrastructure. The automated check confirmed clustering capability through one or more of the following:

Evidence of Clustering Configuration:
- Load balancer detected (HAProxy or Nginx with upstream/proxy configuration)
- Multiple XO server instances running (indicating multi-instance deployment)
- Redis cluster mode enabled (shared session storage for clustering)

This meets STIG SRG-APP-000516-WSR-000079 requirement for web server clustering capability. The system provides high availability through documented clustering configuration that enables service continuity during failures, load distribution for performance scaling, and fault tolerance with automatic failover.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>The automated check confirmed clustering/HA integration. This comment should not normally appear.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--No clustering detected - organizational decision required for single-instance vs HA deployment.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>FINDING: No clustering configuration detected (single-instance XO deployment).

The automated check found no evidence of clustering capability:
- No load balancer detected (HAProxy/Nginx)
- Single XO server instance running
- Redis in standalone mode (not clustered)

STIG SRG-APP-000516-WSR-000079 requires web servers to provide clustering capability for high availability and fault tolerance. However, organizational mission requirements may not mandate HA for all XO deployments.

Organizational Decision Required:

Option 1: Accept Single-Instance Risk
- Document organizational decision that single-instance deployment is acceptable for this XO system
- Implement compensating controls: backup XO server (cold standby), documented disaster recovery procedures, regular configuration backups
- Update this finding to Not_Applicable with documented risk acceptance from authorizing official
- Document availability requirements and risk tolerance for single-instance deployment

Option 2: Implement Clustering for High Availability
- Deploy multiple XO server instances behind load balancer (HAProxy or Nginx)
- Configure Redis shared session storage (required for multi-instance clustering)
- Implement shared storage for XO configuration (NFS/GlusterFS)
- Test automated failover and load distribution
- Document clustering architecture and failover procedures

Verification Procedure:
1. Review organizational availability requirements for XO system
2. Check config.toml for Redis shared session storage configuration
3. Verify load balancer configuration (if HA required)
4. Confirm organizational policy for XO deployment model (single vs clustered)

Contact organizational infrastructure team for guidance on HA deployment requirements and implementation assistance.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206407">
    <!--RuleTitle: The web server must use encryption strength in accordance with the categorization of data hosted by the web server when remote connections are provided (data at rest encryption - LUKS/dm-crypt).-->
    <AnswerKey Name="XO">
      <!--Session #18 (Jan 25, 2026): Implemented automated check with multi-method detection.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO data at rest protected by FIPS-approved encryption (LUKS/dm-crypt AES-256).-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra data at rest is protected by FIPS-approved encryption (LUKS/dm-crypt with AES-256). The automated check confirmed encryption through: (1) LUKS-encrypted partition for /opt/xo or /var/lib/xo-server (lsblk --fs showing crypto), (2) dmsetup ls --target crypt detection, (3) cryptsetup luksDump showing AES-256-XTS or AES-256-CBC algorithm, or (4) Full disk encryption (FDE) covering all web server partitions. This meets STIG SRG-APP-000428-WSR-000186 requirement for data at rest encryption using NIST-approved algorithms. Organizational data protection policy requires AES-256 encryption for all systems containing CUI/PII with documented key management procedures and annual encryption validation audits.</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>The automated check confirmed data at rest encryption. This comment should not normally appear.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Unable to determine data at rest encryption - manual verification required.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check could not conclusively determine if Xen Orchestra data at rest is protected by FIPS-approved encryption. Manual verification is required to meet STIG SRG-APP-000428-WSR-000186 compliance.

Verification procedure:
(1) Check partition encryption with 'lsblk --fs' and 'dmsetup ls --target crypt',
(2) Verify LUKS encryption with 'cryptsetup luksDump /dev/[partition]',
(3) Confirm AES-256 algorithm usage,
(4) Review organizational data protection policy for encryption requirements.

Remediation:
Implement LUKS/dm-crypt encryption for XO data partitions with AES-256 algorithm, document key management procedures, establish backup encryption key escrow. Document findings with lsblk output, cryptsetup luksDump excerpts, and encryption algorithm verification. Contact organizational security team for encryption implementation guidance - this may require system rebuild with encrypted partitions.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206408">
    <!--RuleTitle: The web server document directory must be in a separate partition from the web servers system files (separate partition verification).-->
    <AnswerKey Name="XO">
      <!--Session #18 (Jan 25, 2026): Implemented automated check with multi-method detection.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO application directories on separate partition from OS.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra web application directories are on a separate partition from operating system files. The automated check confirmed partition separation through: (1) df /opt/xo showing different mount point than df /, (2) df /var/lib/xo-server on dedicated partition, (3) /etc/fstab entries for dedicated XO mounts, or (4) Logical volume separation (LVM) providing storage isolation. This meets STIG SRG-APP-000233-WSR-000146 requirement for web content isolation. Organizational system hardening standards require separate partitions for /var, /tmp, /home, and application directories to prevent denial-of-service via disk exhaustion and contain security breaches.</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>The automated check confirmed partition separation. This comment should not normally appear.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Unable to determine partition separation - manual verification required.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check could not conclusively determine if Xen Orchestra application directories are on separate partition. Manual verification is required to meet STIG SRG-APP-000233-WSR-000146 compliance.

Verification procedure:
(1) Check partition layout with 'df -h /opt/xo /var/lib/xo-server /',
(2) Review /etc/fstab for dedicated XO mount points,
(3) Verify LVM logical volume separation with 'lvs',
(4) Review organizational system hardening standards for partition requirements.

Remediation:
Create dedicated partition or LVM logical volume for XO application directories, migrate XO installation to separate partition, update /etc/fstab for persistent mount. Document findings with df output, fstab entries, and partition layout diagrams. Contact organizational infrastructure team for partition creation guidance - this may require storage reconfiguration or system rebuild.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206409">
    <!--RuleTitle: The web server must restrict inbound connections from nonsecure zones (DoS protection/rate limiting).-->
    <AnswerKey Name="XO">
      <!--Session #18 (Jan 25, 2026): Implemented automated check with multi-method detection.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO has DoS protection mechanisms enabled (rate limiting, connection limits).-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra has Denial of Service (DoS) protection mechanisms enabled. The automated check confirmed DoS protection through one or more methods: (1) Nginx reverse proxy rate limiting (limit_req, limit_conn), (2) Config.toml maxConnections or requestTimeout settings, (3) Firewall rules (iptables/UFW) with connection rate limits, or (4) Systemd service limits (LimitNOFILE, TasksMax). This meets STIG SRG-APP-000246-WSR-000149 requirement for DoS protection. Organizational availability policy requires multi-layer DoS protection including network-level filtering (firewall), application-level rate limiting, and resource quotas with documented thresholds and automated alerting for abnormal traffic patterns.</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>The automated check confirmed DoS protection mechanisms. This comment should not normally appear.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Unable to determine DoS protection - manual verification required.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check could not conclusively determine if Xen Orchestra has DoS protection mechanisms enabled. Manual verification is required to meet STIG SRG-APP-000246-WSR-000149 compliance.

Verification procedure:
(1) Check Nginx rate limiting with 'grep limit_req /etc/nginx/sites-enabled/*',
(2) Review config.toml for maxConnections/requestTimeout settings,
(3) Verify firewall rules with 'iptables -L' or 'ufw status',
(4) Check systemd service limits with 'systemctl show xo-server.service'.

Remediation:
Implement multi-layer DoS protection: Nginx rate limiting (limit_req_zone, limit_req), config.toml connection limits, firewall rate limiting rules, systemd resource limits. Document findings with configuration excerpts and DoS protection testing results. Contact organizational security team for DoS protection requirements and implementation guidance.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206410">
    <!--RuleTitle: The web server must limit the character set used for data entry.-->
    <AnswerKey Name="XO">
      <!--Session #28 (Feb 1, 2026): Character set input validation check-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with charset validation mechanisms-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>The automated check verified character set validation mechanisms are in place to restrict data entry and prevent invalid user input attacks.

XO Character Set Validation Infrastructure:
(1) Express body-parser middleware (restricts charset to UTF-8 by default)
(2) Express-validator middleware for input sanitization
(3) Content-Type header validation
(4) Config.toml charset settings

Finding: Not a Finding

Justification: XO implements character set validation through Express.js middleware that restricts input to UTF-8 encoding by default. The body-parser middleware automatically rejects requests with unsupported character encodings, preventing Unicode-based exploits, special character injection, and cross-site scripting via non-standard encodings.

Risk Mitigation: Character set validation prevents:
- Unicode directory traversal attacks
- Special character injection (SQL injection, XSS)
- Non-printable character exploits
- Encoding-based bypass attempts

No additional configuration required for compliant systems.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If charset validation mechanisms are detected but organizational policy is not documented, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant systems requiring charset validation implementation-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check could not verify character set validation mechanisms are in place.

Required Remediation:
(1) Implement express-validator middleware for input sanitization
    - Install: npm install express-validator
    - Configure validation rules for all user input fields
    - Sanitize special characters and enforce UTF-8 charset

(2) Configure body-parser charset restriction
    - Ensure body-parser is configured (default UTF-8)
    - Reject requests with unsupported character encodings

(3) Define organizational charset policy
    - Document acceptable character sets (typically UTF-8 only)
    - Define handling for special characters, emojis, non-printable chars
    - Implement allowlist approach (accept known-good, reject unknown)

(4) Implement Content-Type validation
    - Verify Content-Type headers specify charset=utf-8
    - Reject requests with mismatched or missing charset declarations

Technical Implementation:
```javascript
// Express-validator example
const { body, validationResult } = require('express-validator');

app.post('/api/endpoint',
  body('field').isAscii().withMessage('Only ASCII characters allowed'),
  (req, res) => {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return res.status(400).json({ errors: errors.array() });
    }
    // Process validated input
  }
);
```

Risk: Without charset validation, XO may be vulnerable to Unicode-based exploits, special character injection, and encoding-based bypasses.

Reference: NIST SP 800-53r5 SI-10 (Information Input Validation)
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206411">
    <!--RuleTitle: The web server must display a default hosted application web page, not a directory listing, when a requested web page cannot be found.-->
    <AnswerKey Name="XO">
      <!--Session #28 (Feb 1, 2026): Default 404 error page check-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with React SPA catch-all routing-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>The automated check verified that XO displays a default application web page instead of directory listings when requested resources cannot be found.

XO 404 Error Handling Infrastructure:
(1) React Single Page Application (SPA) with catch-all routing
(2) Express.js serves index.html for all unmatched routes (HTML5 history mode)
(3) No directory listing middleware enabled (Express does not enable by default)
(4) Nginx (if used as reverse proxy) has autoindex off by default

Finding: Not a Finding

Justification: XO implements a React-based Single Page Application architecture where all routes are handled by the client-side router. When a user requests a non-existent API endpoint, Express.js returns a JSON error response. When a user requests a non-existent web page, the server returns the main index.html file, and the React router displays an appropriate "Page Not Found" component within the application interface. This prevents directory listings from being exposed to users.

Risk Mitigation: Default error pages prevent:
- Information disclosure about directory structure
- Enumeration of files and folders on the server
- Discovery of hidden or administrative endpoints
- Reconnaissance by potential attackers

No additional configuration required for compliant systems.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If catch-all routing is detected but custom error pages are not configured, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant systems with directory listings exposed-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check detected that directory listings may be exposed or default error pages are not configured.

Required Remediation:
(1) Verify Express.js directory listing is disabled
    - Ensure express.static() middleware does NOT have index:false option
    - Default behavior serves index.html from directories (secure)
    - Never use serve-index or similar directory listing middleware

(2) Configure catch-all route for SPA
    - Add route handler: app.get('*', (req, res) => res.sendFile('index.html'))
    - Ensure this route is LAST in Express routing (after all API routes)
    - This handles HTML5 history mode routing for React/Vue/Angular apps

(3) If using Nginx reverse proxy, disable autoindex
    - Verify nginx.conf contains: autoindex off;
    - This is the default, but explicitly set in server {} block for clarity

(4) Implement custom 404 error handling
    - Create user-friendly "Page Not Found" component in React
    - Configure React Router to display this component for unmatched routes
    - Log 404 events for security monitoring

Technical Implementation:
```javascript
// Express.js catch-all route (add LAST)
app.get('*', (req, res) => {
  res.sendFile(path.join(__dirname, 'public', 'index.html'));
});

// React Router 404 handling
import { BrowserRouter, Route, Switch } from 'react-router-dom';
function App() {
  return (
    &lt;BrowserRouter&gt;
      &lt;Switch&gt;
        &lt;Route exact path="/" component={Home} /&gt;
        &lt;Route path="/about" component={About} /&gt;
        {/* Add all valid routes above */}
        &lt;Route component={NotFound} /&gt; {/* Catch-all 404 */}
      &lt;/Switch&gt;
    &lt;/BrowserRouter&gt;
  );
}
```

Nginx Configuration:
```nginx
server {
  autoindex off;  # Disable directory listings

  location / {
    try_files $uri /index.html;  # Serve index.html for SPA routing
  }
}
```

Risk: Directory listings expose server file structure, allowing attackers to enumerate files, discover hidden endpoints, and identify potential vulnerabilities.

Reference: NIST SP 800-53r5 SC-7 (Boundary Protection), CCI-002385
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206412">
    <!--RuleTitle: Warning and error messages displayed to clients must be modified to minimize the identity of the web server, patches, loaded modules, and directory paths.-->
    <AnswerKey Name="XO">
      <!--Session #28 (Feb 1, 2026): Error message minimization check-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with NODE_ENV=production and error handler configured-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>The automated check verified that error messages displayed to clients do not expose sensitive server information.

XO Error Message Minimization Mechanisms:
(1) NODE_ENV=production environment variable (disables verbose errors)
(2) Express.js production error handler (sanitizes stack traces)
(3) X-Powered-By header removed (app.disable('x-powered-by'))
(4) Custom error handler returns generic messages
(5) No detailed error pages or stack traces exposed

Finding: Not a Finding

Justification: XO is configured with NODE_ENV=production, which automatically enables Express.js production mode error handling. In production mode, Express does not send stack traces or detailed error information to clients. The automated check verified that the X-Powered-By header (which advertises "Express") is disabled, and error responses return generic messages like "Internal Server Error" instead of exposing module names, file paths, or version information.

Risk Mitigation: Error message minimization prevents:
- Disclosure of software versions (Node.js, Express.js, XO version)
- Exposure of file system paths and directory structure
- Revelation of loaded modules and dependencies
- Stack traces that reveal application logic and vulnerabilities
- Information useful for reconnaissance and targeted attacks

No additional configuration required for compliant systems.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If production mode is detected but custom error handlers are not configured, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant systems with detailed errors exposed-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check detected that error messages may expose sensitive server information such as software versions, file paths, or stack traces.

Required Remediation:
(1) Set NODE_ENV to production
    - Add to systemd service: Environment="NODE_ENV=production"
    - Edit /etc/systemd/system/xo-server.service
    - Reload systemd: systemctl daemon-reload &amp;&amp; systemctl restart xo-server

(2) Disable X-Powered-By header in Express.js
    - Add to XO server code: app.disable('x-powered-by');
    - This prevents "X-Powered-By: Express" header disclosure
    - Verify with: curl -I https://xo-server.domain.mil

(3) Implement custom error handler middleware
    - Create error handler that returns generic messages
    - Log full error details server-side for troubleshooting
    - Never send stack traces or internal paths to clients

(4) Configure Nginx (if used) to suppress error page details
    - Set custom error pages: error_page 404 /404.html;
    - Disable server_tokens to hide Nginx version
    - Remove default error pages that expose software versions

(5) Test error responses in production
    - Trigger 404, 500, 403 errors intentionally
    - Verify responses contain no version numbers, paths, or modules
    - Check that stack traces are not exposed

Technical Implementation:
```javascript
// Express.js production error handler (add LAST middleware)
app.disable('x-powered-by');  // Remove Express header

app.use((err, req, res, next) => {
  // Log full error details server-side
  console.error('[ERROR]', err.stack);

  // Send generic error to client
  const status = err.status || 500;
  res.status(status).json({
    error: {
      message: status === 404 ? 'Not Found' : 'Internal Server Error',
      code: status
    }
  });
});
```

Nginx Configuration:
```nginx
server {
  server_tokens off;  # Hide Nginx version

  # Custom error pages
  error_page 404 /404.html;
  error_page 500 502 503 504 /50x.html;

  location = /404.html {
    internal;
  }
  location = /50x.html {
    internal;
  }
}
```

Systemd Service File:
```ini
[Service]
Environment="NODE_ENV=production"
ExecStart=/usr/bin/node /opt/xo/xo-server/dist/cli.mjs
```

Risk: Verbose error messages expose software versions, file paths, and application internals, providing attackers with reconnaissance data to plan targeted exploits.

Reference: NIST SP 800-53r5 SI-11 (Error Handling), CCI-001312
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206413">
    <!--RuleTitle: Debugging and trace information used to diagnose the web server must be disabled.-->
    <AnswerKey Name="XO">
      <!--Session #28 (Feb 1, 2026): Debugging and trace disabled check-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with no -inspect flags and production mode enabled-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>The automated check verified that debugging and trace functionality is disabled in the production XO deployment.

XO Debug Protection Mechanisms:
(1) Node.js process runs without -inspect or -inspect-brk flags
(2) NODE_ENV=production disables verbose logging and debug output
(3) No source maps deployed to production (dist/ contains minified code only)
(4) Debug logging disabled in config.toml (no DEBUG=* environment variable)
(5) Chrome DevTools remote debugging port not exposed

Finding: Not a Finding

Justification: The automated check verified that the XO server process is running without debugging flags (-inspect, -inspect-brk). Production deployments use NODE_ENV=production which disables debug-level logging and verbose error output. Source maps (which allow reverse-engineering of minified JavaScript) are not deployed to the production server. The Chrome DevTools remote debugging protocol (typically port 9229) is not listening, preventing remote debugging access.

Risk Mitigation: Disabling debugging prevents:
- Remote code execution via Chrome DevTools protocol
- Exposure of application source code via source maps
- Information disclosure through debug logging and stack traces
- Unauthorized inspection of runtime memory and variables
- Performance degradation from debug overhead

No additional configuration required for compliant systems.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If debugging flags are not detected but source maps are deployed, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant systems with debugging enabled-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check detected that debugging or trace functionality may be enabled in the production deployment.

Required Remediation:
(1) Remove Node.js debugging flags from startup command
    - Check systemd service: systemctl cat xo-server.service
    - Remove any -inspect, -inspect-brk, --debug flags from ExecStart
    - Example INCORRECT: node -inspect /opt/xo/xo-server/dist/cli.mjs
    - Example CORRECT: node /opt/xo/xo-server/dist/cli.mjs
    - Reload: systemctl daemon-reload &amp;&amp; systemctl restart xo-server

(2) Verify Chrome DevTools debugging port is not listening
    - Check for port 9229: ss -tlnp | grep 9229
    - If listening, kill process and remove -inspect flag
    - Ensure firewall blocks port 9229 externally

(3) Remove source maps from production deployment
    - Delete all .map files: find /opt/xo -name "*.js.map" -delete
    - Verify dist/ directory contains only minified .js files
    - Rebuild with production settings if necessary

(4) Disable debug logging in config.toml
    - Edit /opt/xo/xo-server/config.toml or /etc/xo-server/config.toml
    - Remove or comment out any DEBUG environment variables
    - Set log level to 'info' or 'warn' (not 'debug' or 'trace')

(5) Set NODE_ENV to production
    - Add to systemd service: Environment="NODE_ENV=production"
    - Verify with: systemctl show xo-server | grep NODE_ENV

(6) Test for debug information exposure
    - Attempt to connect Chrome DevTools to server
    - Check HTTP responses for source map references
    - Verify error responses don't include stack traces

Technical Implementation:
```ini
# Correct systemd service configuration
[Service]
Environment="NODE_ENV=production"
ExecStart=/usr/bin/node /opt/xo/xo-server/dist/cli.mjs
# NO -inspect flags
```

Source Map Removal:
```bash
# Remove all source maps from production
find /opt/xo -name "*.js.map" -type f -delete

# Verify removal
find /opt/xo -name "*.js.map"  # Should return nothing
```

Config.toml Example:
```toml
# Disable debug logging
[http]
  # No DEBUG environment variable

# Set appropriate log level
[log]
  level = "info"  # Not "debug" or "trace"
```

Firewall Protection:
```bash
# Block Chrome DevTools debugging port
ufw deny 9229/tcp
iptables -A INPUT -p tcp --dport 9229 -j DROP
```

Risk: Enabled debugging exposes the Chrome DevTools remote debugging protocol (port 9229), allowing attackers to execute arbitrary code, inspect memory, set breakpoints, and extract sensitive data. Source maps enable reverse-engineering of application logic.

Reference: NIST SP 800-53r5 SI-11 (Error Handling), CM-7 (Least Functionality), CCI-001312
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206414">
    <!--RuleTitle: The web server must set an absolute session timeout value of eight hours or less.-->
    <AnswerKey Name="XO">
      <!--Session #28 (Feb 1, 2026): Absolute session timeout check-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with timeout ≤28,800,000 milliseconds (8 hours)-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>The automated check verified that XO enforces an absolute session timeout of 8 hours or less.

XO Absolute Session Timeout Configuration:
(1) Config.toml maxAge setting ≤28,800,000 milliseconds (8 hours)
(2) Redis session store enforces absolute expiration
(3) Session cookie maxAge attribute limits client-side lifetime
(4) Server-side session expiration enforced regardless of activity
(5) DoD requirement: Sessions must terminate after 8 hours absolute time

Finding: Not a Finding

Justification: The automated check verified that the session maxAge configuration in config.toml is set to 28,800,000 milliseconds or less (equivalent to 8 hours). XO uses Redis for session storage, which enforces absolute session expiration through TTL (Time To Live) settings. Unlike inactivity timeouts (which reset on user activity), the absolute timeout ensures that sessions are terminated after a fixed duration regardless of user activity level. This prevents indefinite session persistence and reduces the window of opportunity for session hijacking attacks.

DoD Requirement Context:
- Maximum absolute timeout: 8 hours (28,800,000 ms)
- Recommended: 4 hours (14,400,000 ms) for high-value systems
- Sessions exceeding 8 hours require re-authentication
- Complements inactivity timeout (typically 15 minutes)

Risk Mitigation: Absolute session timeout prevents:
- Indefinite session persistence across multiple days
- Prolonged exposure from compromised session tokens
- Session fixation attacks with long-lived tokens
- Unauthorized access from unattended workstations
- Compliance violations for DoD information systems

No additional configuration required for compliant systems.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If timeout is configured but organizational policy is not documented, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant systems with timeout >8 hours or not configured-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check detected that the absolute session timeout exceeds 8 hours or is not configured.

Required Remediation:
(1) Configure absolute session timeout in config.toml
    - Edit: /opt/xo/xo-server/config.toml or /etc/xo-server/config.toml
    - Locate [http.cookies] section or create if missing
    - Set maxAge to ≤28,800,000 milliseconds (8 hours)

(2) DoD Timeout Requirements:
    - Maximum absolute timeout: 8 hours (28,800,000 ms)
    - Recommended for classified systems: 4 hours (14,400,000 ms)
    - Recommended for unclassified systems: 8 hours (28,800,000 ms)
    - Must work in conjunction with inactivity timeout (15 minutes)

(3) Verify Redis session expiration
    - Redis automatically enforces session TTL based on maxAge
    - Check Redis: redis-cli KEYS "sess:*" | head -n 1 | xargs redis-cli TTL
    - TTL should be ≤28,800 seconds (8 hours)

(4) Test absolute timeout enforcement
    - Authenticate to XO web interface
    - Keep session active (periodic clicks) for >8 hours
    - Verify session is terminated and re-authentication is required
    - Check that activity does NOT extend session beyond maxAge

(5) Restart XO server to apply changes
    - systemctl restart xo-server
    - Verify new sessions use updated timeout
    - Test session expiration with new timeout value

Technical Implementation:
```toml
# /opt/xo/xo-server/config.toml or /etc/xo-server/config.toml
[http.cookies]
  # Absolute session timeout: 8 hours (28,800,000 ms)
  maxAge = 28800000  # 8 hours = 8 * 60 * 60 * 1000

  # For classified/high-value systems, use 4 hours:
  # maxAge = 14400000  # 4 hours = 4 * 60 * 60 * 1000

  # Other recommended settings
  secure = true      # HTTPS-only cookies
  httpOnly = true    # Prevent JavaScript access
  sameSite = "strict"  # CSRF protection
```

Session Timeout Relationship:
```
Absolute Timeout (maxAge): Session ends after FIXED duration
  - User logs in at 09:00
  - Session expires at 17:00 (8 hours later) regardless of activity
  - User must re-authenticate even if actively using XO

Inactivity Timeout (rolling): Session ends after IDLE period
  - User logs in at 09:00
  - User idle for 15 minutes at 10:30
  - Session expires at 10:45 (15 minutes idle)
  - Activity resets inactivity timer but NOT absolute timer

Both timeouts work together:
  - Session expires when EITHER condition is met
  - Inactivity timeout: 15 minutes idle
  - Absolute timeout: 8 hours total (regardless of activity)
```

Verification Commands:
```bash
# Check current maxAge setting
grep -A 5 "\[http.cookies\]" /opt/xo/xo-server/config.toml

# Check Redis session TTL
redis-cli KEYS "sess:*" | head -n 1 | xargs redis-cli TTL
# Should return ≤28800 seconds

# Monitor session expiration
redis-cli MONITOR | grep sess:
```

Risk: Sessions exceeding 8 hours increase the risk of session hijacking, credential theft from unattended workstations, and prolonged unauthorized access from compromised tokens. DoD policy requires absolute session termination to limit exposure windows.

Reference: NIST SP 800-53r5 AC-12 (Session Termination), DoD 8500.01 (Cybersecurity), CCI-002361
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206415">
    <!--RuleTitle: The web server must set an inactive timeout for sessions.-->
    <AnswerKey Name="XO">
      <!--Session #28 (Feb 1, 2026): Inactive session timeout check-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with risk-appropriate inactivity timeout and rolling=true-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>The automated check verified that XO enforces an inactive session timeout appropriate for the system's risk level.

XO Inactive Session Timeout Configuration:
(1) Config.toml inactivity timeout configured (typically 900,000 ms / 15 minutes)
(2) Session cookie rolling=true (resets timeout on user activity)
(3) Redis session store enforces inactivity expiration via TTL updates
(4) Server-side timeout enforcement (client-side cookie expiration is secondary)
(5) DoD risk-based requirements: ≤5 min (high), ≤10 min (medium), ≤20 min (low)

Finding: Not a Finding

Justification: The automated check verified that the session inactivity timeout is configured in config.toml and set to an appropriate value based on the system's risk classification. The rolling=true setting ensures that the timeout is reset on each user activity (API request), preventing active sessions from expiring. XO uses Redis for session storage, which updates the session TTL on each access when rolling sessions are enabled. This implements a true inactivity timeout where sessions only expire after a period of idle time, not during active use.

DoD Risk-Based Timeout Requirements:
- High Risk (Classified, PII, critical infrastructure): ≤5 minutes (300,000 ms)
- Medium Risk (Unclassified sensitive, general admin access): ≤10 minutes (600,000 ms)
- Low Risk (Public-facing, read-only, non-sensitive): ≤20 minutes (1,200,000 ms)
- Typical XO deployment: 15 minutes (900,000 ms) - suitable for medium-risk

Risk Mitigation: Inactivity timeout prevents:
- Unauthorized access from unattended workstations
- Session hijacking from temporarily abandoned sessions
- Credential theft from inactive but logged-in users
- Compliance violations for DoD information systems
- Extended exposure windows for compromised credentials

No additional configuration required for compliant systems.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If inactivity timeout is configured but organizational risk classification is not documented, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant systems with timeout exceeding risk thresholds or rolling disabled-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check detected that the inactivity timeout exceeds risk-based thresholds or rolling sessions are disabled.

Required Remediation:
(1) Configure inactivity timeout in config.toml based on risk level
    - Edit: /opt/xo/xo-server/config.toml or /etc/xo-server/config.toml
    - Locate [http.cookies] section or create if missing
    - Set timeout and rolling based on system risk classification

(2) DoD Risk-Based Timeout Requirements:
    - High Risk (Classified, PII, critical systems): ≤5 minutes (300,000 ms)
    - Medium Risk (Unclassified sensitive): ≤10 minutes (600,000 ms)
    - Low Risk (Public-facing, read-only): ≤20 minutes (1,200,000 ms)
    - Default recommendation: 15 minutes (900,000 ms)

(3) Enable rolling sessions (required for inactivity timeout)
    - Set rolling=true in config.toml
    - This resets timeout on each user activity
    - Without rolling, sessions expire after fixed duration regardless of activity

(4) Determine system risk classification
    - High Risk: Manages classified VMs, contains PII, critical infrastructure
    - Medium Risk: Manages unclassified sensitive VMs, general admin access
    - Low Risk: Read-only access, non-sensitive VM monitoring
    - Coordinate with organizational ISSO/ISSM for risk determination

(5) Verify Redis session TTL updates on activity
    - Monitor Redis: redis-cli MONITOR | grep sess:
    - Perform user activity (click, API call)
    - Verify Redis session TTL is reset (EXPIRE command)

(6) Test inactivity timeout enforcement
    - Authenticate to XO web interface
    - Remain idle (no clicks) for timeout duration
    - Verify session expires and re-authentication is required
    - Test that activity (clicks) resets the timeout

(7) Restart XO server to apply changes
    - systemctl restart xo-server
    - Verify new sessions use updated timeout
    - Test both idle expiration and activity-based renewal

Technical Implementation:
```toml
# /opt/xo/xo-server/config.toml or /etc/xo-server/config.toml
[http.cookies]
  # Inactivity timeout (risk-based selection):

  # HIGH RISK (Classified, PII, critical infrastructure)
  # timeout = 300000      # 5 minutes = 5 * 60 * 1000

  # MEDIUM RISK (Unclassified sensitive, general admin)
  timeout = 900000        # 15 minutes = 15 * 60 * 1000

  # LOW RISK (Public-facing, read-only, non-sensitive)
  # timeout = 1200000     # 20 minutes = 20 * 60 * 1000

  # Enable rolling sessions (REQUIRED for inactivity timeout)
  rolling = true          # Reset timeout on user activity

  # Absolute timeout (works with inactivity timeout)
  maxAge = 28800000       # 8 hours absolute maximum

  # Security settings
  secure = true           # HTTPS-only cookies
  httpOnly = true         # Prevent JavaScript access
  sameSite = "strict"     # CSRF protection
```

Inactivity vs Absolute Timeout:
```
Inactivity Timeout (rolling=true):
  - User logs in at 09:00
  - User active until 10:30, then idle
  - Session expires at 10:45 (15 minutes idle)
  - Activity resets timer (prevents expiration during active use)

Absolute Timeout (maxAge):
  - User logs in at 09:00
  - Session expires at 17:00 (8 hours total)
  - Activity does NOT reset absolute timer
  - Forces re-authentication after 8 hours regardless of activity

Both timeouts work together:
  - Session expires when EITHER condition is met
  - Whichever occurs first triggers session termination
```

Risk Classification Decision Matrix:
```
System Characteristics               | Risk Level | Timeout
-------------------------------------|-----------|----------
Manages classified VMs               | HIGH      | 5 min
Contains PII or PHI                  | HIGH      | 5 min
Critical infrastructure (DoD)        | HIGH      | 5 min
Unclassified sensitive VMs           | MEDIUM    | 10-15 min
General admin access (non-PII)       | MEDIUM    | 10-15 min
Read-only monitoring access          | LOW       | 15-20 min
Public-facing (if applicable)        | LOW       | 15-20 min
```

Verification Commands:
```bash
# Check current timeout and rolling settings
grep -A 10 "\[http.cookies\]" /opt/xo/xo-server/config.toml

# Monitor Redis session TTL updates
redis-cli MONITOR | grep -E "EXPIRE|TTL"

# Check specific session TTL
redis-cli KEYS "sess:*" | head -n 1 | xargs redis-cli TTL
# Should decrease when idle, reset when active (if rolling=true)

# Test session activity
# Terminal 1: Monitor Redis
redis-cli MONITOR

# Terminal 2: Trigger XO API activity
curl -X GET https://xo-server/api/stats -H "Cookie: connect.sid=&lt;session_id&gt;"
# Watch Terminal 1 for EXPIRE command resetting TTL
```

Risk: Without proper inactivity timeout, unattended workstations remain authenticated indefinitely, allowing unauthorized access. Timeouts exceeding risk-based thresholds violate DoD security policy and increase exposure windows for compromised sessions.

Reference: NIST SP 800-53r5 AC-12 (Session Termination), DoD 8500.01, CCI-002361, CCI-001133
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206416">
    <!--RuleTitle: The web server must restrict inbound connections from nonsecure zones.-->
    <AnswerKey Name="XO">
      <!--Session #32 Batch 2 (Feb 2, 2026): Remote access policy verification-->
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with documented remote access policy-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra remote access policy has been verified and documented by this organization.

The automated check verified remote access infrastructure:
(1) Firewall configuration reviewed (UFW/iptables)
(2) Network segmentation verified (management VLAN isolation)
(3) Access control lists (ACLs) documented
(4) Remote access monitoring implemented
(5) VPN/secure tunnel requirements enforced

Finding: Not a Finding

Justification: This organization has defined and documented the remote access policy for Xen Orchestra per NIST SP 800-53r5 AC-17 (Remote Access). The policy restricts remote access to authorized personnel using DoD-approved encryption and multifactor authentication.

Remote access policy:
- Authorized users: [organizational list]
- Access methods: VPN, SSH with CAC/PIV, HTTPS with MFA
- Monitoring: All remote sessions logged to SIEM
- Documentation: Security plan Section [X.X]

No additional configuration or remediation required for systems with documented remote access policy.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but remote access policy is not documented, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant or undocumented systems requiring remote access policy-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check detected remote access infrastructure but cannot verify organizational remote access policy is defined and documented.

Required Manual Verification:
(1) Define organizational remote access policy
    - Identify authorized personnel for remote access
    - Specify DoD-approved access methods (VPN, SSH with CAC, etc.)
    - Document multifactor authentication requirements
    - Define access hours and emergency procedures

(2) Implement network segmentation for management interface
    - Place Xen Orchestra on dedicated management VLAN
    - Configure firewall rules to restrict access from untrusted networks
    - Example UFW rule (allow SSH from VPN subnet only):
      ufw allow from 10.0.10.0/24 to any port 22 proto tcp
      ufw allow from 10.0.10.0/24 to any port 443 proto tcp

(3) Configure VPN or secure tunnel for remote access
    - Require VPN connection before accessing XO web interface
    - Use IPsec, SSL/TLS VPN, or SSH tunneling
    - Enforce MFA for VPN authentication

(4) Implement monitoring for remote access sessions
    - Configure SIEM alerts for remote login attempts
    - Log source IP, username, timestamp, and session duration
    - Define baseline for normal remote access patterns

(5) Document remote access policy in security plan
    - List of authorized remote users and roles
    - Access methods and authentication requirements
    - Monitoring and incident response procedures

Re-run scan after policy documentation complete.

Note: DoD requires remote access to be restricted to authorized personnel using DoD-approved encryption and multifactor authentication per NIST SP 800-53r5 AC-17.
        </ValidTrueComment>
        <ValidFalseStatus>NotAFinding</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but remote access policy is documented and enforced, manual verification required to confirm policy meets DoD requirements.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206417">
    <!--RuleTitle: The web server must restrict connections from nonsecure zones.-->
    <AnswerKey Name="XO">
      <!--Session #32 Batch 2 (Feb 2, 2026): Nonsecure zone connection restriction-->
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with verified network segmentation-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra network segmentation has been verified and documented by this organization.

The automated check verified network security:
(1) Firewall active and configured (UFW/iptables/nftables)
(2) Management VLAN isolation implemented
(3) Access restricted to trusted networks only
(4) No connections from nonsecure zones (DMZ, Internet) allowed
(5) Deny-by-default firewall policy enforced

Finding: Not a Finding

Justification: This organization has implemented network segmentation per DoD Zero Trust Architecture principles and NIST SP 800-207. Xen Orchestra is isolated on a dedicated management VLAN (VLAN [X]) with firewall rules restricting access to authorized administrative networks only.

Network segmentation configuration:
- Management VLAN: [VLAN ID and subnet]
- Allowed source networks: [internal admin subnets]
- Firewall policy: Deny all, allow specific (whitelist)
- Documentation: Network security architecture diagram

No additional configuration or remediation required for systems with verified network segmentation.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but network segmentation is not documented, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant systems without firewall or network segmentation-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check could not verify that connections from nonsecure zones are restricted.

Required Manual Verification:
(1) Enable and configure firewall on XO server
    - For XOA (Debian-based): UFW is enabled by default
      ufw status
      ufw enable
    - For XOCE: Install and configure UFW or iptables
      apt-get install ufw
      ufw default deny incoming
      ufw default allow outgoing

(2) Implement deny-by-default firewall policy
    - Block all incoming connections by default
    - Allow only specific trusted networks/IP addresses
    - Example UFW rules (allow admin subnet only):
      ufw allow from 10.0.10.0/24 to any port 22 proto tcp
      ufw allow from 10.0.10.0/24 to any port 443 proto tcp
      ufw allow from 10.0.10.0/24 to any port 80 proto tcp

(3) Verify XO is on dedicated management VLAN
    - Use separate VLAN for management traffic
    - Do NOT place XO on DMZ or Internet-facing network
    - Document VLAN assignment in network diagram

(4) Configure XO to listen on management interface only
    - In /opt/xo/xo-server/config.toml (XOCE) or /etc/xo-server/config.toml (XOA):
      [http]
      listen = [
        { port = 80, host = '10.0.10.X' },  # Management IP
        { port = 443, host = '10.0.10.X', cert = '/path/to/cert.pem', key = '/path/to/key.pem' }
      ]
    - Replace '0.0.0.0' or '::' with specific management IP

(5) Document network security architecture
    - Network diagram showing VLAN segmentation
    - Firewall ruleset with justification for each allow rule
    - Access control matrix (who can access from where)

Restart XO service after configuration changes:
  systemctl restart xo-server

Re-run scan to verify firewall active and configured.

WARNING: Systems without firewall or network segmentation are vulnerable to unauthorized access from nonsecure zones (DMZ, Internet). This is a HIGH RISK finding requiring immediate remediation.
        </ValidTrueComment>
        <ValidFalseStatus>NotAFinding</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but firewall and network segmentation are verified, manual verification required to confirm configuration meets DoD requirements.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206418">
    <!--RuleTitle: The web server must immediately disconnect or disable remote access to the information system.-->
    <AnswerKey Name="XO">
      <!--Session #32 Batch 2 (Feb 2, 2026): Immediate disconnect capability-->
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with documented disconnect procedures-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra immediate disconnect procedures have been verified and documented by this organization.

The automated check verified disconnect capabilities:
(1) Firewall active with ability to add/remove rules in real-time
(2) XO service can be stopped immediately (systemctl stop)
(3) Individual sessions can be terminated via XO API
(4) Network interface can be disabled if needed
(5) Documented emergency disconnect procedures available

Finding: Not a Finding

Justification: This organization has documented and tested emergency disconnect procedures for Xen Orchestra per NIST SP 800-53r5 AC-12(2) (Session Termination - Immediate Disconnect). Multiple methods are available for immediate disconnection during security incidents.

Emergency disconnect procedures:
- Method 1: Firewall rule addition (blocks all incoming connections)
  ufw deny from any to any port 80,443 proto tcp
- Method 2: Service shutdown (stops XO Server immediately)
  systemctl stop xo-server
- Method 3: Session termination (individual user disconnection via API)
- Method 4: Network interface shutdown (last resort)
  ip link set eth0 down

Procedures tested: [Date of last test]
Documentation: Incident response plan Section [X.X]

No additional configuration or remediation required for systems with documented disconnect procedures.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but emergency disconnect procedures are not documented, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant or undocumented systems requiring disconnect procedures-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check detected disconnect capabilities but cannot verify organizational procedures are documented and tested.

Required Manual Verification:
(1) Document emergency disconnect procedures
    - Define incident scenarios requiring immediate disconnect
    - List authorized personnel to execute disconnect
    - Specify primary and backup disconnect methods
    - Include contact information and escalation paths

(2) Test immediate disconnect methods (verify functionality)
    - Method 1: Firewall rule addition (fastest)
      ufw insert 1 deny from any to any port 80,443 proto tcp
      ufw status numbered  # Verify rule added
      ufw delete [rule number]  # Remove test rule

    - Method 2: Service shutdown
      systemctl stop xo-server
      systemctl status xo-server  # Verify stopped
      systemctl start xo-server  # Restart after test

    - Method 3: Individual session termination (XO API)
      curl -X POST https://xo.example.com/api/session.signOut \
        -H "Authorization: Bearer YOUR_TOKEN" \
        -d '{"id": "SESSION_ID"}'

    - Method 4: Network interface shutdown (last resort)
      ip link set eth0 down
      ip link set eth0 up  # Restore after test

(3) Create runbook for security incident response
    - Step-by-step procedures for each disconnect method
    - Decision tree for choosing appropriate method
    - Rollback procedures to restore service
    - Post-incident analysis requirements

(4) Train authorized personnel on disconnect procedures
    - Conduct tabletop exercises
    - Perform actual disconnect tests (during maintenance window)
    - Document training completion
    - Update procedures based on lessons learned

(5) Integrate disconnect procedures into incident response plan
    - Define triggering events (e.g., active breach, unauthorized access)
    - Establish notification requirements (ISSM/ISSO)
    - Document in security plan Section [X.X]
    - Review and update annually

Re-run scan after documentation complete.

Note: DoD requires capability for immediate disconnect during security incidents per NIST SP 800-53r5 AC-12(2). Procedures must be documented, tested, and readily available to authorized personnel.
        </ValidTrueComment>
        <ValidFalseStatus>NotAFinding</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but emergency disconnect procedures are documented and tested, manual verification required to confirm procedures meet DoD requirements.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206421">
    <!--RuleTitle: The web server must allocate log record storage capacity in accordance with organization-defined log record storage requirements.-->
    <AnswerKey Name="XO">
      <!--Session #32 Batch 2 (Feb 2, 2026): Log storage capacity planning-->
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with documented log storage capacity-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra log storage capacity has been planned and documented by this organization.

The automated check verified log storage infrastructure:
(1) Log directory identified (/var/log/xo-server or /var/lib/xo-server/logs)
(2) Available disk space calculated
(3) Log rotation configured (logrotate or systemd journal)
(4) Estimated log generation rate documented
(5) Retention period meets organizational requirements

Finding: Not a Finding

Justification: This organization has defined log record storage requirements per NIST SP 800-53r5 AU-4 (Audit Storage Capacity) and allocated sufficient storage capacity for Xen Orchestra logs based on:
- Average log generation rate: [X MB/day]
- Required retention period: [Y days/months per policy]
- Total storage allocated: [Z GB]
- Current utilization: [N%]

Log storage configuration:
- Log directory: [path]
- Partition size: [size]
- Log rotation: Daily, keep [N] days
- Monitoring: SIEM alerts at 80% capacity
- Documentation: Security plan Section [X.X]

No additional configuration or remediation required for systems with documented log storage capacity.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but log storage capacity is not documented, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant or undocumented systems requiring log storage capacity planning-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check identified log storage location but cannot verify organizational storage capacity requirements are defined and met.

Required Manual Verification:
(1) Calculate log generation rate (baseline measurement)
    - Monitor log growth for 7-14 days
      du -sh /var/log/xo-server  # Initial size
      (wait 24 hours)
      du -sh /var/log/xo-server  # Check growth
    - Example calculation:
      Daily growth: 50 MB/day
      Weekly growth: 350 MB/week
      Monthly growth: 1.5 GB/month

(2) Define organizational log retention period
    - DoD minimum: 1 year for privileged access logs
    - Consider compliance requirements (FISMA, PCI-DSS, etc.)
    - Balance retention needs with storage costs
    - Document retention period in security plan

(3) Calculate required storage capacity
    - Formula: Daily growth × Retention days × Safety margin (1.5x)
    - Example:
      50 MB/day × 365 days × 1.5 = 27.4 GB required

(4) Verify sufficient disk space allocated
    - Check current partition size and available space:
      df -h /var/log
    - If insufficient, expand partition or add dedicated log partition
      lvcreate -L 50G -n lv_logs vg_system
      mkfs.ext4 /dev/vg_system/lv_logs
      mount /dev/vg_system/lv_logs /var/log/xo-server

(5) Configure log rotation to prevent disk exhaustion
    - For XOA (systemd journal):
      # In /etc/systemd/journald.conf
      SystemMaxUse=10G
      SystemKeepFree=2G
      MaxRetentionSec=31536000  # 1 year
      systemctl restart systemd-journald

    - For XOCE (logrotate):
      # Create /etc/logrotate.d/xo-server
      /var/log/xo-server/*.log {
        daily
        rotate 365
        compress
        delaycompress
        notifempty
        create 0640 root root
        sharedscripts
        postrotate
          systemctl reload xo-server &gt; /dev/null
        endscript
      }

(6) Implement monitoring for log storage capacity
    - Configure SIEM alerts for disk space:
      Alert at 80% capacity (warning)
      Alert at 90% capacity (critical)
    - Automate reports on log growth trends
    - Define procedures for expanding storage

(7) Document log storage capacity in security plan
    - Log generation rate baseline
    - Retention period and justification
    - Total storage allocated
    - Monitoring and alerting procedures

Re-run scan after capacity planning documentation complete.

Note: DoD requires 1-year minimum retention for privileged access logs per NIST SP 800-53r5 AU-11 (Audit Record Retention). Plan for sufficient storage to meet this requirement without log loss.
        </ValidTrueComment>
        <ValidFalseStatus>NotAFinding</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but log storage capacity is documented and sufficient, manual verification required to confirm configuration meets DoD requirements.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206422">
    <!--RuleTitle: The web server must off-load log records onto a different system or media than the system being logged.-->
    <AnswerKey Name="XO">
      <!--Session #32 Batch 2 (Feb 2, 2026): Log offload to separate system/media-->
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with verified log offload-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra log offload to separate system/media has been verified and documented by this organization.

The automated check verified log offload infrastructure:
(1) Syslog client configured (rsyslog/syslog-ng) forwarding to remote server
(2) Remote syslog server configured and reachable
(3) XO logs forwarded to centralized logging system (SIEM/Splunk/ELK)
(4) Backup logs to separate storage media (NFS/SAN/tape)
(5) Log forwarding tested and operational

Finding: Not a Finding

Justification: This organization has implemented centralized log management per NIST SP 800-53r5 AU-4(1) (Audit Storage Capacity - Transfer to Alternate Storage). Xen Orchestra logs are offloaded to:
- Primary: Centralized SIEM server ([hostname/IP])
- Backup: Network storage ([NFS/SAN path])
- Method: rsyslog forwarding over TLS

Log offload configuration:
- Remote syslog server: [hostname:port]
- Forwarding protocol: Syslog over TLS (RFC 5425)
- Backup destination: [NFS/SAN path]
- Forwarding verified: [Date of last test]
- Documentation: Security plan Section [X.X]

No additional configuration or remediation required for systems with verified log offload.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but log offload is not documented, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant systems without log offload-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check could not verify that logs are offloaded to a different system or media.

Required Manual Verification:
(1) Deploy or identify centralized log server (SIEM/syslog server)
    - Recommended solutions: Splunk, ELK Stack, rsyslog server, Graylog
    - Ensure log server is on different physical system
    - Document log server hostname/IP in security plan

(2) Configure rsyslog on XO server to forward logs
    - Install rsyslog (usually installed by default on Debian):
      apt-get install rsyslog rsyslog-gnutls

    - Configure log forwarding in /etc/rsyslog.d/50-xo-forward.conf:
      # Forward XO logs to remote syslog server
      $ModLoad imfile
      $InputFileName /var/log/xo-server/xo-server.log
      $InputFileTag xo-server:
      $InputFileStateFile stat-xo-server
      $InputFileSeverity info
      $InputRunFileMonitor

      # Forward to remote syslog server over TLS (preferred)
      $DefaultNetstreamDriver gtls
      $ActionSendStreamDriverMode 1
      $ActionSendStreamDriverAuthMode x509/name
      $ActionSendStreamDriverPermittedPeer syslog-server.example.com
      *.* @@syslog-server.example.com:6514

    - Restart rsyslog:
      systemctl restart rsyslog

(3) Configure XO Server to log to syslog
    - In /opt/xo/xo-server/config.toml (XOCE) or /etc/xo-server/config.toml (XOA):
      [logs]
      syslog = "local"  # Send to local syslog (then rsyslog forwards)

    - Restart XO:
      systemctl restart xo-server

(4) Verify log forwarding operational
    - Generate test log entry:
      logger -t xo-server "Test log forwarding to remote syslog server"

    - Check log appears on remote server:
      ssh syslog-server "tail -f /var/log/xo-server.log"

    - Verify no errors in rsyslog:
      journalctl -u rsyslog -n 50

(5) Configure backup to separate storage media (defense in depth)
    - Mount network storage (NFS/CIFS):
      mkdir -p /mnt/log-backup
      mount -t nfs syslog-server.example.com:/backup/xo-logs /mnt/log-backup
      echo "syslog-server.example.com:/backup/xo-logs /mnt/log-backup nfs defaults 0 0" &gt;&gt; /etc/fstab

    - Configure logrotate to copy rotated logs to backup:
      # In /etc/logrotate.d/xo-server
      /var/log/xo-server/*.log {
        daily
        rotate 365
        compress
        delaycompress
        notifempty
        create 0640 root root
        sharedscripts
        postrotate
          cp /var/log/xo-server/*.log.1.gz /mnt/log-backup/ 2&gt;/dev/null || true
          systemctl reload xo-server &gt; /dev/null
        endscript
      }

(6) Document log offload configuration in security plan
    - Centralized log server information
    - Forwarding protocol and encryption (TLS preferred)
    - Backup storage location
    - Verification procedures and test results

Re-run scan after log offload configuration complete.

WARNING: Storing logs only on the system being logged creates single point of failure. If system is compromised, attacker can delete logs to hide evidence. Log offload to separate system is REQUIRED per DoD STIG and NIST SP 800-53r5 AU-4(1).
        </ValidTrueComment>
        <ValidFalseStatus>NotAFinding</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but log offload is verified, manual verification required to confirm configuration meets DoD requirements (separate system/media, not just separate partition).</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
      <Vuln ID="V-206425">
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>The automated check verified that Xen Orchestra web server generates log records using UTC or GMT timestamps, satisfying DoD requirements for forensic analysis and cross-system correlation. The check examined five key areas: (1) Winston logger timezone configuration in config.toml files, confirming UTC settings; (2) System timezone via timedatectl, verifying UTC/GMT/Etc/UTC configuration; (3) Node.js TZ environment variables in running processes; (4) Sample log timestamps showing ISO 8601 format with Z suffix or +00:00 offset; and (5) /etc/timezone file contents. All timestamps detected use UTC/GMT format, enabling accurate forensic correlation across distributed systems without timezone conversion. This configuration meets SRG-APP-000374-WSR-000172 requirements for establishing event time in forensic analysis. The system has been configured correctly to support incident response and security event correlation.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check detected local time zone configuration instead of UTC/GMT timestamps, failing to meet DoD requirements for forensic analysis. Evidence examined includes: (1) Winston logger configuration showing local timezone settings (e.g., America/New_York, US/Eastern); (2) System timezone via timedatectl reporting non-UTC zones; (3) Log samples showing timezone offsets other than +00:00 (e.g., -05:00 for EST); and (4) /etc/timezone containing regional timezone identifiers. This configuration impairs forensic correlation as timestamps require manual timezone conversion when comparing events across systems. REMEDIATION: Execute 'timedatectl set-timezone UTC' to configure system for UTC timestamps. Restart XO server with 'systemctl restart xo-server'. Verify log timestamps show ISO 8601 format with Z suffix (e.g., 2026-02-03T12:00:00.000Z) not local offsets (e.g., 2026-02-03T07:00:00-05:00). Confirm changes persist across reboots by reviewing systemd journal output. Update organizational time synchronization policy to mandate UTC for all security-relevant systems.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
      <Vuln ID="V-206426">
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>The automated check performed 5 verification methods to confirm timestamp granularity compliance. CHECK 1 examined Winston logger configuration for explicit timestamp format settings, detecting ISO 8601 with milliseconds as the default. CHECK 2 analyzed sample log timestamps from /var/log/xo-server/xo-server.log and /var/log/syslog, successfully identifying millisecond-precision timestamps matching the pattern YYYY-MM-DDTHH:MM:SS.sssZ. CHECK 3 reviewed systemd journal timestamps using the short-precise output format, confirming microsecond-level precision. CHECK 4 verified Node.js Date.now() methodology, which returns milliseconds since Unix epoch by design. CHECK 5 queried the XO audit plugin via REST API to examine audit record timestamps stored as Unix millisecond values. The system demonstrates timestamp granularity of 1/1000 second (milliseconds), which exceeds the DoD requirement of ≥1 second minimum granularity. This level of precision enables accurate incident correlation, security event analysis, and audit trail reconstruction required for DoD compliance.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check detected insufficient timestamp granularity that does not meet DoD requirements. The verification process examined Winston logger configuration, sample log file timestamps, systemd journal precision, Node.js timestamp methodology, and XO audit plugin records. FAILURE CRITERIA: Either minute-level timestamps were detected (YYYY-MM-DDTHH:MMZ format without seconds), or timestamp precision could not be determined from available logs. DoD Requirement NOT MET: Timestamps must record events to a minimum granularity of one second for forensic analysis, audit trail integrity, and security event correlation. REMEDIATION STEPS: (1) Review Winston logger configuration in /opt/xo/xo-server/config.toml or /etc/xo-server/config.toml; (2) Ensure timestamp format includes seconds - Acceptable formats include ISO 8601 with seconds (YYYY-MM-DDTHH:MM:SSZ) or milliseconds (YYYY-MM-DDTHH:MM:SS.sssZ); (3) Verify log output format with journalctl -u xo-server --since '1 minute ago' | head -5; (4) If using custom logging middleware, verify format string includes seconds (%S or :ss); (5) Restart XO server service with systemctl restart xo-server; (6) Test timestamp precision by monitoring tail -f /var/log/xo-server/xo-server.log and verify timestamp format; (7) For systemd journal persistence, ensure Storage=persistent in /etc/systemd/journald.conf; (8) Document timestamp configuration in system security configuration baseline.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206427">
    <!--RuleTitle: The web server application, libraries, and configuration files must only be accessible to privileged users.-->
    <AnswerKey Name="XO">
      <!--Session #30 Phase 1 (Feb 1, 2026): File permissions and access control check-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with restricted file permissions-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra application files are accessible only to privileged users (root or authorized service accounts).

The automated check verified file and directory permissions across XO installation directories:
(1) Application directories have restrictive permissions (755 or stricter)
(2) No world-writable files detected (CRITICAL vulnerability check)
(3) File ownership restricted to root or xo-server service account
(4) Sensitive files (config, keys, secrets) have 640 or 600 permissions
(5) Configuration files protected from unauthorized modification
(6) Libraries and executables have appropriate permissions

Finding: Not a Finding

Justification: The organization has configured XO application file permissions according to DoD security requirements. Only system administrators and authorized service accounts can modify application files, libraries, and configuration files. This prevents unauthorized code injection, data theft, and service disruption.

File permission summary:
- XO directories: 755 (rwxr-xr-x) or more restrictive
- Application files: 644 (rw-r--r--) or more restrictive
- Configuration files: 640 (rw-r-----) or 600 (rw-------)
- No world-writable files detected
- Ownership: root:root or xo-server:xo-server

No additional configuration or remediation required for compliant systems.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but file permissions are actually too permissive, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant systems with weak file permissions-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check detected application file permission issues that allow unauthorized users to access or modify XO application files, libraries, or configuration files.

Identified Issues (see Finding Details for specifics):
- Directory permissions too permissive or world-writable
- Application files have weak permissions allowing group/world access
- Configuration files readable by non-privileged users
- World-writable files detected (CRITICAL security vulnerability)
- File ownership not restricted to authorized accounts

Required Remediation Steps:

(1) Fix directory permissions:
    chmod 755 /opt/xo/xo-server
    chmod 755 /opt/xo/xo-web
    chmod 755 /etc/xo-server
    chmod 755 /var/lib/xo-server

(2) Fix application file permissions:
    find /opt/xo -type f -exec chmod 644 {} \;
    find /opt/xo -type f -name "*.sh" -exec chmod 755 {} \;

(3) Secure configuration files:
    chmod 640 /opt/xo/xo-server/config.toml
    chmod 640 /etc/xo-server/config.toml
    chmod 600 /opt/xo/xo-server/.xo-cli

(4) Remove world-write permissions (if detected):
    find /opt/xo -type f -perm -002 -exec chmod o-w {} \;
    find /opt/xo -type d -perm -002 -exec chmod o-w {} \;

(5) Fix file ownership:
    chown -R root:root /opt/xo
    chown -R root:root /etc/xo-server
    # OR for service account deployment:
    chown -R xo-server:xo-server /opt/xo

(6) Verify no unauthorized user access:
    # Review /etc/group for unauthorized users in xo-related groups
    # Review sudo configuration for XO-related commands

(7) Document privileged user access procedures:
    - Maintain list of authorized administrators
    - Implement change management for application file modifications
    - Configure file integrity monitoring (e.g., AIDE, Tripwire)

Verification Commands:
  ls -la /opt/xo/xo-server
  find /opt/xo -type f -perm -002  # Should return nothing
  stat -c '%a %U:%G' /opt/xo/xo-server/config.toml

Restart XO service after permission changes (if configuration files modified):
  systemctl restart xo-server

Re-run scan to verify compliance after remediation.

DoD Requirement: Application files must be protected from unauthorized modification to prevent malicious code injection, privilege escalation, and service disruption per NIST SP 800-53r5 CM-5 (Access Restrictions for Change).
        </ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but file permissions are actually compliant, manual verification required to confirm permissions meet DoD requirements.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206432">
    <!--RuleTitle: The web server must be protected from being stopped by a non-privileged user.-->
    <AnswerKey Name="XO">
      <!--Session #25 Priority 8 Batch 3 (Feb 1, 2026): Server stop protection - systemd service control-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems where only privileged users can stop xo-server-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>The xo-server service is properly protected from being stopped by non-privileged users.

The automated check verified:
(1) Service file owned by root with secure permissions (not world-writable)
(2) No polkit rules allowing non-privileged service control
(3) No sudo rules granting passwordless service control to non-root users
(4) No user-mode systemd services allowing non-root control
(5) Process isolation properly configured (non-root process owner does not weaken service control protection)

Finding: Not a Finding

Justification: This configuration meets NIST SP 800-53r5 CM-5 (Access Restrictions for Change) and CCI-002385 requirements. Systemd restricts service control (start, stop, restart) to:
- root user (UID 0)
- Users with appropriate sudo privileges
- Users explicitly authorized via polkit rules (none detected)

The xo-server process may run as a non-root user (best practice for privilege separation), but service lifecycle control remains restricted to privileged users. This prevents:
- Denial of Service attacks by non-privileged users
- Unauthorized service manipulation
- Configuration tampering during service restart

Service control verification:
- systemctl stop xo-server: Requires root or sudo
- systemctl restart xo-server: Requires root or sudo
- Service file permissions: root:root, not world-writable

No additional configuration or remediation required.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but service control appears accessible to non-privileged users, manual verification required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant systems where non-privileged users can stop xo-server-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>FINDING: The xo-server service is NOT adequately protected from being stopped by non-privileged users.

The automated check identified one or more of the following issues:

POTENTIAL ISSUES:
(1) Service file is world-writable or not owned by root
(2) Polkit rules allow non-privileged users to control the service
(3) Sudo rules grant passwordless service control to non-root users
(4) User-mode systemd service allows non-root users to control their own xo-server instance

SECURITY IMPACT:
- An attacker with non-privileged access can cause a Denial of Service by stopping the web server
- Service manipulation could facilitate configuration tampering
- Attacker could stop service, modify configuration, then restart with malicious changes
- Violates NIST SP 800-53r5 CM-5 (Access Restrictions for Change) and CCI-002385

REQUIRED REMEDIATION ACTIONS:

1. SERVICE FILE SECURITY
   - Ensure service file is owned by root:root
     sudo chown root:root /etc/systemd/system/xo-server.service
   - Set permissions to 644 or more restrictive
     sudo chmod 644 /etc/systemd/system/xo-server.service
   - Reload systemd daemon
     sudo systemctl daemon-reload

2. POLKIT RULES
   - Review polkit rules for xo-server
     sudo find /etc/polkit-1/rules.d /usr/share/polkit-1/rules.d -name '*.rules' -exec grep -l 'xo-server' {} \;
   - Remove any rules allowing non-privileged service control
   - Restart polkit
     sudo systemctl restart polkit

3. SUDO CONFIGURATION
   - Review sudo rules
     sudo grep -r 'xo-server' /etc/sudoers /etc/sudoers.d/ | grep -v '^#'
   - Remove or restrict rules granting service control to non-privileged users
   - Ensure only authorized administrators can control the service
   - Test sudo configuration
     sudo visudo -c

4. USER-MODE SYSTEMD SERVICES
   - Disable user-mode xo-server services (if present)
     systemctl --user disable xo-server
     systemctl --user stop xo-server
   - Remove user service file (if exists)
     rm ~/.config/systemd/user/xo-server.service

5. VERIFICATION
   - Test as non-privileged user (should fail)
     systemctl stop xo-server      # Should return "Permission denied"
     systemctl restart xo-server   # Should return "Permission denied"
   - Verify only root/sudo can control service
     sudo systemctl status xo-server  # Should succeed

ORGANIZATIONAL POLICY ALIGNMENT:
- Document which administrators are authorized to control the xo-server service
- Implement role-based access control (RBAC) for system administration
- Configure audit logging for service control events
- Include service control permissions in regular security audits

Manual verification: After remediation, confirm that non-privileged users cannot execute systemctl stop/restart xo-server commands.

Status: Open - Remediation Required
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>Unexpected result from automated check. Manual verification required to determine service control access restrictions.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
      <Vuln ID="V-206433">
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>The automated check performed technical discovery across 4 verification methods to assess server tuning configuration. CHECK 1 examined Node.js memory/heap limits via NODE_OPTIONS environment variable, detecting explicit --max-old-space-size or --max-heap-size settings. CHECK 2 analyzed process-level resource limits by reading /proc/[XO_PID]/limits for the XO server process, confirming configured file descriptor, memory, and CPU quota restrictions. CHECK 3 reviewed XO configuration tuning parameters in config.toml for settings like maxMemory, heapSize, maxConnections, connectionTimeout, and requestTimeout. CHECK 4 verified systemd service resource limits using systemctl show xo-server for MemoryLimit, CPUQuota, and TasksMax directives. Technical tuning parameters were detected, indicating deliberate capacity planning for expected traffic loads. However, DoD compliance requires organizational documentation correlating these technical settings with traffic analysis, risk assessment, and ISSO/ISSM approval. The system demonstrates configured tuning parameters, but manual ISSO/ISSM review is required to verify alignment with organizational capacity planning and DoD prevention strategies.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check completed technical discovery but detected either no explicit tuning parameters OR insufficient organizational policy documentation. HYBRID CHECK RATIONALE: Technical detection cannot determine DoD compliance - even with tuning parameters present, compliance requires documented correlation between server tuning and expected user traffic loads, supported by risk analysis and ISSO/ISSM approval. REQUIRED ORGANIZATIONAL DOCUMENTATION: (1) Traffic Analysis &amp; Capacity Planning documenting expected concurrent users, request rates, peak traffic patterns, and historical load data; (2) Risk Assessment for DoS Scenarios analyzing denial-of-service attack vectors, resource exhaustion risks, and mitigation strategies; (3) Tuning Parameter Justification documenting rationale for Node.js heap limits, connection pools, timeout values, and systemd resource restrictions; (4) Load Testing Results providing evidence of performance testing validating tuning effectiveness under stress conditions; (5) Change Management Records showing Configuration Control Board (CCB) approval for tuning modifications; (6) Periodic Review Documentation verifying tuning parameters are reassessed when traffic patterns change. REMEDIATION STEPS (Technical): Configure Node.js memory limits with NODE_OPTIONS="--max-old-space-size=4096" (4GB heap); Set systemd resource limits in /etc/systemd/system/xo-server.service.d/override.conf with MemoryLimit=8G, CPUQuota=400%, TasksMax=4096; Configure XO connection limits in config.toml with maxConnections=1000, requestTimeout=30000; Apply ulimit settings in /etc/security/limits.conf for xo-server user; Reload systemd and restart service with systemctl daemon-reload &amp;&amp; systemctl restart xo-server; Document all settings in organizational tuning policy with traffic analysis justification.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206435">
    <!--RuleTitle: The web server must transmit session identifiers using SSL/TLS.-->
    <AnswerKey Name="XO">
      <!--Phase 1: Session security check - session IDs transmitted only via HTTPS-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO transmits session IDs exclusively over HTTPS with Secure cookie flag.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra properly transmits session identifiers exclusively over SSL/TLS encrypted connections. The automated check confirmed: (1) HTTPS listener configured on port 443 (TLS 1.2 or 1.3), (2) Secure cookie flag enabled (prevents transmission over HTTP), (3) HTTP to HTTPS redirect enforced (optional but recommended), (4) No plain HTTP session transmission possible. Technical Implementation: TLS/HTTPS listener active using Node.js HTTPS module or reverse proxy, session cookies have Secure flag set (config.toml or Express.js defaults), session IDs only included in HTTPS requests (browser enforces Secure flag), any HTTP requests redirect to HTTPS before session establishment. This configuration meets STIG SRG-APP-000014-WSR-000006 requirements for transmitting session identifiers via SSL/TLS. Session cookies cannot be transmitted over unencrypted HTTP connections, preventing session hijacking via network eavesdropping. The organization has verified that XO Server transmits all session identifiers exclusively over encrypted HTTPS connections with proper Secure cookie flag configuration.</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>The automated check confirmed HTTPS session transmission. This comment should not normally appear.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--HTTP detected or Secure flag missing - remediation required.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check detected that Xen Orchestra may be transmitting session identifiers over unencrypted HTTP or without proper Secure cookie flag configuration. Remediation is required to meet STIG SRG-APP-000014-WSR-000006 compliance. FINDING: Session IDs may be transmitted insecurely. Required Remediation Steps: (1) Configure HTTPS/TLS for XO Server in config.toml with certificate and key paths, (2) Enable Secure cookie flag with secure=true, httpOnly=true, sameSite=strict, (3) Enforce HTTP to HTTPS redirect with redirectToHttps=true or Nginx reverse proxy configuration, (4) Verify TLS configuration with openssl s_client, (5) Validate Secure cookie flag in browser DevTools, (6) Test session protection by attempting HTTP access. Restart XO Server after configuration changes with systemctl restart xo-server. RISK: Session identifiers transmitted over unencrypted HTTP can be intercepted via network eavesdropping (man-in-the-middle attacks), allowing session hijacking and unauthorized access. Workaround: If organizational policy allows HTTP for specific use cases, document risk acceptance and implement compensating controls (VPN, isolated network segment, etc.). However, DoD environments typically require HTTPS-only access per NIST SP 800-52 Rev 2.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but manual verification confirms HTTPS &amp;&amp; Secure flag are properly configured, contact system administrator.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206436">
    <!--RuleTitle: Cookies exchanged between the web server and the client, such as session cookies, must not be compressed.-->
    <AnswerKey Name="XO">
      <!--Phase 1: Session security check - cookie compression vulnerability (CRIME/BREACH)-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO does not compress cookies - CRIME/BREACH attacks mitigated.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra does not compress session cookies, properly mitigating CRIME and BREACH compression-based attacks. The automated check confirmed: (1) No compression middleware applied to cookies, (2) Express.js compression middleware (if present) excludes Cookie headers, (3) HTTP response headers do not indicate cookie compression, (4) Session cookies transmitted as plain text (not gzip/deflate compressed). Technical Implementation: Express.js does not compress cookies by default, compression middleware (if configured) only applies to response body not headers, cookie headers remain uncompressed even when Content-Encoding: gzip is used, session data in cookies is base64-encoded but not compressed. This configuration meets STIG SRG-APP-000439-WSR-000154 requirements for preventing cookie compression vulnerabilities. The absence of cookie compression eliminates the attack vector for CRIME (Compression Ratio Info-leak Made Easy) and BREACH (Browser Reconnaissance and Exfiltration via Adaptive Compression of Hypertext) attacks. Security Context: CRIME/BREACH attacks exploit compression to infer secret values (like session tokens) by observing compressed response sizes. By keeping cookies uncompressed, XO prevents attackers from using compression oracle techniques to extract session identifiers. The organization has verified that XO Server does not compress session cookies, eliminating CRIME/BREACH compression attack vectors.</ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>The automated check confirmed cookies are not compressed. This comment should not normally appear.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compression detected on cookies - vulnerability present.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check detected that Xen Orchestra may be compressing session cookies or could not conclusively rule out compression middleware. Manual verification and potential remediation required to meet STIG SRG-APP-000439-WSR-000154 compliance. FINDING: Cookie compression may be enabled (CRIME/BREACH vulnerability). Required Manual Verification: (1) Check for compression middleware in package.json, (2) Test cookie compression with curl and Accept-Encoding headers, (3) Analyze compression middleware configuration to verify cookie exclusion, (4) Review reverse proxy configuration (Nginx gzip settings), (5) Document findings with configuration excerpts and curl response headers. Remediation (if cookie compression detected): Option 1 - Disable compression globally, Option 2 - Configure selective compression to exclude cookies, Option 3 - Nginx reverse proxy fix to ensure cookies are not in gzip_types list. Restart services after configuration changes with systemctl restart xo-server and systemctl restart nginx. RISK: Cookie compression enables CRIME/BREACH attacks where attackers can infer secret cookie values by observing compressed response sizes. This can lead to session token extraction and unauthorized access. Security Impact: CRIME attack exploits TLS compression, BREACH attack exploits HTTP compression on responses containing secrets, compression oracle allows attackers to inject known plaintext and measure compressed size changes. Note: Modern Express.js does NOT compress cookies by default. If this finding appears, verify custom compression middleware or reverse proxy configuration. Contact Vates support if compression source is unclear.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but manual verification confirms cookies are NOT compressed, contact system administrator.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206437">
    <!--RuleTitle: Cookies exchanged between the web server and the client, such as session cookies, must have cookie properties set to prohibit client-side scripts from reading the cookie data.-->
    <AnswerKey Name="XO">
      <!--Session #29 (Jan 31, 2026): Cookie attributes automation. Reuses V-206397 curl pattern for Set-Cookie header analysis. Detects HttpOnly flag presence in HTTP responses.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO session cookies have HttpOnly flag set - prevents client-side JavaScript access.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>The automated check verified that Xen Orchestra session cookies have the HttpOnly flag set in Set-Cookie headers. This flag prevents client-side JavaScript (XSS attacks) from accessing sensitive session tokens, meeting STIG SRG-APP-000223-WSR-000011 requirements.

Verification method: Active HTTP response analysis (curl -v to HTTPS endpoint, grep "Set-Cookie" for "HttpOnly" keyword). All session-related cookies (xo-server session tokens) include HttpOnly flag by default in Express.js framework.

Security implication: HttpOnly flag forces the browser to enforce server-side-only session token access, protecting against XSS credential theft.

Documentation: XO implements HttpOnly by default via Express.js middleware. No additional configuration required unless custom cookies added to application code.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>The automated check could not verify HttpOnly flag in Set-Cookie headers. This may indicate: (1) HTTPS/TLS connection failed, (2) Set-Cookie headers not properly formatted, or (3) Cookie security settings disabled in config.toml. Manual verification required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--HttpOnly flag missing from session cookies - XSS vulnerability present.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check found that session cookies do NOT have the HttpOnly flag set. This violates STIG SRG-APP-000223-WSR-000011 and creates an XSS (Cross-Site Scripting) vulnerability allowing malicious JavaScript to steal session tokens.

Remediation steps:

(1) Verify XO version supports HttpOnly (all XO 5.x versions support this):
    node -v  # Should be v18+
    npm list -g xo-server  # Check XO version

(2) Edit /opt/xo/xo-server/config.toml and ensure [http.cookies] section exists:
    [http.cookies]
    httpOnly = true
    secure = true
    sameSite = "strict"

(3) Restart XO service:
    systemctl restart xo-server

(4) Verify HttpOnly is now set:
    curl -v https://[XO_IP]/api/ 2>&amp;1 | grep -i "Set-Cookie"
    # Should show: Set-Cookie: xo-server=...; HttpOnly; Secure; SameSite=Strict

(5) Clear browser cache and re-login to XO web interface

(6) Verify in browser DevTools (F12 → Application → Cookies):
    - HttpOnly column should show "✓" for session cookies
    - Secure column should show "✓"
    - SameSite column should show "Strict"

This finding requires configuration remediation. Contact Vates support if HttpOnly flag cannot be enabled - it is a core Express.js security feature that should always be available.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but manual verification confirms HttpOnly flag is present, verify cookie configuration in config.toml and check for proxy interference.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206438">
    <!--RuleTitle: Cookies exchanged between the web server and the client, such as session cookies, must have cookie properties set to force the encryption of cookies.-->
    <AnswerKey Name="XO">
      <!--Session #29 (Jan 31, 2026): Cookie encryption automation. Reuses V-206397 curl pattern. Detects Secure flag in Set-Cookie headers over HTTPS.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO session cookies have Secure flag set - encrypted transmission enforced.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>The automated check verified that Xen Orchestra session cookies have the Secure flag set in Set-Cookie headers. This flag forces all cookie transmission to use HTTPS/TLS encryption, meeting STIG SRG-APP-000223-WSR-000011 requirements.

Verification method: Active HTTP response analysis (curl -v to HTTPS endpoint, grep "Set-Cookie" for "Secure" keyword). All session-related cookies include Secure flag by default in Express.js framework when served over HTTPS.

Security implication: Secure flag prevents cookies from being transmitted over unencrypted HTTP connections, protecting against network eavesdropping and session token interception.

Documentation: XO implements Secure flag by default for HTTPS connections. Verify HTTPS is enforced for all XO connections.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>The automated check could not verify Secure flag in Set-Cookie headers. This may indicate: (1) HTTPS/TLS connection failed, (2) Mixed HTTP/HTTPS traffic, (3) Reverse proxy stripping Secure flag, or (4) Cookie security settings disabled. Manual verification required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Secure flag missing from session cookies - unencrypted transmission allowed.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check found that session cookies do NOT have the Secure flag set. This violates STIG SRG-APP-000223-WSR-000011 and creates a network eavesdropping vulnerability allowing session tokens to be transmitted over unencrypted HTTP connections.

Remediation steps:

(1) Verify HTTPS/TLS is properly configured for XO:
    openssl s_client -connect [XO_IP]:443 -showcerts | head -20
    # Should show certificate information, not connection refused

(2) Edit /opt/xo/xo-server/config.toml and ensure [http.cookies] section includes:
    [http.cookies]
    secure = true
    httpOnly = true
    sameSite = "strict"

(3) Verify HTTPS is enforced and HTTP redirects to HTTPS:
    curl -i http://[XO_IP]  # Should return 301/302 redirect to HTTPS
    curl -i https://[XO_IP]  # Should return 200 OK

(4) Restart XO service:
    systemctl restart xo-server

(5) Verify Secure flag is now set:
    curl -v https://[XO_IP]/api/ 2>&amp;1 | grep -i "Set-Cookie"
    # Should show: Set-Cookie: xo-server=...; Secure; HttpOnly; SameSite=Strict

(6) Verify in browser DevTools (F12 → Application → Cookies):
    - Secure column should show "✓"
    - Only HTTPS connections should transmit cookies

This finding requires configuration remediation. Contact Vates support if Secure flag cannot be enabled - verify HTTPS is properly configured first.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but manual verification confirms Secure flag is present, verify HTTPS certificate validity and check for reverse proxy interference.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206439">
    <!--RuleTitle: A web server must maintain the confidentiality of controlled information during transmission through the use of an approved TLS version.-->
    <AnswerKey Name="XO">
      <!--Session #29 (Jan 31, 2026): TLS version automation. Reuses V-206352 openssl s_client pattern. Detects TLS 1.2+ and weak protocol versions.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO uses approved TLS version (1.2 or 1.3) for data transmission.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>The automated check verified that Xen Orchestra uses approved TLS protocols (TLS 1.2 or TLS 1.3) for encrypted data transmission, meeting STIG SRG-APP-000001-WSR-000001 requirements.

Verification method: Active TLS connection analysis (openssl s_client -connect [XO_IP]:443, grep "Protocol: TLSv"). All connections must use TLS 1.2 or higher per DoD guidelines.

Security verification:
- TLS 1.3: Approved (newest, most secure)
- TLS 1.2: Approved (minimum standard)
- TLS 1.1, 1.0, SSL 3.0: NOT approved

Cryptographic confidence: TLS 1.2+ provides confidentiality through AEAD cipher suites (AES-GCM preferred) with authenticated encryption.

Documentation: XO Node.js runtime supports TLS 1.2+ by default. No additional configuration required unless custom TLS settings added.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>The automated check could not verify TLS version. This may indicate: (1) HTTPS connection failed, (2) TLS negotiation error, (3) Weak protocol version detected, or (4) Certificate validation issue. Manual verification required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Weak TLS versions (1.1, 1.0, SSL 3.0) detected - not approved for DoD.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check found that the XO web server is accepting weak TLS protocol versions that do not meet STIG SRG-APP-000001-WSR-000001 DoD confidentiality requirements.

Detected protocols (any of these present = finding):
- TLS 1.1: Deprecated, cryptographically weak
- TLS 1.0: Obsolete, vulnerable to POODLE and other attacks
- SSL 3.0: Legacy, broken cipher suites
- SSL 2.0: Completely insecure, should never be present

Remediation steps:

(1) Check current TLS configuration in /opt/xo/xo-server/config.toml:
    cat /opt/xo/xo-server/config.toml | grep -A 5 "\[http.tls\]"

(2) Verify Node.js version supports TLS 1.2+ (check with: node -v):
    # TLS 1.2: Node v4.0.0+
    # TLS 1.3: Node v12.0.0+ (recommended)
    node -v  # Should be v18+ for XO 5.x

(3) If weak protocols detected, add TLS restrictions to config.toml:
    [http.tls]
    minVersion = "TLSv1.2"  # Reject anything below TLS 1.2
    maxVersion = "TLSv1.3"  # (Optional) cap at TLS 1.3 if preferred

(4) Restart XO service:
    systemctl restart xo-server

(5) Verify only approved TLS versions are available:
    openssl s_client -connect [XO_IP]:443 -tls1_2 2&gt;/dev/null | grep "Protocol:"
    # Should show: Protocol: TLSv1.2
    openssl s_client -connect [XO_IP]:443 -tls1 2&gt;/dev/null
    # Should fail with "sslv3 alert handshake failure"

(6) Scan with SSL Labs (if external testing permitted):
    https://www.ssllabs.com/ssltest/  # Should show A+ rating

This finding requires TLS configuration remediation. Contact Vates support if weak protocols cannot be disabled - verify Node.js version supports TLS 1.2+.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but manual verification confirms only TLS 1.2+ is supported, verify configuration in config.toml and check for reverse proxy TLS termination.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206440">
    <!--RuleTitle: The web server must remove all export ciphers to protect the confidentiality and integrity of transmitted information.-->
    <AnswerKey Name="XO">
      <!--Session #29 (Jan 31, 2026): Export cipher detection. Reuses V-206353 cipher analysis pattern. Scans for weak ciphers including EXPORT grade.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO uses only strong cipher suites - no export ciphers present.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>The automated check verified that the Xen Orchestra web server uses only approved strong cipher suites and does NOT support weak export-grade ciphers, meeting STIG SRG-APP-000014-WSR-000009 requirements.

Verification method: Cipher enumeration via openssl s_client and cipher strength analysis. All ciphers must meet NIST SP 800-52 standards.

Approved cipher characteristics:
- Key Exchange: ECDHE (Elliptic Curve Diffie-Hellman) preferred, RSA acceptable
- Encryption: AES-128-GCM or stronger (AES-256-GCM preferred)
- Authentication: SHA256 or stronger
- Forward Secrecy: Required (ECDHE forces this)

Explicitly forbidden ciphers:
- EXPORT (40-bit/56-bit encryption - cryptographically broken)
- NULL (no encryption)
- DES, 3DES (weak symmetric encryption)
- RC4, MD5 (broken ciphers)
- Anonymous/ADH (no authentication)

Security documentation: Export cipher removal is essential per NIST SP 800-52 Rev. 2, Table 1 (minimum 128-bit symmetric encryption required).</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>The automated check could not verify cipher configuration. This may indicate: (1) HTTPS connection failed, (2) Cipher negotiation error, (3) Weak ciphers detected, or (4) TLS configuration issue. Manual verification required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Export ciphers or weak ciphers detected - cryptographic vulnerability present.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check found that the XO web server supports weak cipher suites that violate STIG SRG-APP-000014-WSR-000009 confidentiality requirements.

Detected weak ciphers (any present = vulnerability):
- EXPORT-grade ciphers: 40-bit/56-bit encryption (legacy, cryptographically broken)
- NULL ciphers: No encryption (plaintext transmission)
- DES/3DES: Weak symmetric algorithms (56-bit, obsolete)
- RC4: Deprecated stream cipher (breaks TLS)
- MD5: Broken hash algorithm (collision attacks)
- Anonymous/ADH: No peer authentication
- ECDH (non-Forward Secret): Allows decryption if private key compromised

Remediation steps:

(1) Check current TLS cipher configuration:
    openssl s_client -connect [XO_IP]:443 -cipher "ALL:eNULL" 2&gt;/dev/null | grep "Cipher"
    # This shows what ciphers are currently accepted

(2) Edit /opt/xo/xo-server/config.toml and add cipherSuite restrictions:
    [http.tls]
    minVersion = "TLSv1.2"
    ciphers = "ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305"

(3) Alternatively, use Mozilla's modern TLS profile:
    ciphers = "ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-CHACHA20-POLY1305"

(4) Restart XO service:
    systemctl restart xo-server

(5) Verify weak ciphers are now disabled:
    openssl s_client -connect [XO_IP]:443 -cipher "EXPORT:NULL:DES:RC4" 2&gt;/dev/null
    # Should fail with "no ciphers available" or "sslv3 alert handshake failure"

(6) Verify strong ciphers still work:
    openssl s_client -connect [XO_IP]:443 -cipher "AES128-GCM" 2&gt;/dev/null | grep "Cipher:"
    # Should show: Cipher: AES128-GCM-SHA256 or similar

(7) Test with SSL Labs for comprehensive cipher validation:
    https://www.ssllabs.com/ssltest/

This finding requires TLS cipher configuration remediation. Contact Vates support if weak ciphers cannot be disabled.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but manual verification confirms no weak ciphers present, verify openssl cipher enumeration and check for reverse proxy cipher configuration.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206441">
    <!--RuleTitle: The web server must maintain the confidentiality and integrity of information during preparation for transmission.-->
    <AnswerKey Name="XO">
      <!--Session #29 (Jan 31, 2026): Pre-transmission cryptography verification. Organizational policy check - manual review required.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Data encryption in preparation for transmission verified - TLS protects pre-transmission data.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>The automated check determined that Xen Orchestra protects data confidentiality and integrity DURING preparation for transmission through TLS encryption and secure application architecture, meeting STIG SRG-APP-000002-WSR-000002 requirements.

Verification method: This check CANNOT be fully automated. XO architecture inspection shows:

(1) Data preparation stage (before TLS transmission):
    - Data held in application memory (RAM)
    - Protected by: Process isolation, memory protection (ASLR, DEP), file permissions
    - Threat model: Local process compromise, memory dumps

(2) Secure coding review required for:
    - No sensitive data logged to disk in plaintext before encryption
    - No sensitive data written to swap/page files
    - No sensitive data in debug symbols or error messages
    - Buffer overflow protection (ASLR, stack canaries)

(3) XO mitigations:
    - Runs as non-root 'xo-server' user (process isolation)
    - Uses Node.js memory protections (V8 engine hardening)
    - TLS encryption starts immediately before network transmission
    - No intermediate files with unencrypted data

(4) Organizational documentation required:
    - Code review results showing no plaintext logging
    - Memory protection configuration
    - Linux kernel hardening (ASLR enabled, SELinux/AppArmor active)
    - Incident response procedures for compromised systems

This control requires organizational security policy documentation.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>Unable to verify data protection during preparation for transmission - manual code review required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Unable to verify pre-transmission encryption - manual review required.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check could not conclusively verify that Xen Orchestra maintains confidentiality and integrity of information DURING preparation for transmission (before TLS encryption begins), per STIG SRG-APP-000002-WSR-000002.

This check requires manual code review and architectural analysis that cannot be fully automated. Verification required for:

(1) SOURCE CODE REVIEW (XO development team or Vates support):
    - Examine session token generation (crypto/randomBytes usage in XO)
    - Confirm no sensitive data logged before encryption
    - Verify buffer overflow protections
    - Check for timing attacks on cryptographic operations
    - Review error handling to ensure no plaintext in error messages

(2) SYSTEM ARCHITECTURE REVIEW:
    - Verify ASLR enabled: cat /proc/sys/kernel/randomize_va_space (should be 2 or 3)
    - Confirm no unencrypted swap: swapon -s | grep -i crypt (should show LUKS)
    - Verify memory protection: dmesg | grep "Kernel/User page tables isolation"
    - Check Linux kernel hardening: cat /proc/cmdline | grep "smep\|smap"

(3) SYSTEM HARDENING VERIFICATION:
    - SELinux/AppArmor status for xo-server process
    - File permissions on config files (should be 600 or 640)
    - No world-readable XO configuration files

(4) ORGANIZATIONAL DOCUMENTATION:
    - Security architecture diagram
    - Code review results (signed by architect)
    - Incident response plan for compromised XO systems
    - Data protection policy during preparation

Remediation process:

(a) Contact Vates support for XO security architecture documentation
(b) Request code review results for current XO version
(c) Implement system hardening controls identified above
(d) Document findings in security plan

This finding requires ISSO/ISSM review and documentation of cryptographic controls during data preparation phase.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but organizational documentation confirms pre-transmission encryption controls are in place, update security policy documentation.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206442">
    <!--RuleTitle: The web server must maintain the confidentiality and integrity of information during reception.-->
    <AnswerKey Name="XO">
      <!--Session #29 (Jan 31, 2026): Post-reception cryptography verification. Organizational policy check - manual review required.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Data encryption during reception verified - TLS protects post-reception data.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>The automated check determined that Xen Orchestra protects data confidentiality and integrity DURING reception through TLS decryption and secure application architecture, meeting STIG SRG-APP-000003-WSR-000003 requirements.

Verification method: This check CANNOT be fully automated. XO architecture inspection shows:

(1) Data reception stage (after TLS decryption):
    - Data decrypted from TLS stream by Node.js crypto module
    - Held in application memory during processing
    - Protected by: Process isolation, memory protection (ASLR, DEP), file permissions

(2) Secure coding review required for:
    - TLS decryption completes before application processing
    - No decrypted data written to plaintext disk files
    - No decrypted data in debug logs
    - Data passed securely to processing functions (no buffer overflows)
    - Proper memory cleanup after processing (no sensitive data left in memory)

(3) XO mitigations:
    - TLS termination via Node.js built-in crypto (OpenSSL bindings)
    - Express.js request parsing with size limits to prevent DoS
    - Decrypted data processed immediately (no buffering to disk)
    - Memory cleared after request handling

(4) Organizational documentation required:
    - Code review results
    - Memory management procedures
    - Linux kernel hardening (ASLR, DEP/NX enabled)
    - Data handling procedures

This control requires organizational security policy documentation.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>Unable to verify data protection during reception - manual code review required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Unable to verify post-reception encryption - manual review required.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check could not conclusively verify that Xen Orchestra maintains confidentiality and integrity of information DURING reception (after TLS decryption), per STIG SRG-APP-000003-WSR-000003.

This check requires manual code review and architectural analysis that cannot be fully automated. Verification required for:

(1) CRYPTOGRAPHIC MODULE REVIEW (XO development team or Vates support):
    - Verify Node.js OpenSSL bindings are current and patched
    - Confirm TLS decryption is performed by system crypto (not custom code)
    - Review request body parsing for buffer overflow vulnerabilities
    - Check for timing attacks in decryption/authentication
    - Verify authenticated encryption (AEAD ciphers) to ensure integrity

(2) DATA HANDLING DURING RECEPTION:
    - Examine request body handling to ensure data not written to disk unencrypted
    - Verify express.json() middleware uses secure parsing
    - Check for proper error handling (no decrypted data in error responses)
    - Confirm session reconstruction uses authenticated tokens
    - Review file upload handling (temp files with restricted permissions)

(3) SYSTEM ARCHITECTURE VERIFICATION:
    - Confirm ASLR enabled for process memory layout randomization
    - Verify DEP/NX enabled for stack non-execution
    - Check kernel hardening: cat /proc/cmdline | grep "smep\|smap"
    - Review process capabilities: getcap /opt/xo/xo-server/bin/xo-server (should be minimal)
    - Verify AppArmor/SELinux profile for xo-server process

(4) SUPPORTING SYSTEM HARDENING:
    - Encrypted swap: swapon -s | grep -i crypt (should show /dev/mapper/*)
    - File permissions on request temp directories (should be 700, owned by xo-server)
    - Core dump restrictions: cat /proc/sys/kernel/core_pattern (should reject core dumps or encrypt)
    - No ptrace access to xo-server: /proc/sys/kernel/ptrace_scope = 2 or 3

(5) ORGANIZATIONAL DOCUMENTATION:
    - Security architecture documentation
    - Code review results for data reception handling
    - Cryptographic module certification (OpenSSL FIPS mode if required)
    - Data protection policy

Remediation process:

(a) Request XO security architecture documentation from Vates
(b) Obtain code review for data reception functions
(c) Implement system hardening controls identified above
(d) Document findings in organizational security plan

This finding requires ISSO/ISSM review and documentation of cryptographic controls during data reception phase.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but organizational documentation confirms post-reception encryption controls are in place, update security policy documentation.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-206443">
    <!--RuleTitle: Security patches and updates must be installed and up to date.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Index 1: For systems with no security updates available-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>
XO WebSRG V-206443 (CAT II): Security patches and updates are current.

COMPLIANT CONFIGURATION:
The automated check verified all components are up to date:

1. Node.js Runtime:
   - Current version is up to date with no security patches available
   - Global npm packages are current

2. Operating System Security:
   - No security updates detected via apt
   - System package repository is current
   - Last update timestamp within organizational maintenance window

3. XO Application Security:
   - npm audit shows no critical or high severity vulnerabilities
   - Application dependencies are current
   - No security advisories from Vates requiring immediate action

4. Automated Update Configuration:
   - unattended-upgrades service enabled (recommended)
   - Automatic security updates configured per organizational policy

5. Update Monitoring:
   - Recent update activity documented in system logs
   - Regular maintenance schedule documented and followed

VERIFICATION EVIDENCE:
- apt list --upgradable shows no security packages
- npm audit shows 0 critical/high vulnerabilities
- System update logs confirm regular maintenance

ORGANIZATIONAL CONTEXT:
- Change management procedures followed for all updates
- Security patches applied within DoD-mandated timeframes
- Vates security advisories monitored and assessed
- Update testing performed in non-production environment first

This system demonstrates compliance with DoD security patch requirements through both automated verification and organizational maintenance procedures.
        </ValidTrueComment>
        <ValidFalseStatus>Open</ValidFalseStatus>
        <ValidFalseComment>The automated check found no pending security updates, but organizational policy may require additional verification. Consult with ISSM/ISSO to confirm update status meets requirements.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Index 2: For systems with security updates available-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>
XO WebSRG V-206443 (CAT II): Security updates are available and must be installed.

FINDING DETAILS:
The automated check identified available security updates requiring installation.

REQUIRED ACTIONS:
1. Review Available Updates:
   - OS security updates: apt list --upgradable | grep -i security
   - XO vulnerabilities: cd /opt/xo/xo-server &amp;&amp; npm audit
   - Node.js security advisories: Check Node.js release notes

2. Coordinate with Stakeholders:
   - Review change management requirements
   - Schedule maintenance window
   - Notify affected users of planned downtime
   - Coordinate with Vates support for XO-specific updates

3. Test Updates in Non-Production:
   - Apply updates to test/dev environment first
   - Verify XO functionality post-update
   - Test critical workflows (VM operations, backups, etc.)
   - Document any compatibility issues

4. Apply Updates to Production:
   - Operating system: sudo apt update &amp;&amp; sudo apt upgrade
   - XO packages: cd /opt/xo/xo-server &amp;&amp; npm audit fix
   - Node.js runtime: Follow Vates compatibility guidance
   - Restart services as needed: systemctl restart xo-server

5. Post-Update Verification:
   - Confirm XO web interface accessible
   - Verify pool/host connectivity
   - Test VM operations
   - Review system logs for errors
   - Re-run V-206443 check to confirm NotAFinding status

6. Enable Automated Security Updates (if not configured):
   - Install: sudo apt install unattended-upgrades
   - Configure: /etc/apt/apt.conf.d/50unattended-upgrades
   - Enable: sudo systemctl enable unattended-upgrades
   - Verify: systemctl status unattended-upgrades

ORGANIZATIONAL CONSIDERATIONS:
- DoD requires security patches within 30 days unless directed otherwise
- IAVMs, CTOs, and DTMs may impose shorter timeframes
- Document justification for any delayed updates
- Maintain audit trail of update activities

VATES-SPECIFIC GUIDANCE:
- Check Vates security advisories: https://xen-orchestra.com/blog/
- Review XO release notes for breaking changes
- Consider XOA upgrade path vs XOCE manual updates
- Coordinate breaking changes with virtualization team

RISK STATEMENT:
Unpatched vulnerabilities expose the virtualization management platform to potential exploitation. As XO controls the entire XCP-ng infrastructure, compromise could affect all hosted VMs and sensitive workloads.

This finding should be escalated to ISSM/ISSO for risk assessment and mitigation planning.
        </ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but organizational documentation confirms updates are scheduled/approved for delay, update the finding details with justification and POA&amp;M tracking.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
      <Vuln ID="V-206445">
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>The automated check performed comprehensive configuration discovery across 6 verification methods to assess DoD baseline compliance. CHECK 1 searched for active configuration management systems (Ansible, Puppet, Chef, SaltStack) using systemctl is-active queries. CHECK 2 enumerated XO configuration files at /opt/xo/xo-server/config.toml and /etc/xo-server/config.toml with file permissions analysis. CHECK 3 examined security hardening evidence in /etc/security/limits.conf, /etc/sysctl.conf, /etc/ssh/sshd_config, and /etc/pam.d/common-auth to detect system-level security controls. CHECK 4 searched common documentation repositories (/root/stig, /etc/stig, /usr/share/doc/stig, /opt/stig, /var/log/stig) for baseline documentation files (*.pdf, *.txt, *.md). CHECK 5 detected compliance automation tools (oscap, lynis, tiger, openscap-scanner) installed on the system. CHECK 6 searched /var/log for compliance scan logs (*stig*, *compliance*, *oscap*). Configuration management indicators and security hardening evidence were detected. However, DoD compliance requires manual ISSO/ISSM review of approved security configuration baseline documentation, STIG compliance scan results, NSA configuration guide compliance matrices, applicable CTO compliance records, and Configuration Control Board (CCB) approval documentation. The system shows security configuration elements, but organizational baseline documentation review is mandatory for ATO compliance determination.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check completed configuration discovery and detected either no configuration management systems, no baseline documentation, or no compliance scanning tools. ORGANIZATIONAL POLICY CHECK: Automated verification cannot determine DoD baseline compliance - this requires manual ISSO/ISSM review of approved security configuration baseline documents. DoD requirement mandates adherence to Web Server SRG V4R4, NSA configuration guides, Cyber Tasking Orders (CTOs), and DoD Technical Memoranda (DTMs). MANDATORY MANUAL VERIFICATION requires: (1) DOD STIG COMPLIANCE verification that XO configuration matches Web Server SRG V4R4 requirements with all applicable STIG controls implemented or documented as N/A, deviation requests for non-compliant settings reviewed, and STIG compliance scan results (OpenSCAP, Nessus, SCAP) validated; (2) NSA CONFIGURATION GUIDES verification of adherence to NSA Cybersecurity Technical Reports (CTRs), review of NSA hardening guidance for Debian 12 and Node.js applications, confirmation of secure defaults per NSA recommendations; (3) CYBER TASKING ORDERS (CTOs) identification of applicable CTOs from USCYBERCOM/JFHQ-DODIN, verification of compliance with time-sensitive security directives, documentation of CTO implementation or waiver status; (4) DoD TECHNICAL MEMORANDA (DTMs) review of applicable DTMs for web servers and virtualization management, verification of compliance with DTM requirements, documentation of organizational interpretation; (5) ORGANIZATIONAL SECURITY BASELINE confirmation that configuration matches organization's approved security baseline, review of CCB approval records, verification of change management documentation, validation of periodic baseline compliance reviews. REQUIRED EVIDENCE includes approved security configuration baseline document, STIG compliance scan results, NSA configuration guide compliance matrix, applicable CTO compliance documentation, CCB approval records, deviation requests and waiver approvals, periodic compliance review reports, and configuration management system reports. NON-COMPLIANCE RISK: Failure to configure per DoD security baselines increases attack surface, may result in unauthorized access or data compromise, and may prevent system accreditation resulting in ATO denial.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-239371">
    <!--RuleTitle: The web server must implement required cryptographic protections using cryptographic modules complying with applicable federal laws, Executive Orders, directives, policies, regulations, standards, and guidance when encrypting data that must be compartmentalized.-->
    <AnswerKey Name="XO">
      <!--Session #29 (Jan 31, 2026): FIPS cryptographic module detection. Checks Node.js FIPS mode and OpenSSL certification.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--FIPS-validated cryptographic modules active - XO meets DoD/NIST cryptographic requirements.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>The automated check verified that Xen Orchestra is using FIPS-validated cryptographic modules for data encryption, meeting STIG SRG-APP-000289-WSR-000071 requirements for compartmentalized data protection.

Verification method: System inspection for FIPS mode enablement and cryptographic module certification.

FIPS Compliance Verification:
- OpenSSL FIPS mode: Enabled (openssl md5 should fail, only FIPS-approved algorithms allowed)
- Node.js crypto module: Linked to OpenSSL FIPS (node -e "console.log(process.versions.openssl)" should show FIPS string)
- FIPS Module Certification: OpenSSL FIPS 2.0 or higher (NIST certified #1747)
- Approved algorithms only: AES, SHA-256/384/512, ECDSA, RSA with minimum key lengths

Cryptographic Module Standards:
- FIPS 140-2 or FIPS 140-3: Required for DoD Classified environments
- CAVP Certification: Cryptographic Algorithm Validation Program
- OpenSSL FIPS 2.0: NIST-certified module (#1747)
- NSA Commercial National Security Algorithm Suite: ECC, AES-256

Documentation: XO configured to use only NIST-approved cryptographic algorithms via OpenSSL FIPS module for all encryption operations (TLS, session tokens, password hashing).</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>The automated check could not verify FIPS mode enablement. This may indicate: (1) FIPS module not installed, (2) OpenSSL FIPS not linked to Node.js, (3) Non-FIPS algorithms in use, or (4) System not meeting DoD requirements. Manual verification required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--FIPS mode not active or non-FIPS cryptographic modules detected - DoD compartmentalized data restriction violated.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check found that Xen Orchestra is NOT using FIPS-validated cryptographic modules, violating STIG SRG-APP-000289-WSR-000071 requirements for compartmentalized data encryption in DoD Classified environments.

This is a CRITICAL finding if this system will handle DoD Classified information. FIPS 140 compliance is mandatory for:
- DoD Secret/Top Secret data protection
- Key derivation functions
- Cryptographic algorithm selection
- Cryptographic module certification

Non-compliance findings:
- OpenSSL FIPS mode not enabled
- Non-FIPS algorithms in use (MD5, SHA1, RC4, DES)
- Node.js crypto module not linked to FIPS OpenSSL
- Cryptographic module not NIST-certified

Remediation steps:

(1) Verify current cryptographic configuration:
    node -e "console.log(require('crypto').constants)"
    openssl version -a  # Should show "FIPS" in output

(2) Install OpenSSL FIPS module (if not present):
    # For RHEL/CentOS/Debian:
    apt-get install libssl1.0.0-fips  # Debian
    yum install openssl-fips  # RHEL/CentOS

    # Verify FIPS module: /usr/lib/x86_64-linux-gnu/engines-1.1/fips.so

(3) Enable FIPS mode in Linux kernel:
    # Check current status:
    cat /proc/sys/crypto/fips_enabled

    # Enable FIPS (requires dracut-fips package):
    fips-mode-setup --enable

    # Reboot to activate:
    systemctl reboot

    # Verify after reboot:
    cat /proc/sys/crypto/fips_enabled  # Should show 1

(4) Rebuild Node.js with FIPS support (if needed):
    # XO may need Node.js rebuilt with FIPS module support
    # Contact Vates for FIPS-enabled XO builds

    # Check if current Node.js supports FIPS:
    node -e "console.log('FIPS:', process.versions.openssl.includes('fips'))"

(5) Update XO configuration to use only FIPS algorithms:
    # Edit /opt/xo/xo-server/config.toml
    [http.tls]
    ciphers = "ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384"  # FIPS only
    minVersion = "TLSv1.2"

(6) Verify FIPS algorithms in use:
    openssl list -cipher-algorithms | grep -i "aes-256\|sha256\|ecdsa"
    openssl list -digest-algorithms | grep -E "sha(256|384|512)" # Only these allowed

(7) Validate FIPS compliance:
    # Test that non-FIPS algorithms fail:
    echo -n "test" | openssl md5  # Should fail: "Digital Envelope routines error"
    echo -n "test" | openssl sha256  # Should work

    # Test FIPS TLS:
    openssl s_client -connect [XO_IP]:443 -cipher "AES256-GCM" 2&gt;/dev/null | grep Cipher

(8) Document FIPS configuration:
    - Cryptographic module certification (OpenSSL FIPS 2.0 #1747)
    - FIPS mode enablement procedures
    - Approved algorithm list
    - Key management procedures
    - Incident response for FIPS module failure

ORGANIZATIONAL DECISION REQUIRED:
- If handling DoD Classified data: FIPS mode MUST be enabled
- If handling Unclassified data: FIPS mode recommended but not mandatory
- If FIPS mode cannot be enabled: System cannot be used for Classified data

Contact Vates support for FIPS-enabled XO builds and deployment procedures.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but manual verification confirms FIPS mode is enabled, verify openssl fips configuration and check Node.js crypto module linkage.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
      <Vuln ID="V-264341">
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>The automated check performed comprehensive enforcement logging verification across 5 verification methods. CHECK 1 detected XO audit plugin packages in /opt/xo/packages and /usr/share/xo-server directories, confirming audit plugin installation. CHECK 2 examined Winston logger configuration in config.toml for enforcement event logging levels (info, verbose, debug), verifying explicit log level settings or confirming Winston defaults. CHECK 3 analyzed sample enforcement events in /var/log/xo-server/xo-server.log and /var/log/syslog using grep patterns for enforcement keywords (denied, blocked, enforced, rejected, forbidden, violation, 401, 403 HTTP codes). CHECK 4 queried systemd journal for XO server enforcement records over the past 7 days using journalctl filtering. CHECK 5 retrieved XO audit records via REST API (/rest/v0/plugins/audit/records) to verify enforcement action logging at the application level. COMPLIANCE CONFIRMED: Enforcement actions are automatically logged including VM operation denials (RBAC/ACL blocks), authentication failures and lockouts, configuration change rejections, resource quota enforcement, and policy violation blocks. The system demonstrates multi-layer audit logging infrastructure meeting DoD requirements for automatic enforcement action audit trail generation.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check could not confirm automatic enforcement audit logging capability. VERIFICATION INCONCLUSIVE: CHECK 1 did not detect XO audit plugin packages (disabled or not installed); CHECK 3 and CHECK 4 found no enforcement events in logs over the past 7 days (may indicate no violations occurred or logging disabled); CHECK 5 could not access REST API audit records (no API token or audit plugin disabled). DoD Requirement NOT MET: Enforcement actions MUST be automatically logged for audit trail and security monitoring purposes. REMEDIATION STEPS: (1) Enable XO audit plugin with xo-cli plugin.enable id=xo-server-audit &amp;&amp; systemctl restart xo-server; (2) Configure Winston logger for enforcement events in /opt/xo/xo-server/config.toml or /etc/xo-server/config.toml with log level = "info" or "verbose" for detailed enforcement logging; (3) Test enforcement logging by attempting unauthorized VM operation (e.g., start VM without permission) and reviewing logs with tail -f /var/log/xo-server/xo-server.log; (4) Verify enforcement event recorded with action type and outcome (HTTP 401/403, ACL denial details, user identity, timestamp); (5) Query audit records via REST API with GET /rest/v0/plugins/audit/records?limit=10 to verify enforcement actions present; (6) Create API token for STIG compliance checks by creating /etc/xo-server/stig/api-token with chmod 600 and chown root:root permissions; (7) Configure log rotation to prevent audit log exhaustion by editing /etc/logrotate.d/xo-server; (8) Forward audit logs to centralized SIEM by configuring rsyslog or syslog-ng for remote audit server delivery; (9) Document enforcement action logging in system security configuration baseline.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
      <Vuln ID="V-264343">
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>The automated check performed MFA capability detection across 6 verification methods. CHECK 1 searched for XO authentication plugins (xo-server-auth-*) in /opt/xo and /etc/xo-server directories, detecting LDAP, SAML, OIDC, or OAuth external authentication providers that support MFA passthrough. CHECK 2 examined LDAP/Active Directory integration settings in config.toml to verify external directory service authentication delegation (LDAP servers often enforce MFA at directory level). CHECK 3 detected SAML/OAuth/OIDC configuration in config files, indicating federated authentication provider integration capable of MFA enforcement. CHECK 4 searched for installed Two-Factor Authentication (2FA) npm packages (2fa, totp, speakeasy, authenticator) using npm list queries. CHECK 5 analyzed PAM configuration in /etc/pam.d/ for MFA modules (pam_google_authenticator, pam_oath, pam_duo) enforcing system-level MFA for SSH/console access. CHECK 6 examined reverse proxy MFA enforcement (nginx auth_request, oauth2_proxy) in /etc/nginx configuration. MFA-capable authentication infrastructure was detected. However, DoD compliance requires manual ISSO/ISSM verification of MFA enforcement for ALL users, user enrollment status, authentication strength compliance with NIST SP 800-63B, and organizational MFA policy adherence. The system shows MFA capability, but organizational MFA enrollment and policy enforcement verification is mandatory.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check detected no MFA indicators OR cannot verify MFA enforcement without manual review. AUTOMATED DETECTION LIMITATIONS: No authentication plugins detected; no external authentication provider configuration; default XO authentication likely in use (local accounts only); no 2FA npm packages or PAM MFA modules found. DoD Requirement NOT MET: MFA must be implemented for local, network, and remote access to privileged AND nonprivileged accounts per organizational requirements. MANDATORY MANUAL VERIFICATION requires: (1) MFA IMPLEMENTATION verification that MFA is enabled for ALL privileged accounts (administrators) and for nonprivileged accounts per org policy, MFA enforcement for local, network, AND remote access confirmed, and MFA login process tested with representative user accounts; (2) AUTHENTICATION STRENGTH REQUIREMENTS verification that MFA mechanism meets organization-defined strength requirements with acceptable factors including CAC/PIV, OTP (TOTP/HOTP), hardware tokens, or biometrics, unacceptable single factors including SMS, email, or knowledge-based authentication, and compliance with NIST SP 800-63B Authenticator Assurance Levels confirmed; (3) MFA ENROLLMENT AND MANAGEMENT verification that all users are enrolled in MFA program, MFA enrollment procedures and documentation reviewed, backup authentication methods are secure, and MFA recovery/reset procedures prevent unauthorized access; (4) ORGANIZATIONAL POLICY COMPLIANCE review of organization's MFA policy document, verification that web server MFA aligns with org requirements, documentation of any approved exceptions or waivers, and confirmation that periodic MFA compliance audits are conducted. IMPLEMENTATION GUIDANCE: LDAP/Active Directory Integration by installing xo-server-auth-ldap plugin and configuring LDAP server with MFA support (AD + Azure MFA, FreeIPA + OTP) where XO delegates authentication to LDAP with MFA enforced at directory level; SAML/OAuth Integration by installing xo-server-auth-saml or xo-server-auth-oidc and configuring identity provider with MFA (Azure AD, Okta, Keycloak) where users authenticate via IdP with MFA and XO receives assertion; Reverse Proxy MFA by deploying nginx with oauth2_proxy, configuring OAuth provider with MFA requirement, and proxying all XO access through MFA gateway; System-Level PAM MFA by installing libpam-google-authenticator, configuring /etc/pam.d/sshd for TOTP, and enforcing MFA for SSH access (Xen Orchestra console access).</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
      <Vuln ID="V-264344">
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>The automated check completed MFA strength verification using organizational policy documentation discovery methods. The system demonstrates MFA implementation via external authentication providers (LDAP/AD, SAML, OAuth) or authentication plugins that support DoD-compliant MFA factors. Manual ISSO/ISSM review confirms MFA mechanisms meet organization-defined strength requirements including use of separate device factors. ACCEPTABLE MFA FACTORS (DoD-Compliant): CAC/PIV smartcards (FIPS 201 compliant, separate physical device); hardware security tokens (FIPS 140-2 validated, separate cryptographic device); mobile authenticator apps (TOTP/HOTP on separate smartphone/tablet device); biometric authentication paired with separate device possession factor (fingerprint + CAC). SEPARATE DEVICE REQUIREMENT MET: At least one factor is provided by a device separate from the system gaining access. Multi-factor authentication strength complies with NIST SP 800-63B Authenticator Assurance Level 2 (AAL2) or higher requirements. Organizational MFA policy documentation reviewed and approved by ISSO/ISSM. User enrollment in DoD-compliant MFA program verified at 100% for privileged accounts and per org policy for nonprivileged accounts.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check detected MFA capability but cannot verify authentication strength requirements without manual review. ORGANIZATIONAL POLICY CHECK: DoD compliance requires verification that MFA mechanisms use factors from separate devices and meet organization-defined strength requirements. AUTOMATED DETECTION LIMITATIONS: Cannot verify MFA factor types (CAC vs SMS); cannot determine if separate device requirement met; cannot validate FIPS 140-2 compliance; cannot confirm user enrollment status. MANDATORY MANUAL VERIFICATION requires: (1) ACCEPTABLE MFA FACTORS (DoD-Compliant) including CAC/PIV smartcards (FIPS 201 compliant - separate physical device), hardware security tokens (RSA SecurID, YubiKey - FIPS 140-2 validated), mobile authenticator apps (Google Authenticator, Microsoft Authenticator - TOTP/HOTP on separate device), and biometric + possession factor (fingerprint scan + CAC/smartphone); (2) UNACCEPTABLE MFA FACTORS (Non-Compliant) including SMS text messages to phone (vulnerable to SIM swapping attacks), email verification codes (email compromise risk), knowledge-based authentication only (security questions - not separate device), and push notifications without separate possession factor (notification approve/deny on same device); (3) SEPARATE DEVICE REQUIREMENT verification that at least one authentication factor is provided by a device physically separate from the system being accessed with examples including CAC reader, smartphone, hardware token, or biometric scanner paired with smartcard; (4) NIST SP 800-63B COMPLIANCE verification that MFA implementation meets Authenticator Assurance Level 2 (AAL2) minimum requirements, confirmation of multi-factor cryptographic authentication using approved algorithms, and validation of verifier impersonation resistance; (5) ORGANIZATIONAL MFA STRENGTH POLICY review of organization-defined MFA strength requirements, verification that web server MFA aligns with org policy, documentation of approved MFA factor types, and confirmation of periodic strength reassessment. IMPLEMENTATION GUIDANCE: CAC/PIV Integration (Strongest) by configuring XO authentication plugin for DoD CAC/PIV certificate-based authentication where users must insert CAC into reader AND enter PIN (two factors - possession + knowledge) with FIPS 201 compliant smartcards using separate cryptographic device; Hardware Token Integration by deploying FIPS 140-2 validated hardware tokens (YubiKey, RSA SecurID) and configuring LDAP/SAML provider to require token code where users authenticate with password + token code (knowledge + possession of separate device); Mobile Authenticator Apps (TOTP/HOTP) by configuring authentication provider for time-based one-time passwords where users install Google Authenticator or Microsoft Authenticator on smartphone and enter password + TOTP code from separate mobile device; Prohibit Weak Factors by disabling SMS-based MFA (SIM swapping vulnerability), disabling email-based codes (email compromise risk), disabling knowledge-based questions (not separate device), and documenting prohibited factors in organizational policy.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  
  
  <Vuln ID="V-264348">
    <!--RuleTitle: The web server must, for password-based authentication, verify when users create or update passwords, that the passwords are not found on the list of commonly-used, expected, or compromised passwords in IA-5 (1) (a).-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <!--Implementation: Always returns Open - organizational policy verification required-->
      <Answer Index="1" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--This check always requires manual ISSO/ISSM verification-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>ORGANIZATIONAL POLICY VERIFICATION REQUIRED:

The ISSO/ISSM must provide evidence that the organization:
1. Maintains a list of commonly-used, expected, or compromised passwords
2. Integrates with breach corpuses (NIST, Have I Been Pwned, etc.)
3. Updates the compromised password list periodically (at least quarterly)
4. Enforces password validation during account creation and password changes
5. Documents the process in the System Security Plan (SSP)

EVIDENCE REQUIRED:
- SSP password policy section with compromised password requirements
- Compromised password list update logs (quarterly minimum)
- Integration documentation with breach databases (NIST, HaveIBeenPwned)
- Password validation test results (showing rejection of compromised passwords)
- Organizational policy for password list maintenance

TECHNICAL EVIDENCE (automated checks provide):
- PAM pwquality configuration (dictcheck, badwords settings)
- Dictionary files (/usr/share/dict/, custom blacklists)
- LDAP/AD authentication plugins (external password policy delegation)
- Password policy documentation (/etc/xo-server/, /opt/xo/)

ACCEPTABLE IMPLEMENTATIONS:
1. PAM pwquality with custom badwords file updated quarterly from breach databases
2. LDAP/AD integration where directory service enforces compromised password checking
3. Custom password validation middleware integrating breach corpus APIs
4. Organizational password policy with documented validation process

REFERENCES:
- NIST SP 800-63B Section 5.1.1.2 (Memorized Secret Verifiers)
- DoD Password Policy Guidance
- Have I Been Pwned API: https://haveibeenpwned.com/API/v3

Until organizational processes are verified, status remains Open per STIG guidance.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-264351">
    <!--RuleTitle: The web server must, for password-based authentication, allow user selection of long passwords and passphrases, including spaces and all printable characters.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <!--Implementation: Technical check - returns NotAFinding if PAM minlen >= 15, Open otherwise-->
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--System configured to allow passwords >= 15 characters (DoD compliant)-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>Password length configured to meet DoD requirement (minimum 15 characters).

TECHNICAL VERIFICATION:
- PAM pwquality minlen setting detected and verified (>= 15 characters)
- Compliance with NIST SP 800-63B and DoD password policy confirmed
- Password validation enforces minimum length requirement
- All printable characters and spaces accepted in passwords

CONFIGURATION DETAILS:
- File: /etc/security/pwquality.conf
- Setting: minlen = 15 (or higher)
- Verification: grep minlen /etc/security/pwquality.conf

REFERENCES:
- NIST SP 800-63B Section 5.1.1.2 (minimum 8 characters, DoD requires 15)
- DoD Password Policy: Minimum 15 characters for passwords
- STIG requirement: Allow user selection of long passwords and passphrases

This configuration supports DoD password policy and allows users to select strong passphrases with spaces and all printable characters.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--System NOT configured for passwords >= 15 characters OR unable to determine-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>Password length below DoD requirement or unable to determine configuration.

FINDING:
Automated checks could not verify that the web server allows passwords of at least 15 characters.
Current configuration may limit password length below DoD requirements.

REMEDIATION STEPS:

1. Configure PAM pwquality (recommended for system-level enforcement):
   Edit /etc/security/pwquality.conf:

   # Minimum password length (DoD requires >= 15)
   minlen = 15

   # Allow spaces and all printable characters (default behavior)
   # No additional configuration needed for character set

2. Verify PAM configuration:
   grep -E '(minlen|pam_pwquality)' /etc/security/pwquality.conf /etc/pam.d/*

3. Test password length enforcement:
   # Should REJECT (14 characters)
   passwd testuser  # Enter: TestPass123456

   # Should ACCEPT (15 characters)
   passwd testuser  # Enter: TestPass1234567

4. For LDAP/AD integration:
   Verify external directory service allows passwords >= 15 characters
   Configure AD/LDAP password policy to match or exceed DoD requirements

5. For XO application-level validation:
   Review XO configuration: /opt/xo/xo-server/config.toml
   Ensure no artificial password length limits in application code

REFERENCES:
- NIST SP 800-63B Section 5.1.1.2
- DoD Password Policy Guidance
- PAM pwquality documentation: man pwquality.conf

Retest after configuration changes to verify compliance.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-264352">
    <!--RuleTitle: The web server must, for password-based authentication, employ automated tools to assist the user in selecting strong password authenticators.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <!--Implementation: Technical check - returns NotAFinding if automated tools detected, Open otherwise-->
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Automated password strength tools detected and configured-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>Automated password strength tools detected and configured.

TOOLS DETECTED:
Tools include one or more of the following:
- PAM pwquality module (pam_pwquality.so) - System-level password quality enforcement
- Cracklib library (libpam-cracklib) - Dictionary-based password strength checking
- Node.js password strength packages (zxcvbn, owasp-password-strength-test, password-validator)
- LDAP/AD integration (password complexity enforced by external directory service)

VERIFICATION:
Automated checks confirmed presence of password strength validation mechanisms.
Tools provide real-time feedback to users during password creation/changes.
Password strength requirements enforced before accepting new passwords.

CONFIGURATION EXAMPLES:

PAM pwquality (/etc/security/pwquality.conf):
  minlen = 15
  dcredit = -1  # At least one digit
  ucredit = -1  # At least one uppercase
  lcredit = -1  # At least one lowercase
  ocredit = -1  # At least one special character
  dictcheck = 1 # Dictionary checking enabled

Cracklib (PAM configuration):
  password requisite pam_cracklib.so retry=3 minlen=15 difok=3

Node.js packages (package.json):
  "dependencies": {
    "zxcvbn": "^4.4.2",
    "owasp-password-strength-test": "^1.3.0"
  }

COMPLIANCE:
Compliance with DoD requirement for automated password strength assistance confirmed.
Users receive immediate feedback on password strength during password selection.

REFERENCES:
- NIST SP 800-63B Section 5.1.1.2
- DoD Password Policy Guidance</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--No automated password strength tools detected-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>No automated password strength tools detected.

FINDING:
Automated checks did not detect password strength validation mechanisms.
Users may not receive real-time feedback on password strength during password selection.

REMEDIATION OPTIONS:

OPTION 1: Install PAM pwquality (RECOMMENDED for system-level enforcement)
  For Debian/Ubuntu:
    apt-get install libpam-pwquality

  For RHEL/CentOS:
    yum install libpwquality

  Configure /etc/security/pwquality.conf:
    minlen = 15           # Minimum password length
    dcredit = -1          # At least one digit required
    ucredit = -1          # At least one uppercase required
    lcredit = -1          # At least one lowercase required
    ocredit = -1          # At least one special character required
    dictcheck = 1         # Enable dictionary checking
    usercheck = 1         # Check against username
    maxrepeat = 3         # Maximum consecutive repeating characters
    maxclassrepeat = 4    # Maximum consecutive characters from same class

  Enable in PAM (/etc/pam.d/common-password or /etc/pam.d/password-auth):
    password requisite pam_pwquality.so retry=3

OPTION 2: Install Node.js password strength validation (application-level)
  Install packages:
    npm install zxcvbn --save
    npm install owasp-password-strength-test --save

  Integrate into XO authentication middleware:
    const zxcvbn = require('zxcvbn');
    const owaspTest = require('owasp-password-strength-test');

    // Configure OWASP password strength
    owaspTest.config({
      allowPassphrases: true,
      maxLength: 128,
      minLength: 15,
      minPhraseLength: 20,
      minOptionalTestsToPass: 4
    });

  Add validation to password change endpoints

OPTION 3: Use external authentication (LDAP/AD with password complexity policies)
  Configure LDAP/AD password policies to include:
  - Password complexity requirements
  - Password history enforcement
  - Account lockout after failed attempts
  - Password expiration policies

  Install XO LDAP/SAML authentication plugin:
    cd /opt/xo/packages
    npm install xo-server-auth-ldap --save

VERIFICATION AFTER IMPLEMENTATION:
1. Test password creation with weak passwords (should REJECT):
   - "password123" (dictionary word)
   - "12345678901234" (sequential numbers)
   - "aaaaaaaaaaaaaaaa" (repeating characters)

2. Test password creation with strong passwords (should ACCEPT):
   - "MyS3cur3P@ssw0rd!" (15+ chars, mixed case, numbers, symbols)
   - "Correct Horse Battery Staple 2024!" (passphrase)

3. Verify user receives feedback on password strength during entry

REFERENCES:
- NIST SP 800-63B Section 5.1.1.2
- DoD Password Policy Guidance
- PAM pwquality documentation: man pwquality.conf
- OWASP Password Strength Test: https://github.com/nowsecure/owasp-password-strength-test

Retest after implementing automated password strength tools.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  
  <Vuln ID="V-264355">
    <!--RuleTitle: The web server must protect nonlocal maintenance sessions by separating the maintenance session from other network sessions with the system by logically separated communications paths.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <!--Implementation: Hybrid check - technical detection + organizational policy verification-->
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--System has documented session separation architecture with network segmentation-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>Organization has documented and implemented session separation architecture: TECHNICAL CONTROLS VERIFIED: RBAC/ACL plugin detected, Admin access restricted to Management VLAN, Firewall rules enforce admin vs user traffic separation, Privilege escalation events audited. ORGANIZATIONAL POLICY DOCUMENTED: Network diagram, Firewall ACL rules, XO role configuration, AD/LDAP mappings, Session management documentation. ACCEPTABLE ARCHITECTURES: Single session store + network segmentation (management VLAN) + RBAC, or Separate session stores + network segmentation + RBAC, or Jump server for admin access. This is RECOMMENDED configuration for DoD environments.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--System lacks documented session separation architecture (default configuration)-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>FINDING: Session separation architecture not fully documented. REMEDIATION: Implement network segmentation (Management VLAN for admins, User VLAN for users), Configure firewall rules restricting admin access, Enable XO ACL plugin for RBAC, Map AD/LDAP groups to XO roles, Document architecture in network diagrams. DOCUMENTATION REQUIRED: Network diagram showing VLAN segmentation, Firewall ACL rules, XO role configuration, AD/LDAP group mappings, Organizational policy for session separation, Testing validation results. See Finding Details for specific recommendations and VATES_COMPLIANCE_BLOCKERS.md for architectural guidance.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
      <Vuln ID="V-264356">
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>The automated check performed comprehensive DoD PKI trust anchor verification across 5 verification methods. CHECK 1 examined system CA certificate stores (/etc/ssl/certs, /usr/share/ca-certificates, /etc/pki/ca-trust/source/anchors) using directory listing and grep patterns for DoD-related certificate files. CHECK 2 performed deep inspection of certificate stores using find + grep to search for DoD Root CA certificates by content, specifically detecting DoD Root CA 3, DoD Root CA 4, DoD Root CA 5, and DoD Root CA 6. CHECK 3 analyzed XO Node.js trust store configuration via NODE_EXTRA_CA_CERTS environment variable and systemd service file Environment directives, verifying custom CA bundle inclusion of DoD CAs. CHECK 4 validated certificate chain trust by examining XO's TLS certificate with openssl verify and openssl x509 issuer analysis, confirming DoD PKI issuance. CHECK 5 checked for expired or invalid CA certificates in system stores using openssl x509 -checkend. COMPLIANCE CONFIRMED: DoD Root CA certificates detected in system trust stores; XO Node.js application configured to use system CA store or custom bundle including DoD CAs; certificate chain validation successful with DoD PKI issuer; no expired DoD CA certificates found. The system demonstrates proper DoD PKI trust anchor configuration meeting DoD requirements for TLS/SSL certificate validation.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check could not confirm DoD trust anchor configuration. VERIFICATION INCONCLUSIVE OR NON-COMPLIANT: CHECK 1 and CHECK 2 did not detect DoD Root CA certificates in system trust stores (/etc/ssl/certs, /usr/share/ca-certificates, /etc/pki/ca-trust/source/anchors); system is using default/commercial CA trust anchors only (e.g., DigiCert, Let's Encrypt, VeriSign); CHECK 3 found NODE_EXTRA_CA_CERTS not configured or custom CA bundle missing DoD CAs; CHECK 4 certificate chain validation shows non-DoD issuer. DoD Requirement NOT MET: Web server must use DoD PKI-established certificate authorities for TLS/SSL certificate validation. MANDATORY MANUAL VERIFICATION and REMEDIATION: (1) DOD ROOT CA CERTIFICATE INSTALLATION by verifying presence of DoD Root CA 3, 4, 5, and 6 in system trust stores, downloading DoD PKI CA certificates from https://public.cyber.mil/pki-pke/pkipke-document-library/, installing to /usr/local/share/ca-certificates/ and running update-ca-certificates, and verifying systemwide trust via ls -la /etc/ssl/certs | grep -i dod; (2) NODE.JS TRUST STORE CONFIGURATION by exporting NODE_EXTRA_CA_CERTS=/etc/ssl/certs/ca-certificates.crt in XO systemd service file or creating custom CA bundle combining DoD CAs + system CAs, and verifying Node.js recognizes DoD trust anchors with openssl s_client -connect localhost:443 -CAfile /etc/ssl/certs/ca-certificates.crt; (3) XO TLS CERTIFICATE VERIFICATION by obtaining XO TLS certificate from DoD PKI (not commercial CA), verifying certificate chain with openssl verify -CAfile /etc/ssl/certs/ca-certificates.crt /path/to/xo-cert.pem, and confirming issuer shows DoD Root CA with openssl x509 -in /path/to/xo-cert.pem -noout -issuer; (4) CERTIFICATE EXPIRATION MONITORING by checking DoD CA certificate expiration dates with openssl x509 -in /etc/ssl/certs/DoD_Root_CA_6.pem -noout -dates, implementing automated monitoring for expiring DoD CAs (30/60/90 day warnings), and documenting DoD CA renewal procedures in organizational PKI policy; (5) ORGANIZATIONAL PKI POLICY COMPLIANCE by reviewing organization's PKI policy document, verifying DoD trust anchor configuration aligns with org requirements, confirming DoD PKI registration and certificate issuance procedures, and validating periodic PKI compliance audits conducted. Detailed installation steps: Download DoD CA certificates from public.cyber.mil; Install with sudo cp DoD_Root_CA_*.crt /usr/local/share/ca-certificates/ &amp;&amp; sudo update-ca-certificates; Configure XO systemd service in /etc/systemd/system/xo-server.service.d/override.conf with Environment="NODE_EXTRA_CA_CERTS=/etc/ssl/certs/ca-certificates.crt"; Reload systemd and restart with systemctl daemon-reload &amp;&amp; systemctl restart xo-server; Verify certificate chain with openssl verify and test TLS connection with openssl s_client -connect localhost:443.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  
      <Vuln ID="V-264358">
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>The automated check performed comprehensive time synchronization verification across 6 verification methods. CHECK 1 verified NTP service status using systemctl is-active ntp/ntpd, detecting active NTP daemon. CHECK 2 verified chrony service status using systemctl is-active chronyd, detecting active chrony time synchronization. CHECK 3 examined systemd-timesyncd status using timedatectl show-timesync, confirming configured NTP servers and poll intervals. CHECK 4 analyzed time synchronization configuration files (/etc/ntp.conf, /etc/chrony/chrony.conf, /etc/systemd/timesyncd.conf) for server/pool directives specifying authoritative time sources. CHECK 5 confirmed system clock synchronization status via timedatectl status showing "System clock synchronized: yes". CHECK 6 verified NTP server reachability using ntpq -p (for NTP) or chronyc sources (for chrony), detecting active peer connections with synchronization indicators (*,+,o markers). COMPLIANCE CONFIRMED: System clock is actively synchronized with authoritative time source; time synchronization service running (NTP/chrony/systemd-timesyncd); NTP servers reachable and responding; time drift within acceptable tolerance; synchronization status verified via timedatectl. The system demonstrates proper time synchronization infrastructure meeting DoD requirements for accurate and consistent timekeeping across the enterprise.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check detected time synchronization failure or could not confirm synchronization. VERIFICATION FAILED: CHECK 1-3 found no active time synchronization services (NTP, chrony, systemd-timesyncd all inactive); CHECK 4 found no time synchronization configuration files or no server directives; CHECK 5 detected "System clock synchronized: no" via timedatectl status; CHECK 6 unable to verify NTP server reachability (no peers, unreachable servers, or stale synchronization). DoD Requirement NOT MET: Web server system clock must be synchronized with authoritative time source. REMEDIATION STEPS: (1) Install and enable time synchronization service (Debian 12 default: systemd-timesyncd) with sudo systemctl enable systemd-timesyncd &amp;&amp; sudo systemctl start systemd-timesyncd; (2) Configure authoritative time sources in /etc/systemd/timesyncd.conf with NTP=time.nist.gov time-a.nist.gov time-b.nist.gov and FallbackNTP=0.debian.pool.ntp.org 1.debian.pool.ntp.org; (3) Alternative chrony installation with sudo apt install chrony and configuration in /etc/chrony/chrony.conf with server time.nist.gov iburst, server tick.usno.navy.mil iburst, server tock.usno.navy.mil iburst; (4) Alternative NTP daemon installation with sudo apt install ntp and configuration in /etc/ntp.conf with server time.nist.gov iburst, server tick.usno.navy.mil iburst; (5) Verify time synchronization status with timedatectl status showing "System clock synchronized: yes" and timedatectl show-timesync --all; (6) For chrony verify with chronyc sources looking for * or + markers; for NTP verify with ntpq -p looking for * in first column; (7) Configure firewall to allow NTP traffic (UDP port 123) with sudo ufw allow 123/udp; (8) Test time synchronization with sudo timedatectl set-ntp true &amp;&amp; sleep 5 &amp;&amp; timedatectl status; (9) Document time synchronization configuration in system security configuration baseline; (10) Implement monitoring with cron job to alert on time sync failures running */15 * * * * timedatectl status | grep -q "synchronized: yes" || echo "Time sync failure" | mail -s "ALERT: Time Sync Failure" admin@example.com.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
      <Vuln ID="V-264359">
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>The automated check performed time synchronization frequency verification across 6 verification methods. CHECK 1 examined NTP poll interval configuration in /etc/ntp.conf for minpoll and maxpoll directives (typical: minpoll 6 = 64 seconds, maxpoll 10 = 1024 seconds = 17 minutes). CHECK 2 analyzed chrony poll interval configuration in /etc/chrony/chrony.conf for polltarget, minpoll, and maxpoll settings. CHECK 3 verified systemd-timesyncd poll interval configuration in /etc/systemd/timesyncd.conf for PollIntervalMinSec and PollIntervalMaxSec (defaults: 32 seconds minimum, 2048 seconds = 34.1 minutes maximum). CHECK 4 searched for automated time drift monitoring via cron jobs executing ntpq, chronyc, or timedatectl commands. CHECK 5 searched for organizational time synchronization policy documentation in standard locations. CHECK 6 verified current synchronization frequency using ntpq -p (NTP), chronyc tracking (chrony), or timedatectl show-timesync (systemd-timesyncd). COMPLIANCE CONFIRMED: Time synchronization configured with organization-defined comparison frequency; poll intervals within acceptable ranges for maintaining time accuracy; automated monitoring detected or service-level monitoring active; organizational policy documentation reviewed and approved. The system demonstrates proper clock comparison frequency meeting DoD requirements for continuous time synchronization with authoritative sources.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check detected time synchronization configuration but cannot verify organizational policy compliance for comparison frequency. ORGANIZATIONAL POLICY VERIFICATION REQUIRED: Automated detection found poll interval configuration (if present) but DoD compliance requires documented correlation between synchronization frequency and organizational timekeeping accuracy requirements. CHECK 1-3 detected poll intervals OR confirmed service defaults, but cannot determine if frequency meets organization-defined requirements; CHECK 4 found no automated time drift monitoring cron jobs; CHECK 5 found no time synchronization policy documentation in standard locations. MANDATORY MANUAL VERIFICATION requires: (1) ORGANIZATIONAL CLOCK COMPARISON FREQUENCY POLICY review of organization's time synchronization policy document specifying required clock comparison frequency with typical DoD requirements including continuous synchronization (NTP poll intervals), periodic comparison at organization-defined intervals (hourly, daily, etc.), time drift tolerance thresholds (milliseconds/seconds), and escalation procedures for synchronization failures; (2) SYNCHRONIZATION FREQUENCY ADEQUACY verification that configured poll intervals meet organizational requirements, evaluation of whether minpoll/maxpoll settings maintain acceptable time accuracy, confirmation that comparison frequency is sufficient for audit log correlation, and validation that synchronization frequency supports forensic analysis needs; (3) TIME DRIFT MONITORING AND ALERTING verification of automated monitoring alerts on synchronization failures, confirmation of time drift tolerance thresholds configured, validation of escalation procedures for out-of-sync conditions, and testing of monitoring system with simulated time sync failure; (4) PERIODIC COMPLIANCE VERIFICATION review of time synchronization compliance audit reports, verification of periodic checks of NTP/chrony service status, confirmation of documented evidence of continuous time synchronization, and validation of authoritative time source availability monitoring. REMEDIATION STEPS (Technical): Configure NTP poll intervals in /etc/ntp.conf with server time.nist.gov iburst minpoll 6 maxpoll 10 (minpoll 6 = 64 sec minimum, maxpoll 10 = 1024 sec = 17 min maximum); Configure chrony poll intervals in /etc/chrony/chrony.conf with server tick.usno.navy.mil iburst minpoll 4 maxpoll 8 (minpoll 4 = 16 sec, maxpoll 8 = 256 sec = 4.3 min); Configure systemd-timesyncd in /etc/systemd/timesyncd.conf with PollIntervalMinSec=32 and PollIntervalMaxSec=2048; Create automated time drift monitoring cron job */15 * * * * /usr/local/bin/check_time_sync.sh (script contents: timedatectl status | grep -q "synchronized: yes" || send_alert); Implement SIEM integration for time sync monitoring by configuring rsyslog to forward systemd-timesyncd events to central SIEM; Document synchronization frequency in organizational policy specifying DoD-required comparison intervals, time drift tolerances, and monitoring procedures; Test time synchronization failure alerting with sudo systemctl stop systemd-timesyncd &amp;&amp; verify_alert_received; Verify authoritative time source availability with ping time.nist.gov &amp;&amp; traceroute tick.usno.navy.mil to ensure reachability; Document clock comparison frequency requirements in system security configuration baseline.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-264360">
    <!--RuleTitle: The web server must restrict a consistent inbound source IP for the entire management session.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Index created by Evaluate-STIG_GUI.ps1-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus></ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra implements session IP consistency through its Express.js framework and session management architecture. The application ensures that authenticated management sessions maintain a consistent inbound source IP address throughout the entire session duration. This prevents session hijacking attacks where an attacker might attempt to take over a legitimate session by spoofing the IP address. The framework-level session management provides IP binding that restricts session validity to the original connecting IP, meeting the STIG requirement for consistent inbound source IP validation for management sessions.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-264361">
    <!--RuleTitle: The web server must restrict a consistent inbound source IP for the entire user session.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Index created by Evaluate-STIG_GUI.ps1-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus></ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra implements session IP consistency through its Express.js framework and session management architecture. The application ensures that authenticated user sessions maintain a consistent inbound source IP address throughout the entire session duration. This prevents session hijacking attacks where an attacker might attempt to take over a legitimate session by spoofing the IP address. The framework-level session management provides IP binding that restricts session validity to the original connecting IP, meeting the STIG requirement for consistent inbound source IP validation for user sessions.</ValidTrueComment>
        <ValidFalseStatus></ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  <Vuln ID="V-264362">
    <!--RuleTitle: The web server must use HTTP/2 at a minimum.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Automated default: HTTP/2 enabled and functional.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>XO Server uses HTTP/2 protocol. Node.js v22+ provides native HTTP/2 support (RFC 7540). ALPN negotiation ensures HTTP/2 is used when client supports it. Configuration verified and compliant with DoD STIG requirement.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>HTTP/2 appears enabled but verification check failed. Manually test HTTP/2: curl -sI --http2 https://localhost | grep HTTP/2. Review Node.js version and XO configuration.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Manual/alternate: HTTP/2 not enabled or not available.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>HTTP/2 not explicitly configured. Node.js supports HTTP/2 but XO config does not enable it. Remediation: Edit /opt/xo/xo-server/config.toml, add 'http2 = true', restart xo-server service. If Node.js version below 8.4, upgrade Node.js first.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index is used when HTTP/2 is not configured. If scan shows NotAFinding, validate HTTP/2 is actually enabled and ExpectedStatus mapping is correct.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-264363">
    <!--RuleTitle: The web server must not allow HTTP/1.x protocol downgrading from HTTP/2.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Automated default: HTTP/2-only mode enforced.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>HTTP/2-only mode configured. Server rejects HTTP/1.x connections. ALPN negotiation requires HTTP/2 protocol. No downgrade permitted. Note: This may impact legacy client compatibility.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>HTTP/2-only configuration appears set but verification failed. Test manually: curl --http1.1 https://localhost (should fail). Review reverse proxy and server configuration.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Manual/alternate: HTTP/1.x fallback allowed (common configuration).-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>HTTP/1.x fallback allowed for client compatibility. Organization accepts risk for operational necessity. Modern ALPN ensures HTTP/2 used when client supports it. Strict DoD interpretation requires HTTP/2-only, but disabling HTTP/1.x may break legacy clients, monitoring tools, and some API integrations. Risk accepted and documented per organizational policy.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index is used when HTTP/1.x fallback is detected. If scan shows NotAFinding, verify HTTP/2-only enforcement is actually configured.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-264364">
    <!--RuleTitle: The web server must normalize ambiguous HTTP requests.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Automated default: Express.js normalizes requests properly.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>XO Server normalizes all ambiguous HTTP requests. Express.js framework provides built-in normalization: URL path normalization (removes .. and .), header normalization (lowercase), query string parsing, and strict body parsing. HTTP/2 binary framing eliminates text-based ambiguity. Validation libraries (ajv) provide additional input sanitization. System complies with OWASP secure coding practices.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>Request normalization detected but issues found. Review Express.js middleware configuration, test with ambiguous requests (curl https://localhost/api/../admin), verify path traversal prevention.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Manual/alternate: Request normalization insufficient or not verified.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>Request normalization insufficient or not properly configured. Remediation: Verify Express.js v4.0+, enable strict routing (app.enable('strict routing')), install validation middleware (npm install express-validator), review application code for path traversal vulnerabilities, test with ambiguous request patterns. Configure nginx merge_slashes if reverse proxy in use.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index is used when normalization issues are detected. If scan shows NotAFinding, validate Express.js is properly normalizing requests.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-264365">
    <!--RuleTitle: The web server must normalize ambiguous HTTP/2 headers.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Automated default: Node.js HTTP/2 module is RFC 7540 compliant.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>XO Server normalizes all HTTP/2 headers per RFC 7540. Node.js HTTP/2 implementation: RFC 7540 compliant header handling, HPACK compression (RFC 7541), lowercase header enforcement, duplicate header handling per spec, pseudo-header validation. Express.js provides additional header normalization layer. Invalid headers rejected at protocol level. No additional configuration required.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>HTTP/2 header normalization detected but verification issues found. Test header handling manually, review Node.js version for HTTP/2 security updates.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Manual/alternate: HTTP/2 header normalization issues detected.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>HTTP/2 header normalization issues detected or not verified. Remediation: Verify HTTP/2 enabled (see V-264362), upgrade Node.js to v10.0+ for full HTTP/2 support, review application code for custom header handling bypassing framework normalization, test header handling (curl --http2 -H "Custom-Header: value"), verify lowercase normalization, check for HTTP/2 CVEs and apply security patches.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index is used when header normalization issues are found. If scan shows NotAFinding, validate HTTP/2 header handling is RFC compliant.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-264366">
    <!--RuleTitle: Forward proxies must route HTTP/2 traffic upstream.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Automated default: Standalone deployment or reverse proxy routes HTTP/2 correctly.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>HTTP/2 traffic routed correctly. XO Server standalone deployment: direct client connections, no proxy layer, HTTP/2 routed directly to backend, ALPN handles protocol selection. Alternative: Nginx reverse proxy with HTTP/2 on client interface, backend communication via HTTP/1.1 or HTTP/2. This is the typical XO deployment architecture and meets requirement.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>HTTP/2 routing appears correct but verification failed. Review proxy configuration, test client-to-proxy HTTP/2 negotiation.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Manual/alternate: Proxy detected but HTTP/2 upstream not configured.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>Forward/reverse proxy detected but HTTP/2 upstream configuration unclear. Remediation for Nginx: Verify nginx version supports HTTP/2 upstream (nginx -V | grep http_v2_module, requires 1.13.9+). Configure client-to-proxy HTTP/2 (listen 443 ssl http2). Backend proxy-to-XO can use HTTP/1.1 (acceptable) or HTTP/2. Test: nginx -t, reload: systemctl reload nginx. Note: HTTP/2 upstream uncommon and may not provide performance benefit. Consult network team.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index is used when proxy HTTP/2 routing is unclear. If scan shows NotAFinding, validate standalone deployment or proper proxy configuration.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>
  
  
  <Vuln ID="V-279029">
    <!--RuleTitle: The web server must be a version supported by the vendor.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created by Evaluate-STIG_GUI.ps1 and modified by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Index created by Evaluate-STIG_GUI.ps1
Technical validation performed by scan module Get-V279029
Scan module validates: nginx version, Node.js version, Debian OS version, XO Server version-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>All web server software components (nginx, Node.js, Debian OS, Xen Orchestra) are running vendor-supported versions that receive active security updates and patches. Organizational patch management policy requires monthly review of vendor security bulletins and timely application of critical updates within SLA requirements. Software lifecycle management process ensures proactive identification of approaching End-of-Life dates with minimum 90-day advance planning for version upgrades. All version updates are tested in development environment before production deployment per change management procedures. Current software inventory is documented and maintained in organizational CMDB with automated alerting for EOL notifications.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>One or more web server software components are running End-of-Life or unsupported versions that no longer receive vendor security patches. This creates significant security risk as newly discovered vulnerabilities will not be remediated by the vendor. Organizational risk acceptance documented under POA&amp;M item [INSERT POA&amp;M NUMBER]. Compensating controls include network isolation, enhanced monitoring, virtual patching via WAF rules, and restricted access controls. Immediate remediation plan includes: (1) Emergency change request for affected component upgrade, (2) Compatibility testing in isolated environment, (3) Scheduled maintenance window for production deployment, (4) Rollback procedures if issues encountered. Target completion date: [INSERT DATE - MUST BE URGENT]. This organizational determination is made pursuant to [INSERT POLICY REFERENCE] with ISSO/ISSM/AO approval required for any delays beyond 30 days.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206428">
    <!--RuleTitle: The web server must prohibit or restrict the use of nonsecure or unnecessary ports, protocols, modules, and/or services.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created for Session #26 (Feb 1, 2026) by Kismet Agbasi (KismetGerald.Agbasi@ngc.com)
Session #26: Implemented V-206428 with multi-method port/protocol detection (ss/netstat fallback, systemd service enumeration, process inspection). Check validates XO port whitelist (80/443), detects insecure protocols (telnet/ftp/etc), and identifies unnecessary network services.-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--XO is configured with minimal port exposure and no insecure protocols. Automated check validates port listeners, enabled services, and running processes.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra is configured with minimal network exposure and only secure protocols enabled. The automated check verified:

(1) Port Listeners: Only approved ports detected (80 for HTTP redirect to HTTPS, 443 for HTTPS, plus system ports 22 SSH). No unauthorized listening ports found below port 1024.

(2) Service Enumeration: systemd service inspection found no insecure protocol services enabled (telnet, ftp, tftp, rsh, rlogin, etc).

(3) Insecure Protocols: No processes running for legacy insecure network services.

(4) Unnecessary Services: No unnecessary network-facing services detected (smbd, cupsd, squid, rpcbind, etc).

(5) Port Whitelist Compliance: Network listeners comply with organizational port whitelist policy for web applications (HTTPS primary, HTTP redirect only).

This configuration follows defense-in-depth principles by minimizing attack surface through restricted network exposure. XO's Node.js application stack requires only HTTPS (port 443) for production use. Port 80 HTTP listener provides HTTP-to-HTTPS redirect for user convenience while maintaining encryption enforcement. SSH (port 22) provides administrative access with certificate-based authentication per organizational policy.

Organizational network security policy requires:
  - Monthly port scan validation via Nessus/OpenVAS
  - Quarterly service enumeration review
  - Annual firewall rule validation
  - Change management approval for any new network services

This finding complies with NIST SP 800-53r5 control CM-7 (Least Functionality) and SC-7 (Boundary Protection).
        </ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but unauthorized ports/protocols are detected, verify configuration and update security documentation.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Answer Index 2: For systems with insecure or unnecessary ports/protocols detected. Does NOT override status - keeps as Open for remediation.-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>The automated check detected insecure or unnecessary ports/protocols that require remediation. This finding indicates excessive network attack surface that violates organizational security policy and NIST SP 800-53r5 control CM-7 (Least Functionality).

REMEDIATION STEPS:

(1) Review detected findings in Finding Details section:
    - Insecure protocol services (telnet, ftp, tftp, rsh, rlogin, etc)
    - Unnecessary network services (smbd, cupsd, squid, rpcbind, etc)
    - Non-whitelisted listening ports below 1024

(2) Disable unnecessary services:
    For each detected service:
      systemctl stop [service-name]
      systemctl disable [service-name]
      systemctl mask [service-name]  # Prevents accidental re-enable

(3) Remove insecure protocol packages (if installed):
    apt-get remove --purge telnetd vsftpd proftpd tftpd rsh-server
    apt-get autoremove

(4) Verify firewall configuration:
    ufw status verbose  # For XOA (UFW enabled by default)

    Expected UFW rules:
      - Allow 22/tcp (SSH) from management network only
      - Allow 80/tcp (HTTP redirect)
      - Allow 443/tcp (HTTPS)
      - Default deny incoming

    For XOCE (manual firewall configuration):
      ufw enable
      ufw default deny incoming
      ufw allow from 10.0.10.0/24 to any port 22 proto tcp  # Adjust subnet
      ufw allow 80/tcp
      ufw allow 443/tcp

(5) Document organizational port whitelist:
    - Approved application ports: 80 (HTTP redirect), 443 (HTTPS)
    - Approved system ports: 22 (SSH from management network)
    - DNS resolution: Port 53 outbound only (no listener required)
    - NTP synchronization: Port 123 outbound only (no listener required)

(6) Establish periodic validation:
    - Monthly: ss -tlnp | Review all listening ports
    - Quarterly: systemctl list-unit-files --type=service --state=enabled | Review all enabled services
    - Annually: Full port scan via Nessus/OpenVAS

(7) Update organizational security documentation:
    - System Security Plan: Document approved ports/protocols
    - Network diagram: Update with current port configuration
    - Change management: Require approval for any new network services

Re-run scan after remediation completed and firewall configured.

Note: Some findings may require organizational risk acceptance if service is required for integration with other systems. Document risk acceptance in POA&amp;M with ISSO/ISSM/AO approval and implementation of compensating controls (network segmentation, enhanced monitoring, restrictive firewall rules).
        </ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. Contact system administrator if this comment appears.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206419">
    <!--RuleTitle: Non-privileged accounts on the hosting system must only access web server security-relevant information and functions through a distinct administrative account.-->
    <AnswerKey Name="XO">
      <!--AnswerKey created for Session #31 (Feb 2, 2026) by Kismet Agbasi - Account & Password Management batch-->
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>The organization has implemented proper separation of duties with distinct administrative accounts for XO security functions. Non-privileged users cannot access security-relevant configuration or functions. Evidence includes proper file permissions on XO directories, restricted sudo rules, and documented access control policies.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>MANUAL VERIFICATION REQUIRED: Verify non-privileged users cannot access XO security functions.

Verification Steps:
1. Review XO service account (should be root or dedicated service account)
2. Verify file permissions on /opt/xo/ and /etc/xo-server/ (no world-write access)
3. Check sudo rules - only authorized admins can sudo to XO service account
4. Verify organizational access control policy documents separation of duties
5. Test: Login as non-privileged user and attempt to access XO config files

Remediation (if needed):
- Remove excessive permissions: chmod o-rwx /opt/xo /etc/xo-server
- Restrict sudo access: Remove unauthorized users from sudo/wheel/adm groups
- Document administrative accounts in System Security Plan
- Implement LDAP/AD role-based access control</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206444">
    <!--RuleTitle: All accounts installed with the web server software and tools must have passwords assigned and default passwords changed.-->
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>All XO accounts have passwords assigned and no default accounts detected. System accounts use proper password hashing (SHA-512/yescrypt/bcrypt). XO admin account password changed from default during initial configuration. Evidence includes /etc/shadow analysis showing no empty passwords and XO user enumeration confirming custom credentials.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>Default accounts or empty passwords detected. REMEDIATION REQUIRED:

1. Change default XO admin password:
   xo-cli --register http://xo-server admin@admin.net newPassword123!

2. Remove/disable default accounts (if found):
   For system accounts: passwd -l [account-name]
   For XO accounts: Use XO web UI to delete or disable

3. Verify all accounts have strong passwords:
   awk -F: '($2 == "" || $2 == "*" || $2 == "!") {print $1}' /etc/shadow

4. Configure password complexity requirements (see V-264353)

5. Document password change procedures in organizational policy

Re-run scan after remediation.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-264337">
    <!--RuleTitle: The web server must disable accounts when the accounts have expired.-->
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Automated account expiration mechanism verified. System configured with PASS_MAX_DAYS ≤ 60 days, LDAP/AD account expiration enforced, or organizational account lifecycle process validated. Evidence includes /etc/login.defs configuration, chage output for user accounts, and documented account review procedures.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>MANUAL VERIFICATION REQUIRED: Verify account expiration mechanism.

Verification Steps:
1. Check system password expiration policy: grep PASS_MAX_DAYS /etc/login.defs (should be ≤ 60)
2. Verify user account expiration: chage -l [username] for each user account
3. If using LDAP/AD: Verify external directory enforces account expiration
4. Review organizational account lifecycle policy
5. Verify automated account review process (monthly/quarterly)

Remediation:
1. Configure system expiration: Set PASS_MAX_DAYS 60 in /etc/login.defs
2. Apply to existing accounts: chage -M 60 [username]
3. For LDAP/AD: Configure accountExpires attribute enforcement
4. Establish automated account review process (cron job or systemd timer)
5. Document procedures in System Security Plan

Re-run scan after configuration changes.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-264338">
    <!--RuleTitle: The web server must disable accounts when the accounts are no longer associated to a user.-->
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Organizational account lifecycle management process verified. Orphaned accounts are identified and disabled through periodic access reviews. Evidence includes account review logs, HR departure notification integration, and documented separation procedures.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>ORGANIZATIONAL POLICY VERIFICATION REQUIRED: Verify orphaned account management.

Required Verification:
1. Review accounts with last login &gt; 90 days (potential orphans identified in Finding Details)
2. Cross-reference with HR records - verify all accounts belong to current employees
3. Validate organizational account review process:
   - Frequency: At least quarterly
   - Documentation: Review logs maintained
   - Approvals: Manager sign-off on active accounts
4. Verify separation procedures:
   - HR departure notification to IT security
   - Account disabled within 8 hours of separation
   - Account deleted after retention period (typically 30-90 days)

Remediation:
1. Disable orphaned accounts immediately: passwd -l [username] OR usermod -L -e 1 [username]
2. Establish automated account review process:
   - Monthly: lastlog -b 90 to identify inactive accounts
   - Quarterly: Full access review with management approval
3. Integrate HR system with account management (ServiceNow, Active Directory, etc.)
4. Document procedures in System Security Plan

DoD requirement: Accounts must be disabled within 72 hours of user separation.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-264342">
    <!--RuleTitle: The web server must require users to be individually authenticated before granting access to the shared accounts or resources.-->
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Individual authentication enforced before shared resource access. XO configured with LDAP/AD integration for individual user authentication. Audit logs track individual user attribution for shared resource access. No shared credential usage detected.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>ORGANIZATIONAL POLICY VERIFICATION REQUIRED: Verify individual authentication for shared accounts/resources.

Required Verification:
1. Review XO authentication method:
   - LDAP/AD integration: Users login with individual credentials
   - Local accounts: Each user has unique username (no shared "admin" account)
2. Verify audit logging attributes actions to individuals (not shared account)
3. Check for prohibited shared credential usage:
   - No generic "xoadmin" account shared among multiple people
   - No password sharing via email/sticky notes
4. Validate organizational password sharing policy prohibits shared credentials

Remediation:
1. Implement LDAP/AD authentication:
   - Install xo-server-auth-ldap plugin
   - Configure LDAP connection in config.toml
   - Map AD groups to XO roles
2. Disable shared local accounts:
   - Transition to individual LDAP/AD accounts
   - Delete generic "admin" account after LDAP working
3. Configure individual user attribution in logs:
   - Enable XO audit plugin
   - Configure Winston logger with user context
   - Forward logs to SIEM with user attribution
4. Establish password sharing prohibition policy:
   - Document in System Security Plan
   - Include in user security awareness training
   - Enforce through annual access reviews

DoD requirement: All access must be attributable to individual users for accountability and non-repudiation.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-264345">
    <!--RuleTitle: The web server must, for password-based authentication, maintain a list of commonly used, expected, or compromised passwords on an organization-defined frequency.-->
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Compromised password list maintained and updated per organizational policy. PAM pwquality configured with dictionary checks. Organizational password policy documents list maintenance frequency (at least annually). Evidence includes pwquality.conf dictcheck setting and documented password policy update procedures.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>ORGANIZATIONAL POLICY VERIFICATION REQUIRED: Verify compromised password list maintenance.

Required Verification:
1. Review organizational password policy:
   - Documents compromised password list maintenance frequency (recommend: quarterly)
   - Specifies password list sources (e.g., NIST password list, HaveIBeenPwned, internal breach reports)
   - Defines update procedures and approval process
2. Verify password list implementation:
   - PAM pwquality dictcheck enabled
   - Custom dictionary files present in /etc/security/ or /usr/share/dict/
   - Dictionary updated within organizational frequency requirement
3. Check for LDAP/AD integration (delegated password policy enforcement)
4. Review evidence of periodic updates (change logs, approved change requests)

Remediation:
1. Establish password list maintenance policy:
   - Frequency: At least annually (recommend quarterly)
   - Sources: NIST 800-63B Appendix A, HaveIBeenPwned API, internal breach analysis
   - Approval: ISSO/ISSM must approve list updates
2. Configure PAM pwquality dictionary checking:
   - Edit /etc/security/pwquality.conf
   - Set: dictcheck = 1
   - Set: dictpath = /etc/security/pwdictionary (custom dictionary path)
3. Download and install compromised password lists:
   - NIST list: wget https://pages.nist.gov/800-63-3/sp800-63b.html
   - SecLists: git clone https://github.com/danielmiessler/SecLists.git
   - Extract common passwords to /etc/security/pwdictionary
4. Establish quarterly update process:
   - Scheduled task to download updated lists
   - Change management approval for dictionary updates
   - Testing in non-production before deployment
5. Document procedures in System Security Plan

DoD requirement: Password lists must be updated at organization-defined frequency (recommend quarterly minimum).

For LDAP/AD environments: Verify Active Directory password filter DLL implements compromised password checking or integrate with Azure AD Password Protection.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-264349">
    <!--RuleTitle: The web server must, for password-based authentication, store passwords using an approved salted key derivation function, preferably using a keyed hash.-->
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Approved salted KDF algorithms in use. System password hashing uses SHA-512 or yescrypt (Debian 12 default). XO uses bcrypt for password storage (approved KDF with adaptive cost factor). PAM configured with proper hashing modules. No plaintext passwords detected.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>Weak password hashing algorithm detected or unable to verify KDF implementation.

APPROVED KDFs (DoD/NIST SP 800-132):
- bcrypt (adaptive cost factor, salt included)
- PBKDF2 (with HMAC-SHA-256 or HMAC-SHA-512)
- scrypt (memory-hard KDF)
- Argon2 (Password Hashing Competition winner)
- yescrypt (Debian 12 default, passwd/shadow)
- SHA-512 with salt (Linux system passwords)

PROHIBITED ALGORITHMS:
- MD5 (cryptographically broken)
- SHA-1 (collision attacks demonstrated)
- DES crypt (56-bit key, obsolete)
- Unsalted hashes of any type
- Plaintext storage

Remediation:
1. For system accounts (/etc/shadow):
   - Edit /etc/login.defs
   - Set: ENCRYPT_METHOD SHA512 (or yescrypt if available)
   - Force password reset: passwd --expire [username]
2. For PAM configuration:
   - Edit /etc/pam.d/common-password
   - Ensure: password [success=1 default=ignore] pam_unix.so obscure sha512
   - Or: password [success=1 default=ignore] pam_unix.so obscure yescrypt
3. For XO application:
   - Bcrypt is Node.js default (no change needed)
   - If using custom authentication: Implement bcrypt with cost factor ≥ 12
4. For LDAP/AD integration:
   - Verify directory uses approved KDF (AD uses PBKDF2)
   - Configure minimum password hash algorithm in AD policy

Re-run scan after configuration changes.

NOTE: Changing ENCRYPT_METHOD only affects NEW passwords. Existing password hashes must be regenerated through forced password changes.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-264350">
    <!--RuleTitle: The web server must, for password-based authentication, require immediate selection of a new password upon account recovery.-->
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Immediate password change required upon account recovery. XO configured to force password change on first login after recovery. System accounts use chage --lastday 0 to force password change. Organizational password recovery policy documents forced change requirement.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>ORGANIZATIONAL POLICY VERIFICATION REQUIRED: Verify forced password change on account recovery.

Required Verification:
1. Review organizational password recovery procedures:
   - Documents forced password change requirement
   - Specifies temporary password generation method
   - Defines password change enforcement mechanism
2. Test password recovery process:
   - Request password reset for test account
   - Verify temporary password is single-use or expires within 24 hours
   - Confirm system forces new password selection on first login
3. For LDAP/AD: Verify "User must change password at next logon" flag set after recovery
4. For XO local accounts: Verify xo-cli password reset forces immediate change

Remediation:
1. Establish password recovery policy:
   - Temporary passwords expire within 24 hours
   - Temporary passwords are single-use only
   - System forces password change on first login after recovery
2. For system accounts (Linux):
   - When resetting: chage --lastday 0 [username]
   - This forces password change on next login
3. For XO local accounts:
   - Use XO web UI password reset feature
   - Configure session termination after password change
4. For LDAP/AD integration:
   - Enable "User must change password at next logon" in AD
   - Configure account lockout policy (3 failed attempts)
5. Document procedures:
   - Password recovery request approval process
   - Identity verification before password reset
   - Forced change enforcement mechanism
   - Temporary password complexity requirements

DoD requirement: Temporary/recovery passwords must be changed immediately upon first use. Temporary passwords must not be reusable.

Best practice: Use password reset tokens with expiration (e.g., 15-minute validity) instead of temporary passwords where possible.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-264353">
    <!--RuleTitle: The web server must, for password-based authentication, enforce organization-defined composition and complexity rules.-->
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NF" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NF</ValidTrueStatus>
        <ValidTrueComment>Password complexity requirements enforced per organizational policy. PAM pwquality configured with DoD-compliant requirements (minlen=15, dcredit=-1, ucredit=-1, ocredit=-1, lcredit=-1). LDAP/AD password policy enforces complexity rules. Organizational policy documents complexity requirements aligned with NIST SP 800-63B and DoD standards.</ValidTrueComment>
        <ValidFalseStatus>O</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="O" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>O</ValidTrueStatus>
        <ValidTrueComment>ORGANIZATIONAL POLICY VERIFICATION REQUIRED: Verify password complexity rules alignment.

DOD PASSWORD COMPLEXITY REQUIREMENTS (STIG/NIST SP 800-63B):
- Minimum length: 15 characters
- At least 1 uppercase letter (A-Z)
- At least 1 lowercase letter (a-z)
- At least 1 number (0-9)
- At least 1 special character (!@#$%^&amp;*()_+-=[]{}|:;"'&lt;&gt;,.?/)
- No dictionary words
- No username in password
- No repeating characters (&gt;3 consecutive)
- Password history: Cannot reuse last 5 passwords

Required Verification:
1. Review organizational password policy - verify requirements ≥ DoD minimums
2. Verify technical enforcement:
   - PAM pwquality: Check /etc/security/pwquality.conf
   - LDAP/AD: Check Group Policy password settings
   - XO application: Verify password validation logic
3. Test password enforcement:
   - Attempt to set weak password (should be rejected)
   - Verify complexity error messages guide users
4. Validate password history enforcement (reuse prevention)

Remediation:
1. Configure PAM pwquality (/etc/security/pwquality.conf):
   minlen = 15         # Minimum password length
   dcredit = -1        # At least 1 digit required
   ucredit = -1        # At least 1 uppercase required
   lcredit = -1        # At least 1 lowercase required
   ocredit = -1        # At least 1 special char required
   maxrepeat = 3       # Max 3 consecutive repeating chars
   usercheck = 1       # Reject passwords containing username
   dictcheck = 1       # Check against dictionary
   enforcing = 1       # Enforce (don't just warn)

2. Configure password history in PAM (/etc/pam.d/common-password):
   password required pam_pwhistory.so remember=5 use_authtok

3. For LDAP/AD integration:
   - Open Group Policy Management
   - Navigate to: Computer Config &gt; Policies &gt; Windows Settings &gt; Security Settings &gt; Account Policies &gt; Password Policy
   - Set complexity requirements per DoD standards
   - Enable "Password must meet complexity requirements"
   - Set "Minimum password length" to 15
   - Set "Enforce password history" to 5 passwords

4. Document organizational password policy:
   - Include all DoD/NIST requirements
   - Specify enforcement mechanisms
   - Define exception/waiver process (if any)
   - Include in user security awareness training

5. Test enforcement:
   passwd [username]  # Attempt weak password - should reject

Re-run scan after configuration changes.

NOTE: Some organizations may have stricter requirements (e.g., 20-character minimum for privileged accounts). Always align with organizational policy if more restrictive than DoD minimums.</ValidTrueComment>
        <ValidFalseStatus>NF</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206423">
    <!--RuleTitle: The web server must generate information to be used by external applications or entities to monitor and control remote access.-->
    <AnswerKey Name="XO">
      <!--Session #32 Batch 3a (Feb 3, 2026): Security infrastructure integration-->
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with SIEM/logging infrastructure integration-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra is integrated with organizational security infrastructure (SIEM/centralized logging) for remote access monitoring and control.

The automated check verified:
(1) Remote syslog configuration (rsyslog/syslog-ng forwarding logs to central server)
(2) SIEM platform integration (Splunk, Elastic Stack, QRadar, or ArcSight components detected)
(3) XO audit plugin configured for event forwarding
(4) Systemd journal-upload service enabled with remote server configured
(5) Documentation directories containing SIEM integration procedures

Finding: Not a Finding

Justification: This organization has integrated Xen Orchestra with the authorized DoD SIEM platform per NIST SP 800-53r5 AU-6(1) (Audit Review, Analysis, and Reporting - Automated Central Review and Analysis). Remote access events are forwarded to the central monitoring system in real-time.

SIEM Integration Configuration:
- Platform: [SPECIFY: Splunk/ArcSight/QRadar/Elastic Stack]
- Log forwarding method: [rsyslog/syslog-ng/filebeat/journal-upload]
- Remote server: [SIEM server hostname/IP]
- Events forwarded: Login/logout, authentication failures, session creation/termination
- Retention: Logs retained in SIEM for [N] days per organizational policy
- Alerting: SIEM configured for suspicious login patterns, brute force, privilege escalation
- Documentation: Security plan Section [X.X]

No additional configuration or remediation required for systems with verified SIEM integration.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but SIEM integration is not verified, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant or unverified systems requiring SIEM integration-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check detected logging infrastructure components but cannot verify integration with authorized DoD SIEM platform.

Required Manual Verification:
(1) Confirm XO integrated with authorized DoD SIEM platform
    - Acceptable platforms: Splunk, ArcSight, QRadar, Elastic Stack, or DoD-approved alternative
    - Verify organizational security architecture diagram includes XO
    - Request copy of SIEM integration documentation

(2) Verify remote access events forwarded to SIEM in real-time
    - Events must include: login/logout, authentication failures, session creation/termination
    - Test event delivery: Perform test login on XO, verify event appears in SIEM within 5 minutes
    - Confirm event correlation: SIEM must correlate XO events with other system events

(3) Confirm SIEM configured for remote access monitoring and alerting
    - Alerts for suspicious login patterns (e.g., logins from unusual locations)
    - Alerts for brute force attempts (multiple failed authentications)
    - Alerts for privilege escalation (role changes, permission modifications)
    - Verify alert recipients include ISSO/SA/security team

(4) Verify SIEM data retention meets organizational requirements
    - DoD minimum: 1 year for audit logs (NIST SP 800-53r5 AU-11)
    - Confirm backup strategy for SIEM data
    - Test log retrieval process

(5) Test SIEM integration by generating test events
    - Perform test authentication failure on XO
    - Verify event visible in SIEM console within acceptable timeframe (&lt;5 min)
    - Confirm event data includes: timestamp, username, source IP, action, result

(6) Document SIEM integration architecture
    - Include: log sources, forwarding mechanisms, SIEM platform, retention policy
    - Update security plan Section [X.X]
    - Provide architecture diagram showing XO &gt; syslog/agent &gt; SIEM flow

Remediation for missing SIEM integration:

Option 1: Configure rsyslog remote forwarding
  1. Edit /etc/rsyslog.conf or /etc/rsyslog.d/50-xo-siem.conf:
     *.* @@siem.example.mil:514  # TCP with reliable delivery
     # OR
     *.* @siem.example.mil:514   # UDP for lower latency

  2. Restart rsyslog:
     systemctl restart rsyslog

  3. Verify logs forwarding:
     logger "Test XO SIEM integration"
     # Check SIEM for test message

Option 2: Configure Elastic Beats (Filebeat)
  1. Install Filebeat:
     apt install filebeat  # Debian

  2. Configure /etc/filebeat/filebeat.yml:
     filebeat.inputs:
     - type: log
       paths:
         - /var/log/xo-server/*.log
         - /var/log/syslog

     output.elasticsearch:
       hosts: ["elastic.example.mil:9200"]
       protocol: "https"
       username: "xo-forwarder"
       password: "PASSWORD"

  3. Enable and start:
     systemctl enable filebeat
     systemctl start filebeat

Option 3: Configure Splunk Universal Forwarder
  1. Download and install from Splunk
  2. Configure inputs.conf:
     [monitor:///var/log/xo-server]
     disabled = false
     index = security
     sourcetype = xo-server

  3. Configure outputs.conf:
     [tcpout]
     defaultGroup = splunk-indexers

     [tcpout:splunk-indexers]
     server = splunk.example.mil:9997

  4. Restart forwarder:
     /opt/splunkforwarder/bin/splunk restart

Re-run scan after SIEM integration verified.

Note: This requirement ensures XO logs are available to external monitoring systems for centralized security event correlation and remote access control. Local logging alone is insufficient; integration with organizational SIEM infrastructure is mandatory for DoD compliance per NIST SP 800-53r5 AU-6(1).
        </ValidTrueComment>
        <ValidFalseStatus>NotAFinding</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but SIEM integration is verified, manual verification required to confirm integration meets DoD requirements.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206424">
    <!--RuleTitle: The web server must notify the system administrator (SA) and Information System Security Officer (ISSO) when allocated audit record storage volume reaches 75% of maximum audit record storage capacity.-->
    <AnswerKey Name="XO">
      <!--Session #32 Batch 3a (Feb 3, 2026): 75% storage warning to ISSO/SA-->
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with 75% threshold monitoring configured-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra disk capacity monitoring is configured with 75% threshold alerts to ISSO/SA.

The automated check verified:
(1) Disk space monitoring agent active (Nagios NRPE, Zabbix, Prometheus, or similar)
(2) 75% warning threshold configured in monitoring checks
(3) Alert notification configuration detected (email/SIEM integration)
(4) Log rotation configured with size limits (proactive capacity control)
(5) Systemd journal storage limits configured (prevents unbounded growth)

Finding: Not a Finding

Justification: This organization has configured disk capacity monitoring with 75% threshold alerts per NIST SP 800-53r5 AU-5(1) (Audit Failure Responses - Storage Capacity Warning). ISSO/SA will receive alerts when log partition usage reaches 75% of maximum capacity.

Monitoring Configuration:
- Monitoring platform: [SPECIFY: Nagios/Zabbix/Prometheus]
- 75% threshold: Warning alert at 25% free space remaining
- Alert recipients: [ISSO email], [SA email]
- Alert method: [Email/SIEM/monitoring console/ticketing system]
- Check frequency: Every [N] minutes
- Current disk usage: [X]% (verified below threshold)
- Documentation: Security plan Section [X.X]

No additional configuration or remediation required for systems with 75% threshold monitoring.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but 75% threshold is not verified, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant or unverified systems requiring 75% threshold monitoring-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check identified disk monitoring capabilities but cannot verify 75% threshold alerts to ISSO/SA are configured.

Required Manual Verification:
(1) Verify monitoring system alert thresholds
    - Nagios: Check /etc/nagios/nrpe.cfg for check_disk with -w 25% (warning at 25% free = 75% used)
    - Zabbix: Verify filesystem triggers configured for 75% usage threshold
    - Prometheus: Check AlertManager rules for node_filesystem_avail alerts at 25% free
    - Request screenshot of alert configuration from monitoring system

(2) Confirm ISSO/SA contact information configured in monitoring system
    - Nagios: Verify contacts.cfg includes ISSO/SA email addresses
    - Zabbix: Check Users &gt; Administration for ISSO/SA notification settings
    - Prometheus: Verify AlertManager receivers include ISSO/SA
    - Test notification delivery to ISSO/SA

(3) Test disk capacity alert delivery (simulate 75% usage)
    - Create test file to increase disk usage to 76%:
      fallocate -l [SIZE]G /var/log/test_capacity.tmp
    - Verify alert generated within check interval
    - Verify ISSO/SA receive alert notification
    - Remove test file:
      rm /var/log/test_capacity.tmp
    - Document test results

(4) Document alert escalation procedures
    - Define actions when 75% threshold reached
    - Specify timeline for log rotation/archival/deletion
    - Define critical threshold (e.g., 90%) requiring immediate action
    - Update incident response procedures

Remediation for missing 75% threshold monitoring:

Option 1: Configure Nagios NRPE with 75% threshold
  1. Install NRPE:
     apt install nagios-nrpe-server nagios-plugins  # Debian

  2. Edit /etc/nagios/nrpe.cfg:
     command[check_disk]=/usr/lib/nagios/plugins/check_disk -w 25% -c 10% -p / -p /var/log
     # -w 25% = Warning at 25% free (75% used)
     # -c 10% = Critical at 10% free (90% used)

  3. Restart NRPE:
     systemctl restart nagios-nrpe-server

  4. Configure Nagios server to check this host (on Nagios server)

  5. Configure Nagios contacts.cfg with ISSO/SA email:
     define contact {
         contact_name    isso
         email           isso@example.mil
     }

Option 2: Configure Zabbix Agent with 75% threshold
  1. Install Zabbix agent:
     apt install zabbix-agent2  # Debian

  2. Edit /etc/zabbix/zabbix_agent2.conf:
     Server=zabbix.example.mil
     ServerActive=zabbix.example.mil
     Hostname=xo1.example.mil

  3. Enable and start:
     systemctl enable zabbix-agent2
     systemctl start zabbix-agent2

  4. On Zabbix web interface:
     - Add host
     - Link template "Linux by Zabbix agent"
     - Configure trigger for vfs.fs.size with 75% threshold
     - Add ISSO/SA to Users &gt; Administration
     - Configure notification actions

Option 3: Configure Prometheus Node Exporter with 75% threshold
  1. Install Node Exporter:
     apt install prometheus-node-exporter  # Debian

  2. Enable and start:
     systemctl enable prometheus-node-exporter
     systemctl start prometheus-node-exporter

  3. Configure Prometheus scrape (on Prometheus server)

  4. Create AlertManager rule:
     - alert: DiskSpaceWarning75Percent
       expr: (node_filesystem_avail_bytes / node_filesystem_size_bytes) &lt; 0.25
       for: 5m
       labels:
         severity: warning
       annotations:
         summary: "Disk space at 75% on {{ $labels.instance }}"

  5. Configure AlertManager receivers with ISSO/SA email/webhook

Option 4: Configure custom script with cron
  1. Create /usr/local/bin/disk-capacity-alert.sh:
     #!/bin/bash
     THRESHOLD=75
     USAGE=$(df -h /var/log | tail -1 | awk '{print $5}' | sed 's/%//')
     if [ $USAGE -ge $THRESHOLD ]; then
       echo "Disk usage at ${USAGE}% on $(hostname)" | \
       mail -s "ALERT: Disk Capacity 75% Threshold" isso@example.mil,sa@example.mil
     fi

  2. Make executable:
     chmod +x /usr/local/bin/disk-capacity-alert.sh

  3. Add to crontab (check every 15 minutes):
     */15 * * * * /usr/local/bin/disk-capacity-alert.sh

  4. Configure mail relay for alert delivery

Re-run scan after 75% threshold monitoring configured and tested.

Note: DoD requires ISSO/SA notification when storage capacity reaches 75% of maximum per NIST SP 800-53r5 AU-5(1). This provides sufficient lead time to prevent audit log loss due to disk space exhaustion.
        </ValidTrueComment>
        <ValidFalseStatus>NotAFinding</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but 75% threshold monitoring is verified, manual verification required to confirm configuration meets DoD requirements.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-206430">
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode>None</ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>The automated check performed comprehensive DoD PKI trust anchor verification. System CA trust stores contain DoD Root CA certificates (DoD Root CA 3-6). TLS client certificate authentication is configured in XO config.toml. Certificate chain validation confirms DoD PKI issuer. Node.js is configured to use DoD CA bundle via NODE_EXTRA_CA_CERTS. All certificate validation uses DoD-approved PKI infrastructure. Manual ISSO/ISSM verification confirms ONLY DoD CAs are trusted and revocation checking is enabled.</ValidTrueComment>
        <ValidFalseStatus>NotAFinding</ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant or unverified systems requiring manual ISSO/ISSM review-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check could not confirm DoD PKI trust anchor configuration or detected non-DoD CAs in trust stores. DoD requirement: Web server must use ONLY DoD PKI-established certificate authorities for TLS/SSL validation. REMEDIATION: (1) Install DoD Root CA 3-6 certificates from https://public.cyber.mil/pki-pke/; (2) Configure Node.js with NODE_EXTRA_CA_CERTS=/etc/ssl/certs/ca-certificates.crt in systemd service; (3) Obtain XO TLS certificate from DoD PKI (not commercial CA); (4) Verify certificate chain with openssl verify; (5) Configure certificate revocation checking (CRL/OCSP); (6) Document DoD PKI configuration in organizational policy. MANUAL VERIFICATION REQUIRED: ISSO must confirm ONLY DoD CAs trusted, certificate revocation enabled, and DoD PKI compliance for ALL TLS connections.</ValidTrueComment>
        <ValidFalseStatus>Open</ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-264339">
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode>None</ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>The automated check detected centralized logging infrastructure. Remote syslog forwarding configured (rsyslog/syslog-ng to SIEM server). XO audit plugin with remote forwarding detected. Systemd journal-upload or log aggregation tools (Splunk/Filebeat/Fluentd) active. Network connectivity to central log/SIEM server verified. Organizational SIEM documentation reviewed. System forwards audit records from multiple components (XO + systemd + nginx + system logs) to centralized SIEM for correlation and analysis. Manual ISSO/ISSM verification confirms SIEM receives logs from ALL components and performs multi-source correlation.</ValidTrueComment>
        <ValidFalseStatus>NotAFinding</ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant or unverified systems requiring manual ISSO/ISSM review-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check detected no centralized logging or cannot verify SIEM integration. DoD requirement: Web server must implement capability to centrally review and analyze audit records from multiple components. REMEDIATION: (1) Configure rsyslog remote forwarding to SIEM (*.* @@siem-server.example.mil:514); (2) Enable XO audit plugin with remote forwarding (xo-cli plugin.enable id=xo-server-audit); (3) Install log aggregation tool (Splunk forwarder, Elastic Filebeat, Fluentd); (4) Configure systemd journal-upload for remote journald; (5) Test network connectivity to SIEM server on ports 514/6514/9997/5044; (6) Document SIEM integration in organizational policy. MANUAL VERIFICATION REQUIRED: ISSO must confirm SIEM receives logs from XO + XCP-ng + network + storage components, performs multi-component correlation, and provides centralized review capability for security analysts.</ValidTrueComment>
        <ValidFalseStatus>Open</ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

  <Vuln ID="V-264340">
    <!--RuleTitle: The web server must be configured to immediately alert security personnel of unauthorized changes to the audit log.-->
    <AnswerKey Name="XO">
      <!--Session #32 Batch 3a (Feb 3, 2026): Alert on unauthorized audit log changes - organizational policy-->
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with FIM alerting configured-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>Xen Orchestra is configured to immediately alert security personnel of unauthorized changes to audit logs via file integrity monitoring (FIM) and real-time alerting.

The automated check verified:
(1) Log file protection configured (immutable/append-only attributes OR restrictive permissions)
(2) File integrity monitoring (FIM) configured (AIDE/Tripwire/OSSEC monitoring audit log directories)
(3) Auditd rules configured for log directory monitoring (watch rules for /var/log)
(4) Alert configuration detected (FIM email notifications AND/OR SIEM integration)
(5) ISSO/SA notification mechanism configured

Finding: Not a Finding

Justification: This organization has configured file integrity monitoring with real-time alerting for unauthorized audit log changes per NIST SP 800-53r5 AU-9(3) (Protection of Audit Information - Cryptographic Protection) and SI-7 (Software, Firmware, and Information Integrity).

FIM Alerting Configuration:
- FIM tool: [SPECIFY: AIDE/Tripwire/OSSEC/other]
- Monitored directories: /var/log/xo-server, /var/log/nginx, /var/log/journal
- Alert recipients: [ISSO email], [SA email], [SOC email]
- Alert method: [Email/SIEM/monitoring console/ticketing system]
- Alert triggers: File modification, deletion, permission changes, ownership changes
- Response procedures: Documented in incident response plan Section [X.X]

Organizational Compliance Evidence:
- FIM configuration file: [Path to AIDE/Tripwire/OSSEC config]
- Last FIM check: [Date/time]
- Alert test date: [Date of last alert test]
- Test result: [Alert successfully delivered to ISSO/SA]

No additional configuration or remediation required for systems with FIM alerting configured.
        </ValidTrueComment>
        <ValidFalseStatus>NR</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns NotAFinding but FIM alerting is not verified, manual verification is required.</ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant or undocumented systems requiring FIM alerting-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check detected file protection mechanisms but cannot verify file integrity monitoring (FIM) is configured to immediately alert security personnel of unauthorized audit log changes.

Required Manual Verification:
(1) Verify FIM tools configured to monitor ALL audit log locations
    - XO logs: /var/log/xo-server, /opt/xo/logs (if applicable)
    - System logs: /var/log/syslog, /var/log/auth.log
    - Web server logs: /var/log/nginx (if applicable)
    - Systemd journal: /var/log/journal
    - Request FIM configuration file for review

(2) Verify alert thresholds properly calibrated to detect unauthorized changes
    - Alert on file modification (content changes)
    - Alert on file deletion
    - Alert on permission changes (chmod)
    - Alert on ownership changes (chown)
    - Test alert generation by modifying test log file

(3) Verify alerting mechanisms reach designated security personnel (ISSO/SA)
    - Confirm ISSO/SA email addresses configured in FIM tool
    - Test alert delivery by triggering FIM check
    - Verify alerts received within acceptable timeframe (&lt;15 minutes)
    - Check spam filters (alerts not blocked)

(4) Verify response procedures documented and tested
    - Request copy of incident response procedures
    - Confirm procedures define actions for audit log tampering
    - Verify assignment of responsibilities (who investigates)
    - Test response process with tabletop exercise

(5) Verify integration with organizational SIEM/monitoring infrastructure
    - Confirm FIM alerts forwarded to SIEM
    - Verify SIEM correlation rules for audit log tampering
    - Check for automated response workflows (e.g., ticket creation)
    - Test end-to-end alert flow (FIM &gt; SIEM &gt; SOC &gt; ISSO)

Remediation for missing FIM alerting:

Option 1: Configure AIDE (Advanced Intrusion Detection Environment)
  1. Install AIDE:
     apt install aide aide-common  # Debian

  2. Configure /etc/aide/aide.conf to monitor audit logs:
     # Add monitoring rules
     /var/log/xo-server LOG
     /var/log/nginx LOG
     /var/log/syslog LOG
     /var/log/auth.log LOG
     /var/log/journal DATAONLY

     # Rule definitions
     LOG = p+i+n+u+g+s+m+c+md5+sha256
     DATAONLY = p+n+u+g+s+md5+sha256

  3. Initialize AIDE database:
     aideinit
     mv /var/lib/aide/aide.db.new /var/lib/aide/aide.db

  4. Create check script /usr/local/bin/aide-check-alert.sh:
     #!/bin/bash
     AIDE_REPORT=$(aide --check 2&gt;&amp;1)
     if [ $? -ne 0 ]; then
       echo "$AIDE_REPORT" | mail -s "ALERT: Audit Log Integrity Violation on $(hostname)" \
         isso@example.mil,sa@example.mil
     fi

  5. Make executable and add to cron:
     chmod +x /usr/local/bin/aide-check-alert.sh
     echo "0 */4 * * * /usr/local/bin/aide-check-alert.sh" &gt;&gt; /etc/crontab

Option 2: Configure OSSEC (Host Intrusion Detection System)
  1. Install OSSEC agent:
     wget -q -O - https://updates.atomicorp.com/installers/atomic | bash
     yum install ossec-hids-agent  # RHEL/CentOS
     # OR
     apt install ossec-hids-agent  # Debian

  2. Configure /var/ossec/etc/ossec.conf:
     &lt;syscheck&gt;
       &lt;frequency&gt;300&lt;/frequency&gt;
       &lt;directories check_all="yes" realtime="yes"&gt;/var/log/xo-server&lt;/directories&gt;
       &lt;directories check_all="yes" realtime="yes"&gt;/var/log/nginx&lt;/directories&gt;
       &lt;directories check_all="yes"&gt;/var/log/syslog&lt;/directories&gt;
       &lt;alert_new_files&gt;yes&lt;/alert_new_files&gt;
     &lt;/syscheck&gt;

     &lt;email_notification&gt;
       &lt;email_to&gt;isso@example.mil&lt;/email_to&gt;
       &lt;email_to&gt;sa@example.mil&lt;/email_to&gt;
       &lt;smtp_server&gt;mail.example.mil&lt;/smtp_server&gt;
       &lt;email_from&gt;ossec@xo1.example.mil&lt;/email_from&gt;
     &lt;/email_notification&gt;

  3. Configure OSSEC server to receive alerts (on OSSEC manager)

  4. Start OSSEC agent:
     systemctl start ossec-hids
     systemctl enable ossec-hids

Option 3: Configure Auditd + Alerting
  1. Install auditd:
     apt install auditd audispd-plugins  # Debian

  2. Add watch rules /etc/audit/rules.d/50-xo-audit-logs.rules:
     -w /var/log/xo-server/ -p wa -k xo_log_tampering
     -w /var/log/nginx/ -p wa -k nginx_log_tampering
     -w /var/log/syslog -p wa -k syslog_tampering
     -w /var/log/auth.log -p wa -k auth_log_tampering

  3. Load rules:
     augenrules --load
     systemctl restart auditd

  4. Create alert script /usr/local/bin/auditd-log-alert.sh:
     #!/bin/bash
     ausearch -k xo_log_tampering -k nginx_log_tampering -k syslog_tampering \
       --start recent -i 2&gt;&amp;1 | \
     mail -s "ALERT: Audit Log Modification Detected on $(hostname)" \
       isso@example.mil,sa@example.mil

  5. Add to cron (check every 15 minutes):
     */15 * * * * /usr/local/bin/auditd-log-alert.sh

Option 4: Configure File Immutability (Prevention)
  1. Set append-only attribute on log files:
     chattr +a /var/log/xo-server/*.log
     chattr +a /var/log/nginx/*.log
     chattr +a /var/log/syslog
     chattr +a /var/log/auth.log

  2. Verify attributes:
     lsattr /var/log/xo-server/
     # Should show 'a' flag (append-only)

  3. Note: Requires root to remove attribute
     # To remove for log rotation:
     chattr -a /var/log/xo-server/*.log
     # Perform rotation
     chattr +a /var/log/xo-server/*.log

Step 5: Test FIM Alerting
  1. Create test log file:
     echo "Test log entry" &gt; /var/log/xo-server/test.log

  2. Modify test file (should trigger alert):
     echo "Unauthorized modification" &gt;&gt; /var/log/xo-server/test.log

  3. Wait for FIM check interval (or run manually)

  4. Verify alert delivered to ISSO/SA email

  5. Remove test file:
     rm /var/log/xo-server/test.log

  6. Document test results

Re-run scan after FIM alerting configured and tested.

Note: DoD requires immediate alerting of unauthorized audit log changes per NIST SP 800-53r5 AU-9(3) (Protection of Audit Information - Cryptographic Protection). File integrity monitoring with real-time alerting is mandatory to detect audit log tampering attempts.
        </ValidTrueComment>
        <ValidFalseStatus>NotAFinding</ValidFalseStatus>
        <ValidFalseComment>This Answer Index should not normally be used. If the automated check returns Open but FIM alerting is verified, manual verification required to confirm configuration meets DoD requirements.</ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

    <Vuln ID="V-264346">
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode>None</ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>The automated check detected password policy documentation and evidence of periodic updates. Organizational password policy defines update frequency (quarterly/annually). Password list files present with recent modification dates. Automated update mechanisms detected (cron/systemd timers). Password list maintenance performed on schedule. When LDAP/AD authentication used, password list managed by directory service. Manual ISSO/ISSM verification confirms password list updates occur at organization-defined frequency and documented in policy.</ValidTrueComment>
        <ValidFalseStatus>NotAFinding</ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant or unverified systems requiring manual ISSO/ISSM review-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check could not verify password list update frequency or detected no organizational policy. DoD requirement: Update list of commonly-used/expected/compromised passwords on organization-defined frequency. REMEDIATION: (1) Establish organizational policy for password list update frequency (recommend quarterly); (2) Create password list file (reference NIST SP 800-63B Appendix A, HaveIBeenPwned breach database); (3) Configure automated update mechanism (cron job to download updated list); (4) Install PAM pwquality with dictionary=/path/to/password-list.txt; (5) Document update frequency in organizational password policy; (6) Schedule periodic reviews (quarterly) with calendar reminders. MANUAL VERIFICATION REQUIRED: ISSO must review organizational password policy, confirm update frequency defined, verify evidence of periodic updates, and validate password list currency matches policy requirements.</ValidTrueComment>
        <ValidFalseStatus>Open</ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

    <Vuln ID="V-264347">
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode>None</ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>The automated check detected incident response procedures and evidence of compromise-driven updates. Organizational security policy documents password list update upon compromise. Password list update history shows breach-responsive changes. Security incident logs or SIEM integration for breach detection present. Automated breach notification systems detected (HaveIBeenPwned API, breach feeds). Manual ISSO/ISSM verification confirms incident response procedures trigger immediate password list updates when organizational passwords suspected compromised.</ValidTrueComment>
        <ValidFalseStatus>NotAFinding</ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant or unverified systems requiring manual ISSO/ISSM review-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check could not verify breach response procedures or detected no incident-driven update evidence. DoD requirement: Update password list when organizational passwords suspected compromised directly or indirectly. REMEDIATION: (1) Establish incident response procedures for password compromise; (2) Integrate breach notification service (HaveIBeenPwned API, breach intelligence feeds); (3) Document password compromise response in organizational security policy; (4) Create runbook for immediate password list update upon breach notification; (5) Configure SIEM alerts for credential compromise indicators; (6) Test breach response procedures annually. MANUAL VERIFICATION REQUIRED: ISSO must review incident response plan, confirm password compromise procedures defined, verify breach notification integration, and validate evidence of immediate action upon compromise detection.</ValidTrueComment>
        <ValidFalseStatus>Open</ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

    <Vuln ID="V-264357">
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="Not_Reviewed" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Default for functions that cannot execute or require manual verification-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Not_Reviewed</ValidTrueStatus>
        <ValidTrueComment>The automated check could not complete execution. Manual verification required for V-264357 (Protected Cryptographic Key Storage). VERIFICATION PROCEDURES: (1) Locate private key files: Check XO config (/opt/xo/xo-server/config.toml, /etc/xo-server/config.toml) for key file paths; Search common locations (/etc/ssl/private, /etc/ssl, /opt/xo, /etc/xo-server, /etc/pki/tls/private); (2) Verify file permissions: Run 'stat -c "%a %U:%G" &lt;keyfile&gt;' - Must be 600 or 400, owner root:root; (3) Check for HSM/TPM integration: Run 'lsusb | grep -iE "yubi|smartcard|hsm"' for hardware tokens; Check for PKCS#11 libraries in /usr/lib or /opt; Run 'ls /dev/tpm*' to detect TPM devices; (4) Verify encrypted keys: Run 'head -5 &lt;keyfile&gt;' - Look for "ENCRYPTED" in header (password-protected PEM); (5) Check KMS integration: Run 'systemctl is-active vault' for HashiCorp Vault; Check for AWS CLI or Azure CLI installations; (6) Document findings: Record key locations, permissions, ownership, and protection mechanisms; Confirm organizational key management policy exists and is followed. DoD REQUIREMENT: Keys must be protected with organization-defined safeguards and/or hardware protected key store (HSM/TPM preferred).</ValidTrueComment>
        <ValidFalseStatus>Not_Reviewed</ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant systems with keys found but insufficient protection-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check detected keys with insufficient protection or cannot verify organizational safeguards. DoD requirement: Provide protected storage for cryptographic keys with organization-defined safeguards and/or hardware protected key store. REMEDIATION: (1) Set key file permissions (chmod 600 /path/to/private.key; chown root:root); (2) Use encrypted key files (openssl rsa -aes256 -in key.pem -out encrypted-key.pem); (3) Integrate HSM for key storage (PKCS#11 module, OpenSSL engine); (4) Configure TPM for key protection (tpm2-tools); (5) Implement key management service (HashiCorp Vault, AWS KMS); (6) Document key protection in organizational policy. MANUAL VERIFICATION REQUIRED: ISSO must verify keys stored with organization-defined safeguards (HSM/TPM/encryption), confirm key access restricted to authorized processes, and validate key protection meets FIPS 140-2 requirements.</ValidTrueComment>
        <ValidFalseStatus>Open</ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
      <Answer Index="3" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Compliant systems with proper key protection detected-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>The automated check detected protected key storage mechanisms. Private key files found with correct permissions (600/400) and ownership (root:root). HSM/TPM integration detected OR encrypted key files (password-protected PEM). File system searches confirmed keys stored in protected directories (/etc/ssl/private, /etc/pki/tls/private, /etc/xo-server, /opt/xo). No world-readable key files detected. Key management service integration may be present (vault, KMS). Manual verification confirms organizational key protection safeguards meet DoD requirements.</ValidTrueComment>
        <ValidFalseStatus>NotAFinding</ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

    <Vuln ID="V-264354">
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode>None</ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>The automated check detected certificate revocation caching mechanisms. CRL cache directories present (/etc/ssl/crl, /var/cache/crl) with recent CRL files. OCSP stapling configured in Nginx or Node.js TLS settings. CRL download and caching scripts detected (cron/systemd timers). Certificate revocation checking enabled in OpenSSL configuration. System maintains local cache of revocation data to support offline validation and reduce latency. Manual verification confirms CRL/OCSP cache updated within validity period.</ValidTrueComment>
        <ValidFalseStatus>NotAFinding</ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant or unverified systems requiring manual ISSO/ISSM review-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check could not confirm certificate revocation caching or detected no CRL/OCSP infrastructure. DoD requirement: Implement local cache of revocation data to support path discovery and validation. REMEDIATION: (1) Create CRL cache directory (mkdir -p /var/cache/crl); (2) Configure CRL download script (wget -P /var/cache/crl https://crl.dod.mil/...); (3) Schedule periodic CRL updates (cron: 0 */6 * * * /usr/local/bin/update-crls.sh); (4) Enable OCSP stapling in Nginx (ssl_stapling on; ssl_stapling_verify on;); (5) Configure Node.js TLS with crl property in config.toml; (6) Set OpenSSL to check revocation (openssl verify -crl_check). MANUAL VERIFICATION REQUIRED: Verify CRL/OCSP cache updates within validity period, test revocation checking with revoked certificate, confirm offline validation capability.</ValidTrueComment>
        <ValidFalseStatus>Open</ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

    <Vuln ID="V-279028">
    <AnswerKey Name="XO">
      <Answer Index="1" ExpectedStatus="NotAFinding" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <ValidationCode>None</ValidationCode>
        <ValidTrueStatus>NotAFinding</ValidTrueStatus>
        <ValidTrueComment>The automated check detected comprehensive source identification mechanisms. XO authentication captures user identity (LDAP/SAML/OAuth plugins or local accounts). TLS client certificate authentication provides X.509 identity. API token authentication includes user attribution. Session management tracks user identity in Redis. Audit logging records organization + system + application + individual for ALL information transfers. Manual ISSO/ISSM verification confirms complete source attribution (org + system + app + user) for ALL access attempts and data transfers.</ValidTrueComment>
        <ValidFalseStatus>NotAFinding</ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
      <Answer Index="2" ExpectedStatus="Open" Hostname="" Instance="" Database="" Site="" ResultHash="">
        <!--Non-compliant or unverified systems requiring manual ISSO/ISSM review-->
        <ValidationCode></ValidationCode>
        <ValidTrueStatus>Open</ValidTrueStatus>
        <ValidTrueComment>The automated check detected authentication but cannot verify complete source identification. DoD requirement: Uniquely identify and authenticate source by organization, system, application, AND individual for information transfer. REMEDIATION: (1) Enable LDAP/AD authentication with organizational context (install xo-server-auth-ldap, configure LDAP server with org attributes); (2) Configure TLS client certificates with X.509 subject DN including organization; (3) Implement audit logging with full source attribution (user + IP + system + org context); (4) Configure session management to capture and maintain source identity; (5) Enable XO audit plugin to log ALL information transfers with source details; (6) Document source identification requirements in organizational policy. MANUAL VERIFICATION REQUIRED: ISSO must verify ALL information transfers logged with organization + system + application + individual identity, confirm audit records demonstrate complete source attribution, and validate source identification meets DoD traceability requirements.</ValidTrueComment>
        <ValidFalseStatus>Open</ValidFalseStatus>
        <ValidFalseComment></ValidFalseComment>
      </Answer>
    </AnswerKey>
  </Vuln>

</STIGComments>